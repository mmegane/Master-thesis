2020-05-12 21:33:30.387389: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-05-12 21:33:30.391572: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz
2020-05-12 21:33:30.392194: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf326dc6b0 executing computations on platform Host. Devices:
2020-05-12 21:33:30.392253: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-05-12 21:33:30.392978: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-05-12 21:33:30.555854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.556248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-05-12 21:33:30.556305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.556597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-05-12 21:33:30.557564: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-12 21:33:30.560387: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-05-12 21:33:30.562690: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-05-12 21:33:30.563873: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-05-12 21:33:30.565961: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-05-12 21:33:30.567359: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-05-12 21:33:30.570601: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-12 21:33:30.570715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.571132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.571449: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.571802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.572092: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-12 21:33:30.572120: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-12 21:33:30.573011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-12 21:33:30.573027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-12 21:33:30.573034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-05-12 21:33:30.573047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-05-12 21:33:30.573146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.573522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.573844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.574214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.574563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-05-12 21:33:30.575014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.575366: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.575667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7507 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-05-12 21:33:30.577317: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55bf33a1f1f0 executing computations on platform CUDA. Devices:
2020-05-12 21:33:30.577348: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-05-12 21:33:30.577353: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From segmentation.py:18: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

WARNING:tensorflow:From segmentation.py:31: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From segmentation.py:33: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-05-12 21:33:30.578321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.578689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-05-12 21:33:30.578752: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.579069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-05-12 21:33:30.579109: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-12 21:33:30.579118: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-05-12 21:33:30.579126: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-05-12 21:33:30.579134: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-05-12 21:33:30.579142: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-05-12 21:33:30.579155: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-05-12 21:33:30.579163: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-12 21:33:30.579203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.579573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.579919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.580323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.580614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-12 21:33:30.580643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-12 21:33:30.580650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-12 21:33:30.580655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-05-12 21:33:30.580658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-05-12 21:33:30.580735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.581111: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.581434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.581773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-05-12 21:33:30.581818: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-12 21:33:30.582113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7507 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-05-12 21:34:18.186066: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
Epoch 1/150
 - 1168s - loss: 0.4731 - weighted_dice_loss: 0.4731 - val_loss: 0.3736 - val_weighted_dice_loss: 0.3736

Epoch 00001: val_loss improved from inf to 0.37362, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 2/150
 - 1123s - loss: 0.3366 - weighted_dice_loss: 0.3366 - val_loss: 0.3105 - val_weighted_dice_loss: 0.3105

Epoch 00002: val_loss improved from 0.37362 to 0.31046, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 3/150
 - 1126s - loss: 0.2968 - weighted_dice_loss: 0.2968 - val_loss: 0.3250 - val_weighted_dice_loss: 0.3250

Epoch 00003: val_loss did not improve from 0.31046
Epoch 4/150
 - 1126s - loss: 0.2822 - weighted_dice_loss: 0.2822 - val_loss: 0.2790 - val_weighted_dice_loss: 0.2790

Epoch 00004: val_loss improved from 0.31046 to 0.27900, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 5/150
 - 1125s - loss: 0.2730 - weighted_dice_loss: 0.2730 - val_loss: 0.2725 - val_weighted_dice_loss: 0.2725

Epoch 00005: val_loss improved from 0.27900 to 0.27248, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 6/150
 - 1126s - loss: 0.2637 - weighted_dice_loss: 0.2637 - val_loss: 0.2639 - val_weighted_dice_loss: 0.2639

Epoch 00006: val_loss improved from 0.27248 to 0.26392, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 7/150
 - 1126s - loss: 0.2562 - weighted_dice_loss: 0.2562 - val_loss: 0.2598 - val_weighted_dice_loss: 0.2598

Epoch 00007: val_loss improved from 0.26392 to 0.25984, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 8/150
 - 1126s - loss: 0.2499 - weighted_dice_loss: 0.2499 - val_loss: 0.2846 - val_weighted_dice_loss: 0.2846

Epoch 00008: val_loss did not improve from 0.25984
Epoch 9/150
 - 1126s - loss: 0.2439 - weighted_dice_loss: 0.2439 - val_loss: 0.2498 - val_weighted_dice_loss: 0.2498

Epoch 00009: val_loss improved from 0.25984 to 0.24975, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 10/150
 - 1126s - loss: 0.2393 - weighted_dice_loss: 0.2393 - val_loss: 0.2412 - val_weighted_dice_loss: 0.2412

Epoch 00010: val_loss improved from 0.24975 to 0.24122, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 11/150
 - 1125s - loss: 0.2351 - weighted_dice_loss: 0.2351 - val_loss: 0.2432 - val_weighted_dice_loss: 0.2432

Epoch 00011: val_loss did not improve from 0.24122
Epoch 12/150
 - 1125s - loss: 0.2307 - weighted_dice_loss: 0.2307 - val_loss: 0.2373 - val_weighted_dice_loss: 0.2373

Epoch 00012: val_loss improved from 0.24122 to 0.23734, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 13/150
 - 1125s - loss: 0.2281 - weighted_dice_loss: 0.2281 - val_loss: 0.2416 - val_weighted_dice_loss: 0.2416

Epoch 00013: val_loss did not improve from 0.23734
Epoch 14/150
 - 1126s - loss: 0.2252 - weighted_dice_loss: 0.2252 - val_loss: 0.2338 - val_weighted_dice_loss: 0.2338

Epoch 00014: val_loss improved from 0.23734 to 0.23384, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 15/150
 - 1125s - loss: 0.2229 - weighted_dice_loss: 0.2229 - val_loss: 0.2562 - val_weighted_dice_loss: 0.2562

Epoch 00015: val_loss did not improve from 0.23384
Epoch 16/150
 - 1126s - loss: 0.2188 - weighted_dice_loss: 0.2188 - val_loss: 0.2390 - val_weighted_dice_loss: 0.2390

Epoch 00016: val_loss did not improve from 0.23384
Epoch 17/150
 - 1126s - loss: 0.2168 - weighted_dice_loss: 0.2168 - val_loss: 0.2266 - val_weighted_dice_loss: 0.2266

Epoch 00017: val_loss improved from 0.23384 to 0.22663, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 18/150
 - 1126s - loss: 0.2143 - weighted_dice_loss: 0.2143 - val_loss: 0.2344 - val_weighted_dice_loss: 0.2344

Epoch 00018: val_loss did not improve from 0.22663
Epoch 19/150
 - 1125s - loss: 0.2118 - weighted_dice_loss: 0.2118 - val_loss: 0.2212 - val_weighted_dice_loss: 0.2212

Epoch 00019: val_loss improved from 0.22663 to 0.22124, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 20/150
 - 1125s - loss: 0.2097 - weighted_dice_loss: 0.2097 - val_loss: 0.2223 - val_weighted_dice_loss: 0.2223

Epoch 00020: val_loss did not improve from 0.22124
Epoch 21/150
 - 1126s - loss: 0.2080 - weighted_dice_loss: 0.2080 - val_loss: 0.2246 - val_weighted_dice_loss: 0.2246

Epoch 00021: val_loss did not improve from 0.22124
Epoch 22/150
 - 1125s - loss: 0.2054 - weighted_dice_loss: 0.2054 - val_loss: 0.6878 - val_weighted_dice_loss: 0.6878

Epoch 00022: val_loss did not improve from 0.22124
Epoch 23/150
 - 1126s - loss: 0.2044 - weighted_dice_loss: 0.2044 - val_loss: 0.2194 - val_weighted_dice_loss: 0.2194

Epoch 00023: val_loss improved from 0.22124 to 0.21938, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 24/150
 - 1126s - loss: 0.2027 - weighted_dice_loss: 0.2027 - val_loss: 0.2139 - val_weighted_dice_loss: 0.2139

Epoch 00024: val_loss improved from 0.21938 to 0.21386, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 25/150
 - 1126s - loss: 0.2013 - weighted_dice_loss: 0.2013 - val_loss: 0.2170 - val_weighted_dice_loss: 0.2170

Epoch 00025: val_loss did not improve from 0.21386
Epoch 26/150
 - 1125s - loss: 0.1995 - weighted_dice_loss: 0.1995 - val_loss: 0.2112 - val_weighted_dice_loss: 0.2112

Epoch 00026: val_loss improved from 0.21386 to 0.21117, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 27/150
 - 1125s - loss: 0.1982 - weighted_dice_loss: 0.1982 - val_loss: 0.2136 - val_weighted_dice_loss: 0.2136

Epoch 00027: val_loss did not improve from 0.21117
Epoch 28/150
 - 1126s - loss: 0.1975 - weighted_dice_loss: 0.1975 - val_loss: 0.2127 - val_weighted_dice_loss: 0.2127

Epoch 00028: val_loss did not improve from 0.21117
Epoch 29/150
 - 1126s - loss: 0.1963 - weighted_dice_loss: 0.1963 - val_loss: 0.2069 - val_weighted_dice_loss: 0.2069

Epoch 00029: val_loss improved from 0.21117 to 0.20687, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 30/150
 - 1125s - loss: 0.1946 - weighted_dice_loss: 0.1946 - val_loss: 0.2111 - val_weighted_dice_loss: 0.2111

Epoch 00030: val_loss did not improve from 0.20687
Epoch 31/150
 - 1125s - loss: 0.1939 - weighted_dice_loss: 0.1939 - val_loss: 0.2133 - val_weighted_dice_loss: 0.2133

Epoch 00031: val_loss did not improve from 0.20687
Epoch 32/150
 - 1125s - loss: 0.1925 - weighted_dice_loss: 0.1925 - val_loss: 0.2133 - val_weighted_dice_loss: 0.2133

Epoch 00032: val_loss did not improve from 0.20687
Epoch 33/150
 - 1125s - loss: 0.1909 - weighted_dice_loss: 0.1909 - val_loss: 0.2169 - val_weighted_dice_loss: 0.2169

Epoch 00033: val_loss did not improve from 0.20687
Epoch 34/150
 - 1126s - loss: 0.1902 - weighted_dice_loss: 0.1902 - val_loss: 0.2143 - val_weighted_dice_loss: 0.2143

Epoch 00034: val_loss did not improve from 0.20687
Epoch 35/150
 - 1126s - loss: 0.1894 - weighted_dice_loss: 0.1894 - val_loss: 0.2278 - val_weighted_dice_loss: 0.2278

Epoch 00035: val_loss did not improve from 0.20687
Epoch 36/150
 - 1126s - loss: 0.1879 - weighted_dice_loss: 0.1879 - val_loss: 0.2035 - val_weighted_dice_loss: 0.2035

Epoch 00036: val_loss improved from 0.20687 to 0.20350, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 37/150
 - 1126s - loss: 0.1874 - weighted_dice_loss: 0.1874 - val_loss: 0.2182 - val_weighted_dice_loss: 0.2182

Epoch 00037: val_loss did not improve from 0.20350
Epoch 38/150
 - 1126s - loss: 0.1864 - weighted_dice_loss: 0.1864 - val_loss: 0.2173 - val_weighted_dice_loss: 0.2173

Epoch 00038: val_loss did not improve from 0.20350
Epoch 39/150
 - 1126s - loss: 0.1857 - weighted_dice_loss: 0.1857 - val_loss: 0.2044 - val_weighted_dice_loss: 0.2044

Epoch 00039: val_loss did not improve from 0.20350
Epoch 40/150
 - 1126s - loss: 0.1848 - weighted_dice_loss: 0.1848 - val_loss: 0.2231 - val_weighted_dice_loss: 0.2231

Epoch 00040: val_loss did not improve from 0.20350
Epoch 41/150
 - 1126s - loss: 0.1840 - weighted_dice_loss: 0.1840 - val_loss: 0.1989 - val_weighted_dice_loss: 0.1989

Epoch 00041: val_loss improved from 0.20350 to 0.19890, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 42/150
 - 1126s - loss: 0.1833 - weighted_dice_loss: 0.1833 - val_loss: 0.2104 - val_weighted_dice_loss: 0.2104

Epoch 00042: val_loss did not improve from 0.19890
Epoch 43/150
 - 1126s - loss: 0.1833 - weighted_dice_loss: 0.1833 - val_loss: 0.2010 - val_weighted_dice_loss: 0.2010

Epoch 00043: val_loss did not improve from 0.19890
Epoch 44/150
 - 1126s - loss: 0.1821 - weighted_dice_loss: 0.1821 - val_loss: 0.5829 - val_weighted_dice_loss: 0.5829

Epoch 00044: val_loss did not improve from 0.19890
Epoch 45/150
 - 1126s - loss: 0.1815 - weighted_dice_loss: 0.1815 - val_loss: 0.2034 - val_weighted_dice_loss: 0.2034

Epoch 00045: val_loss did not improve from 0.19890
Epoch 46/150
 - 1125s - loss: 0.1803 - weighted_dice_loss: 0.1803 - val_loss: 0.1965 - val_weighted_dice_loss: 0.1965

Epoch 00046: val_loss improved from 0.19890 to 0.19649, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 47/150
 - 1125s - loss: 0.1803 - weighted_dice_loss: 0.1803 - val_loss: 0.1983 - val_weighted_dice_loss: 0.1983

Epoch 00047: val_loss did not improve from 0.19649
Epoch 48/150
 - 1126s - loss: 0.1793 - weighted_dice_loss: 0.1793 - val_loss: 0.2020 - val_weighted_dice_loss: 0.2020

Epoch 00048: val_loss did not improve from 0.19649
Epoch 49/150
 - 1125s - loss: 0.1793 - weighted_dice_loss: 0.1793 - val_loss: 0.2099 - val_weighted_dice_loss: 0.2099

Epoch 00049: val_loss did not improve from 0.19649
Epoch 50/150
 - 1126s - loss: 0.1779 - weighted_dice_loss: 0.1779 - val_loss: 0.1972 - val_weighted_dice_loss: 0.1972

Epoch 00050: val_loss did not improve from 0.19649
Epoch 51/150
 - 1125s - loss: 0.1777 - weighted_dice_loss: 0.1777 - val_loss: 0.2218 - val_weighted_dice_loss: 0.2218

Epoch 00051: val_loss did not improve from 0.19649
Epoch 52/150
 - 1125s - loss: 0.1766 - weighted_dice_loss: 0.1766 - val_loss: 0.1965 - val_weighted_dice_loss: 0.1965

Epoch 00052: val_loss did not improve from 0.19649
Epoch 53/150
 - 1125s - loss: 0.1761 - weighted_dice_loss: 0.1761 - val_loss: 0.2008 - val_weighted_dice_loss: 0.2008

Epoch 00053: val_loss did not improve from 0.19649
Epoch 54/150
 - 1125s - loss: 0.1760 - weighted_dice_loss: 0.1760 - val_loss: 0.1992 - val_weighted_dice_loss: 0.1992

Epoch 00054: val_loss did not improve from 0.19649
Epoch 55/150
 - 1125s - loss: 0.1757 - weighted_dice_loss: 0.1757 - val_loss: 0.1968 - val_weighted_dice_loss: 0.1968

Epoch 00055: val_loss did not improve from 0.19649
Epoch 56/150
 - 1125s - loss: 0.1753 - weighted_dice_loss: 0.1753 - val_loss: 0.1947 - val_weighted_dice_loss: 0.1947

Epoch 00056: val_loss improved from 0.19649 to 0.19472, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 57/150
 - 1125s - loss: 0.1745 - weighted_dice_loss: 0.1745 - val_loss: 0.2017 - val_weighted_dice_loss: 0.2017

Epoch 00057: val_loss did not improve from 0.19472
Epoch 58/150
 - 1125s - loss: 0.1736 - weighted_dice_loss: 0.1736 - val_loss: 0.1966 - val_weighted_dice_loss: 0.1966

Epoch 00058: val_loss did not improve from 0.19472
Epoch 59/150
 - 1125s - loss: 0.1729 - weighted_dice_loss: 0.1729 - val_loss: 0.2009 - val_weighted_dice_loss: 0.2009

Epoch 00059: val_loss did not improve from 0.19472
Epoch 60/150
 - 1125s - loss: 0.1728 - weighted_dice_loss: 0.1728 - val_loss: 0.1976 - val_weighted_dice_loss: 0.1976

Epoch 00060: val_loss did not improve from 0.19472
Epoch 61/150
 - 1125s - loss: 0.1728 - weighted_dice_loss: 0.1728 - val_loss: 0.4378 - val_weighted_dice_loss: 0.4378

Epoch 00061: val_loss did not improve from 0.19472
Epoch 62/150
 - 1125s - loss: 0.1723 - weighted_dice_loss: 0.1723 - val_loss: 0.1970 - val_weighted_dice_loss: 0.1970

Epoch 00062: val_loss did not improve from 0.19472
Epoch 63/150
 - 1125s - loss: 0.1718 - weighted_dice_loss: 0.1718 - val_loss: 0.2016 - val_weighted_dice_loss: 0.2016

Epoch 00063: val_loss did not improve from 0.19472
Epoch 64/150
 - 1125s - loss: 0.1716 - weighted_dice_loss: 0.1716 - val_loss: 0.1982 - val_weighted_dice_loss: 0.1982

Epoch 00064: val_loss did not improve from 0.19472
Epoch 65/150
 - 1125s - loss: 0.1712 - weighted_dice_loss: 0.1712 - val_loss: 0.2095 - val_weighted_dice_loss: 0.2095

Epoch 00065: val_loss did not improve from 0.19472
Epoch 66/150
 - 1125s - loss: 0.1711 - weighted_dice_loss: 0.1711 - val_loss: 0.1969 - val_weighted_dice_loss: 0.1969

Epoch 00066: val_loss did not improve from 0.19472
Epoch 67/150
 - 1126s - loss: 0.1701 - weighted_dice_loss: 0.1701 - val_loss: 0.2034 - val_weighted_dice_loss: 0.2034

Epoch 00067: val_loss did not improve from 0.19472
Epoch 68/150
 - 1125s - loss: 0.1702 - weighted_dice_loss: 0.1702 - val_loss: 0.2411 - val_weighted_dice_loss: 0.2411

Epoch 00068: val_loss did not improve from 0.19472
Epoch 69/150
 - 1125s - loss: 0.1693 - weighted_dice_loss: 0.1693 - val_loss: 0.1965 - val_weighted_dice_loss: 0.1965

Epoch 00069: val_loss did not improve from 0.19472
Epoch 70/150
 - 1125s - loss: 0.1692 - weighted_dice_loss: 0.1692 - val_loss: 0.1928 - val_weighted_dice_loss: 0.1928

Epoch 00070: val_loss improved from 0.19472 to 0.19278, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 71/150
 - 1125s - loss: 0.1693 - weighted_dice_loss: 0.1693 - val_loss: 0.8033 - val_weighted_dice_loss: 0.8033

Epoch 00071: val_loss did not improve from 0.19278
Epoch 72/150
 - 1125s - loss: 0.1684 - weighted_dice_loss: 0.1684 - val_loss: 0.3878 - val_weighted_dice_loss: 0.3878

Epoch 00072: val_loss did not improve from 0.19278
Epoch 73/150
 - 1125s - loss: 0.1682 - weighted_dice_loss: 0.1682 - val_loss: 0.1976 - val_weighted_dice_loss: 0.1976

Epoch 00073: val_loss did not improve from 0.19278
Epoch 74/150
 - 1125s - loss: 0.1677 - weighted_dice_loss: 0.1677 - val_loss: 0.4959 - val_weighted_dice_loss: 0.4959

Epoch 00074: val_loss did not improve from 0.19278
Epoch 75/150
 - 1125s - loss: 0.1676 - weighted_dice_loss: 0.1676 - val_loss: 0.1978 - val_weighted_dice_loss: 0.1978

Epoch 00075: val_loss did not improve from 0.19278
Epoch 76/150
 - 1125s - loss: 0.1669 - weighted_dice_loss: 0.1669 - val_loss: 0.1923 - val_weighted_dice_loss: 0.1923

Epoch 00076: val_loss improved from 0.19278 to 0.19228, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 77/150
 - 1125s - loss: 0.1668 - weighted_dice_loss: 0.1668 - val_loss: 0.6454 - val_weighted_dice_loss: 0.6454

Epoch 00077: val_loss did not improve from 0.19228
Epoch 78/150
 - 1125s - loss: 0.1667 - weighted_dice_loss: 0.1667 - val_loss: 0.1963 - val_weighted_dice_loss: 0.1963

Epoch 00078: val_loss did not improve from 0.19228
Epoch 79/150
 - 1125s - loss: 0.1660 - weighted_dice_loss: 0.1660 - val_loss: 0.6003 - val_weighted_dice_loss: 0.6003

Epoch 00079: val_loss did not improve from 0.19228
Epoch 80/150
 - 1125s - loss: 0.1665 - weighted_dice_loss: 0.1665 - val_loss: 0.1976 - val_weighted_dice_loss: 0.1976

Epoch 00080: val_loss did not improve from 0.19228
Epoch 81/150
 - 1125s - loss: 0.1657 - weighted_dice_loss: 0.1657 - val_loss: 0.1930 - val_weighted_dice_loss: 0.1930

Epoch 00081: val_loss did not improve from 0.19228
Epoch 82/150
 - 1126s - loss: 0.1652 - weighted_dice_loss: 0.1652 - val_loss: 0.1939 - val_weighted_dice_loss: 0.1939

Epoch 00082: val_loss did not improve from 0.19228
Epoch 83/150
 - 1125s - loss: 0.1650 - weighted_dice_loss: 0.1650 - val_loss: 0.9278 - val_weighted_dice_loss: 0.9278

Epoch 00083: val_loss did not improve from 0.19228
Epoch 84/150
 - 1126s - loss: 0.1645 - weighted_dice_loss: 0.1645 - val_loss: 0.2085 - val_weighted_dice_loss: 0.2085

Epoch 00084: val_loss did not improve from 0.19228
Epoch 85/150
 - 1126s - loss: 0.1650 - weighted_dice_loss: 0.1650 - val_loss: 0.2025 - val_weighted_dice_loss: 0.2025

Epoch 00085: val_loss did not improve from 0.19228
Epoch 86/150
 - 1125s - loss: 0.1640 - weighted_dice_loss: 0.1640 - val_loss: 0.1942 - val_weighted_dice_loss: 0.1942

Epoch 00086: val_loss did not improve from 0.19228
Epoch 87/150
 - 1125s - loss: 0.1643 - weighted_dice_loss: 0.1643 - val_loss: 0.2489 - val_weighted_dice_loss: 0.2489

Epoch 00087: val_loss did not improve from 0.19228
Epoch 88/150
 - 1125s - loss: 0.1635 - weighted_dice_loss: 0.1635 - val_loss: 0.1901 - val_weighted_dice_loss: 0.1901

Epoch 00088: val_loss improved from 0.19228 to 0.19008, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 89/150
 - 1125s - loss: 0.1629 - weighted_dice_loss: 0.1629 - val_loss: 0.1996 - val_weighted_dice_loss: 0.1996

Epoch 00089: val_loss did not improve from 0.19008
Epoch 90/150
 - 1126s - loss: 0.1634 - weighted_dice_loss: 0.1634 - val_loss: 0.1929 - val_weighted_dice_loss: 0.1929

Epoch 00090: val_loss did not improve from 0.19008
Epoch 91/150
 - 1125s - loss: 0.1629 - weighted_dice_loss: 0.1629 - val_loss: 0.2944 - val_weighted_dice_loss: 0.2944

Epoch 00091: val_loss did not improve from 0.19008
Epoch 92/150
 - 1126s - loss: 0.1629 - weighted_dice_loss: 0.1629 - val_loss: 0.2074 - val_weighted_dice_loss: 0.2074

Epoch 00092: val_loss did not improve from 0.19008
Epoch 93/150
 - 1126s - loss: 0.1624 - weighted_dice_loss: 0.1624 - val_loss: 0.1914 - val_weighted_dice_loss: 0.1914

Epoch 00093: val_loss did not improve from 0.19008
Epoch 94/150
 - 1126s - loss: 0.1620 - weighted_dice_loss: 0.1620 - val_loss: 0.2752 - val_weighted_dice_loss: 0.2752

Epoch 00094: val_loss did not improve from 0.19008
Epoch 95/150
 - 1126s - loss: 0.1620 - weighted_dice_loss: 0.1620 - val_loss: 0.2786 - val_weighted_dice_loss: 0.2786

Epoch 00095: val_loss did not improve from 0.19008
Epoch 96/150
 - 1126s - loss: 0.1619 - weighted_dice_loss: 0.1619 - val_loss: 0.1932 - val_weighted_dice_loss: 0.1932

Epoch 00096: val_loss did not improve from 0.19008
Epoch 97/150
 - 1126s - loss: 0.1623 - weighted_dice_loss: 0.1623 - val_loss: 0.1933 - val_weighted_dice_loss: 0.1933

Epoch 00097: val_loss did not improve from 0.19008
Epoch 98/150
 - 1125s - loss: 0.1610 - weighted_dice_loss: 0.1610 - val_loss: 0.1924 - val_weighted_dice_loss: 0.1924

Epoch 00098: val_loss did not improve from 0.19008
Epoch 99/150
 - 1125s - loss: 0.1609 - weighted_dice_loss: 0.1609 - val_loss: 0.1900 - val_weighted_dice_loss: 0.1900

Epoch 00099: val_loss improved from 0.19008 to 0.19003, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 100/150
 - 1125s - loss: 0.1605 - weighted_dice_loss: 0.1605 - val_loss: 0.5316 - val_weighted_dice_loss: 0.5316

Epoch 00100: val_loss did not improve from 0.19003
Epoch 101/150
 - 1125s - loss: 0.1608 - weighted_dice_loss: 0.1608 - val_loss: 0.1896 - val_weighted_dice_loss: 0.1896

Epoch 00101: val_loss improved from 0.19003 to 0.18960, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 102/150
 - 1125s - loss: 0.1608 - weighted_dice_loss: 0.1608 - val_loss: 0.2682 - val_weighted_dice_loss: 0.2682

Epoch 00102: val_loss did not improve from 0.18960
Epoch 103/150
 - 1125s - loss: 0.1603 - weighted_dice_loss: 0.1603 - val_loss: 0.1891 - val_weighted_dice_loss: 0.1891

Epoch 00103: val_loss improved from 0.18960 to 0.18912, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 104/150
 - 1125s - loss: 0.1600 - weighted_dice_loss: 0.1600 - val_loss: 0.2337 - val_weighted_dice_loss: 0.2337

Epoch 00104: val_loss did not improve from 0.18912
Epoch 105/150
 - 1125s - loss: 0.1594 - weighted_dice_loss: 0.1594 - val_loss: 0.1903 - val_weighted_dice_loss: 0.1903

Epoch 00105: val_loss did not improve from 0.18912
Epoch 106/150
 - 1125s - loss: 0.1587 - weighted_dice_loss: 0.1587 - val_loss: 0.1885 - val_weighted_dice_loss: 0.1885

Epoch 00106: val_loss improved from 0.18912 to 0.18848, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 107/150
 - 1125s - loss: 0.1589 - weighted_dice_loss: 0.1589 - val_loss: 0.4154 - val_weighted_dice_loss: 0.4154

Epoch 00107: val_loss did not improve from 0.18848
Epoch 108/150
 - 1125s - loss: 0.1590 - weighted_dice_loss: 0.1590 - val_loss: 0.3637 - val_weighted_dice_loss: 0.3637

Epoch 00108: val_loss did not improve from 0.18848
Epoch 109/150
 - 1125s - loss: 0.1585 - weighted_dice_loss: 0.1585 - val_loss: 0.1872 - val_weighted_dice_loss: 0.1872

Epoch 00109: val_loss improved from 0.18848 to 0.18718, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 110/150
 - 1125s - loss: 0.1591 - weighted_dice_loss: 0.1591 - val_loss: 0.1975 - val_weighted_dice_loss: 0.1975

Epoch 00110: val_loss did not improve from 0.18718
Epoch 111/150
 - 1125s - loss: 0.1585 - weighted_dice_loss: 0.1585 - val_loss: 0.5433 - val_weighted_dice_loss: 0.5433

Epoch 00111: val_loss did not improve from 0.18718
Epoch 112/150
 - 1125s - loss: 0.1581 - weighted_dice_loss: 0.1581 - val_loss: 0.1894 - val_weighted_dice_loss: 0.1894

Epoch 00112: val_loss did not improve from 0.18718
Epoch 113/150
 - 1125s - loss: 0.1580 - weighted_dice_loss: 0.1580 - val_loss: 0.1968 - val_weighted_dice_loss: 0.1968

Epoch 00113: val_loss did not improve from 0.18718
Epoch 114/150
 - 1125s - loss: 0.1580 - weighted_dice_loss: 0.1580 - val_loss: 0.2065 - val_weighted_dice_loss: 0.2065

Epoch 00114: val_loss did not improve from 0.18718
Epoch 115/150
 - 1122s - loss: 0.1579 - weighted_dice_loss: 0.1579 - val_loss: 0.1880 - val_weighted_dice_loss: 0.1880

Epoch 00115: val_loss did not improve from 0.18718
Epoch 116/150
 - 1122s - loss: 0.1574 - weighted_dice_loss: 0.1574 - val_loss: 0.7491 - val_weighted_dice_loss: 0.7491

Epoch 00116: val_loss did not improve from 0.18718
Epoch 117/150
 - 1122s - loss: 0.1568 - weighted_dice_loss: 0.1568 - val_loss: 0.4732 - val_weighted_dice_loss: 0.4732

Epoch 00117: val_loss did not improve from 0.18718
Epoch 118/150
 - 1123s - loss: 0.1571 - weighted_dice_loss: 0.1571 - val_loss: 0.1891 - val_weighted_dice_loss: 0.1891

Epoch 00118: val_loss did not improve from 0.18718
Epoch 119/150
 - 1125s - loss: 0.1569 - weighted_dice_loss: 0.1569 - val_loss: 0.1931 - val_weighted_dice_loss: 0.1931

Epoch 00119: val_loss did not improve from 0.18718
Epoch 120/150
 - 1125s - loss: 0.1575 - weighted_dice_loss: 0.1575 - val_loss: 0.1887 - val_weighted_dice_loss: 0.1887

Epoch 00120: val_loss did not improve from 0.18718
Epoch 121/150
 - 1126s - loss: 0.1564 - weighted_dice_loss: 0.1564 - val_loss: 0.2707 - val_weighted_dice_loss: 0.2707

Epoch 00121: val_loss did not improve from 0.18718
Epoch 122/150
 - 1126s - loss: 0.1569 - weighted_dice_loss: 0.1569 - val_loss: 0.2096 - val_weighted_dice_loss: 0.2096

Epoch 00122: val_loss did not improve from 0.18718
Epoch 123/150
 - 1124s - loss: 0.1563 - weighted_dice_loss: 0.1563 - val_loss: 0.1879 - val_weighted_dice_loss: 0.1879

Epoch 00123: val_loss did not improve from 0.18718
Epoch 124/150
 - 1124s - loss: 0.1562 - weighted_dice_loss: 0.1562 - val_loss: 0.1900 - val_weighted_dice_loss: 0.1900

Epoch 00124: val_loss did not improve from 0.18718
Epoch 125/150
 - 1124s - loss: 0.1560 - weighted_dice_loss: 0.1560 - val_loss: 0.1896 - val_weighted_dice_loss: 0.1896

Epoch 00125: val_loss did not improve from 0.18718
Epoch 126/150
 - 1125s - loss: 0.1560 - weighted_dice_loss: 0.1560 - val_loss: 0.1860 - val_weighted_dice_loss: 0.1860

Epoch 00126: val_loss improved from 0.18718 to 0.18600, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN.h5
Epoch 127/150
 - 1125s - loss: 0.1555 - weighted_dice_loss: 0.1555 - val_loss: 0.2374 - val_weighted_dice_loss: 0.2374

Epoch 00127: val_loss did not improve from 0.18600
Epoch 128/150
 - 1125s - loss: 0.1551 - weighted_dice_loss: 0.1551 - val_loss: 0.8997 - val_weighted_dice_loss: 0.8997

Epoch 00128: val_loss did not improve from 0.18600
Epoch 129/150
 - 1125s - loss: 0.1553 - weighted_dice_loss: 0.1553 - val_loss: 0.1957 - val_weighted_dice_loss: 0.1957

Epoch 00129: val_loss did not improve from 0.18600
Epoch 130/150
 - 1127s - loss: 0.1555 - weighted_dice_loss: 0.1555 - val_loss: 0.1884 - val_weighted_dice_loss: 0.1884

Epoch 00130: val_loss did not improve from 0.18600
Epoch 131/150
 - 1125s - loss: 0.1558 - weighted_dice_loss: 0.1558 - val_loss: 0.6718 - val_weighted_dice_loss: 0.6718

Epoch 00131: val_loss did not improve from 0.18600
Epoch 132/150
 - 1125s - loss: 0.1549 - weighted_dice_loss: 0.1549 - val_loss: 0.8246 - val_weighted_dice_loss: 0.8246

Epoch 00132: val_loss did not improve from 0.18600
Epoch 133/150
 - 1125s - loss: 0.1551 - weighted_dice_loss: 0.1551 - val_loss: 0.1893 - val_weighted_dice_loss: 0.1893

Epoch 00133: val_loss did not improve from 0.18600
Epoch 134/150
 - 1125s - loss: 0.1542 - weighted_dice_loss: 0.1542 - val_loss: 0.1883 - val_weighted_dice_loss: 0.1883

Epoch 00134: val_loss did not improve from 0.18600
Epoch 135/150
 - 1125s - loss: 0.1542 - weighted_dice_loss: 0.1542 - val_loss: 0.2820 - val_weighted_dice_loss: 0.2820

Epoch 00135: val_loss did not improve from 0.18600
Epoch 136/150
 - 1127s - loss: 0.1544 - weighted_dice_loss: 0.1544 - val_loss: 0.2023 - val_weighted_dice_loss: 0.2023

Epoch 00136: val_loss did not improve from 0.18600
Epoch 137/150
 - 1126s - loss: 0.1544 - weighted_dice_loss: 0.1544 - val_loss: 0.3798 - val_weighted_dice_loss: 0.3798

Epoch 00137: val_loss did not improve from 0.18600
Epoch 138/150
 - 1136s - loss: 0.1535 - weighted_dice_loss: 0.1535 - val_loss: 0.2024 - val_weighted_dice_loss: 0.2024

Epoch 00138: val_loss did not improve from 0.18600
Epoch 139/150
 - 1126s - loss: 0.1538 - weighted_dice_loss: 0.1538 - val_loss: 0.1893 - val_weighted_dice_loss: 0.1893

Epoch 00139: val_loss did not improve from 0.18600
Epoch 140/150
 - 1125s - loss: 0.1544 - weighted_dice_loss: 0.1544 - val_loss: 0.1866 - val_weighted_dice_loss: 0.1866

Epoch 00140: val_loss did not improve from 0.18600
Epoch 141/150
 - 1126s - loss: 0.1538 - weighted_dice_loss: 0.1538 - val_loss: 0.1901 - val_weighted_dice_loss: 0.1901

Epoch 00141: val_loss did not improve from 0.18600
Epoch 142/150
 - 1126s - loss: 0.1537 - weighted_dice_loss: 0.1537 - val_loss: 0.1988 - val_weighted_dice_loss: 0.1988

Epoch 00142: val_loss did not improve from 0.18600
Epoch 143/150
 - 1125s - loss: 0.1533 - weighted_dice_loss: 0.1533 - val_loss: 0.7478 - val_weighted_dice_loss: 0.7478

Epoch 00143: val_loss did not improve from 0.18600
Epoch 144/150
 - 1125s - loss: 0.1531 - weighted_dice_loss: 0.1531 - val_loss: 0.1882 - val_weighted_dice_loss: 0.1882

Epoch 00144: val_loss did not improve from 0.18600
Epoch 145/150
 - 1126s - loss: 0.1525 - weighted_dice_loss: 0.1525 - val_loss: 0.3039 - val_weighted_dice_loss: 0.3039

Epoch 00145: val_loss did not improve from 0.18600
Epoch 146/150
 - 1126s - loss: 0.1530 - weighted_dice_loss: 0.1530 - val_loss: 0.8251 - val_weighted_dice_loss: 0.8251

Epoch 00146: val_loss did not improve from 0.18600
Epoch 147/150
 - 1125s - loss: 0.1525 - weighted_dice_loss: 0.1525 - val_loss: 0.1890 - val_weighted_dice_loss: 0.1890

Epoch 00147: val_loss did not improve from 0.18600
Epoch 148/150
 - 1126s - loss: 0.1527 - weighted_dice_loss: 0.1527 - val_loss: 0.3233 - val_weighted_dice_loss: 0.3233

Epoch 00148: val_loss did not improve from 0.18600
Epoch 149/150
 - 1128s - loss: 0.1521 - weighted_dice_loss: 0.1521 - val_loss: 0.1894 - val_weighted_dice_loss: 0.1894

Epoch 00149: val_loss did not improve from 0.18600
Epoch 150/150
 - 1126s - loss: 0.1523 - weighted_dice_loss: 0.1523 - val_loss: 0.1912 - val_weighted_dice_loss: 0.1912

Epoch 00150: val_loss did not improve from 0.18600
