nohup: ignoring input
2020-08-26 23:47:38.730578: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-08-26 23:47:38.747221: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3601770000 Hz
2020-08-26 23:47:38.748700: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558445b1e980 executing computations on platform Host. Devices:
2020-08-26 23:47:38.748776: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-08-26 23:47:38.753001: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-08-26 23:47:38.787991: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:38.789594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
2020-08-26 23:47:38.796266: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-08-26 23:47:38.823684: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-08-26 23:47:38.840639: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-08-26 23:47:38.866995: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-08-26 23:47:38.886192: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-08-26 23:47:38.899474: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-08-26 23:47:38.919917: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-08-26 23:47:38.920161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:38.921581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:38.922795: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-08-26 23:47:38.922878: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-08-26 23:47:39.095624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-26 23:47:39.095722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-08-26 23:47:39.095766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-08-26 23:47:39.098936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.100429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.101838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.103143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7464 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-26 23:47:39.109024: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55844662b5e0 executing computations on platform CUDA. Devices:
2020-08-26 23:47:39.109088: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From segmentation.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

WARNING:tensorflow:From segmentation.py:33: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From segmentation.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-08-26 23:47:39.111844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.116699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
2020-08-26 23:47:39.116810: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-08-26 23:47:39.116870: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-08-26 23:47:39.116922: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-08-26 23:47:39.116973: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-08-26 23:47:39.117024: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-08-26 23:47:39.117075: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-08-26 23:47:39.117127: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-08-26 23:47:39.117343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.118725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.119950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-08-26 23:47:39.120024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-26 23:47:39.120059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-08-26 23:47:39.120086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-08-26 23:47:39.120336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.121703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-26 23:47:39.122960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7464 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-08-26 23:56:13.314598: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7

Reading data...
Finished reading data.

Reading data...
Finished reading data.

Training 2 classes with 26040 images (0 real and 26040 GAN images):

Epoch 1/150
 - 1629s - loss: 0.2193 - weighted_dice_loss: 0.2193 - val_loss: 0.3134 - val_weighted_dice_loss: 0.3134

Epoch 00001: val_weighted_dice_loss improved from inf to 0.31338, saving model to ./Unet-weights/2_classes_0_reals_26040_GANs.h5
Epoch 2/150
 - 1579s - loss: 0.1049 - weighted_dice_loss: 0.1049 - val_loss: 0.2642 - val_weighted_dice_loss: 0.2642

Epoch 00002: val_weighted_dice_loss improved from 0.31338 to 0.26419, saving model to ./Unet-weights/2_classes_0_reals_26040_GANs.h5
Epoch 3/150
 - 1579s - loss: 0.0793 - weighted_dice_loss: 0.0793 - val_loss: 0.2913 - val_weighted_dice_loss: 0.2913

Epoch 00003: val_weighted_dice_loss did not improve from 0.26419
Epoch 4/150
 - 1579s - loss: 0.0668 - weighted_dice_loss: 0.0668 - val_loss: 0.2903 - val_weighted_dice_loss: 0.2903

Epoch 00004: val_weighted_dice_loss did not improve from 0.26419
Epoch 5/150
 - 1578s - loss: 0.0584 - weighted_dice_loss: 0.0584 - val_loss: 0.2480 - val_weighted_dice_loss: 0.2480

Epoch 00005: val_weighted_dice_loss improved from 0.26419 to 0.24801, saving model to ./Unet-weights/2_classes_0_reals_26040_GANs.h5
Epoch 6/150
 - 1579s - loss: 0.0532 - weighted_dice_loss: 0.0532 - val_loss: 0.4328 - val_weighted_dice_loss: 0.4328

Epoch 00006: val_weighted_dice_loss did not improve from 0.24801
Epoch 7/150
 - 1580s - loss: 0.0487 - weighted_dice_loss: 0.0487 - val_loss: 0.2946 - val_weighted_dice_loss: 0.2946

Epoch 00007: val_weighted_dice_loss did not improve from 0.24801
Epoch 8/150
 - 1580s - loss: 0.0467 - weighted_dice_loss: 0.0467 - val_loss: 0.3039 - val_weighted_dice_loss: 0.3039

Epoch 00008: val_weighted_dice_loss did not improve from 0.24801
Epoch 9/150
 - 1580s - loss: 0.0436 - weighted_dice_loss: 0.0436 - val_loss: 0.2658 - val_weighted_dice_loss: 0.2658

Epoch 00009: val_weighted_dice_loss did not improve from 0.24801
Epoch 10/150
 - 1579s - loss: 0.0423 - weighted_dice_loss: 0.0423 - val_loss: 0.2891 - val_weighted_dice_loss: 0.2891

Epoch 00010: val_weighted_dice_loss did not improve from 0.24801
Epoch 11/150
 - 1582s - loss: 0.0404 - weighted_dice_loss: 0.0404 - val_loss: 0.3007 - val_weighted_dice_loss: 0.3007

Epoch 00011: val_weighted_dice_loss did not improve from 0.24801
Epoch 12/150
 - 1580s - loss: 0.0396 - weighted_dice_loss: 0.0396 - val_loss: 0.3292 - val_weighted_dice_loss: 0.3292

Epoch 00012: val_weighted_dice_loss did not improve from 0.24801
Epoch 13/150
 - 1581s - loss: 0.0377 - weighted_dice_loss: 0.0377 - val_loss: 0.4436 - val_weighted_dice_loss: 0.4436

Epoch 00013: val_weighted_dice_loss did not improve from 0.24801
Epoch 14/150
 - 1586s - loss: 0.0369 - weighted_dice_loss: 0.0369 - val_loss: 0.3059 - val_weighted_dice_loss: 0.3059

Epoch 00014: val_weighted_dice_loss did not improve from 0.24801
Epoch 15/150
 - 1583s - loss: 0.0356 - weighted_dice_loss: 0.0356 - val_loss: 0.2481 - val_weighted_dice_loss: 0.2481

Epoch 00015: val_weighted_dice_loss did not improve from 0.24801
Epoch 16/150
 - 1580s - loss: 0.0349 - weighted_dice_loss: 0.0349 - val_loss: 0.3014 - val_weighted_dice_loss: 0.3014

Epoch 00016: val_weighted_dice_loss did not improve from 0.24801
Epoch 17/150
 - 1581s - loss: 0.0341 - weighted_dice_loss: 0.0341 - val_loss: 0.2781 - val_weighted_dice_loss: 0.2781

Epoch 00017: val_weighted_dice_loss did not improve from 0.24801
Epoch 18/150
 - 1583s - loss: 0.0333 - weighted_dice_loss: 0.0333 - val_loss: 0.2601 - val_weighted_dice_loss: 0.2601

Epoch 00018: val_weighted_dice_loss did not improve from 0.24801
Epoch 19/150
 - 1580s - loss: 0.0325 - weighted_dice_loss: 0.0325 - val_loss: 0.2747 - val_weighted_dice_loss: 0.2747

Epoch 00019: val_weighted_dice_loss did not improve from 0.24801
Epoch 20/150
 - 1582s - loss: 0.0316 - weighted_dice_loss: 0.0316 - val_loss: 0.2778 - val_weighted_dice_loss: 0.2778

Epoch 00020: val_weighted_dice_loss did not improve from 0.24801
Epoch 21/150
 - 1582s - loss: 0.0309 - weighted_dice_loss: 0.0309 - val_loss: 0.2648 - val_weighted_dice_loss: 0.2648

Epoch 00021: val_weighted_dice_loss did not improve from 0.24801
Epoch 22/150
 - 1585s - loss: 0.0305 - weighted_dice_loss: 0.0305 - val_loss: 0.2943 - val_weighted_dice_loss: 0.2943

Epoch 00022: val_weighted_dice_loss did not improve from 0.24801
Epoch 23/150
 - 1586s - loss: 0.0297 - weighted_dice_loss: 0.0297 - val_loss: 0.2661 - val_weighted_dice_loss: 0.2661

Epoch 00023: val_weighted_dice_loss did not improve from 0.24801
Epoch 24/150
 - 1582s - loss: 0.0293 - weighted_dice_loss: 0.0293 - val_loss: 0.2809 - val_weighted_dice_loss: 0.2809

Epoch 00024: val_weighted_dice_loss did not improve from 0.24801
Epoch 25/150
 - 1581s - loss: 0.0287 - weighted_dice_loss: 0.0287 - val_loss: 0.2594 - val_weighted_dice_loss: 0.2594

Epoch 00025: val_weighted_dice_loss did not improve from 0.24801
Epoch 26/150
 - 1585s - loss: 0.0280 - weighted_dice_loss: 0.0280 - val_loss: 0.2747 - val_weighted_dice_loss: 0.2747

Epoch 00026: val_weighted_dice_loss did not improve from 0.24801
Epoch 27/150
 - 1590s - loss: 0.0279 - weighted_dice_loss: 0.0279 - val_loss: 0.2842 - val_weighted_dice_loss: 0.2842

Epoch 00027: val_weighted_dice_loss did not improve from 0.24801
Epoch 28/150
 - 1585s - loss: 0.0269 - weighted_dice_loss: 0.0269 - val_loss: 0.2820 - val_weighted_dice_loss: 0.2820

Epoch 00028: val_weighted_dice_loss did not improve from 0.24801
Epoch 29/150
 - 1585s - loss: 0.0266 - weighted_dice_loss: 0.0266 - val_loss: 0.3302 - val_weighted_dice_loss: 0.3302

Epoch 00029: val_weighted_dice_loss did not improve from 0.24801
Epoch 30/150
 - 1584s - loss: 0.0264 - weighted_dice_loss: 0.0264 - val_loss: 0.2874 - val_weighted_dice_loss: 0.2874

Epoch 00030: val_weighted_dice_loss did not improve from 0.24801
Epoch 31/150
 - 1588s - loss: 0.0257 - weighted_dice_loss: 0.0257 - val_loss: 0.2371 - val_weighted_dice_loss: 0.2371

Epoch 00031: val_weighted_dice_loss improved from 0.24801 to 0.23707, saving model to ./Unet-weights/2_classes_0_reals_26040_GANs.h5
Epoch 32/150
 - 1583s - loss: 0.0254 - weighted_dice_loss: 0.0254 - val_loss: 0.2967 - val_weighted_dice_loss: 0.2967

Epoch 00032: val_weighted_dice_loss did not improve from 0.23707
Epoch 33/150
 - 1584s - loss: 0.0251 - weighted_dice_loss: 0.0251 - val_loss: 0.3039 - val_weighted_dice_loss: 0.3039

Epoch 00033: val_weighted_dice_loss did not improve from 0.23707
Epoch 34/150
 - 1584s - loss: 0.0248 - weighted_dice_loss: 0.0248 - val_loss: 0.2985 - val_weighted_dice_loss: 0.2985

Epoch 00034: val_weighted_dice_loss did not improve from 0.23707
Epoch 35/150
 - 1583s - loss: 0.0241 - weighted_dice_loss: 0.0241 - val_loss: 0.2635 - val_weighted_dice_loss: 0.2635

Epoch 00035: val_weighted_dice_loss did not improve from 0.23707
Epoch 36/150
 - 1582s - loss: 0.0239 - weighted_dice_loss: 0.0239 - val_loss: 0.2835 - val_weighted_dice_loss: 0.2835

Epoch 00036: val_weighted_dice_loss did not improve from 0.23707
Epoch 37/150
 - 1583s - loss: 0.0235 - weighted_dice_loss: 0.0235 - val_loss: 0.2783 - val_weighted_dice_loss: 0.2783

Epoch 00037: val_weighted_dice_loss did not improve from 0.23707
Epoch 38/150
 - 1582s - loss: 0.0233 - weighted_dice_loss: 0.0233 - val_loss: 0.3057 - val_weighted_dice_loss: 0.3057

Epoch 00038: val_weighted_dice_loss did not improve from 0.23707
Epoch 39/150
 - 1583s - loss: 0.0226 - weighted_dice_loss: 0.0226 - val_loss: 0.2782 - val_weighted_dice_loss: 0.2782

Epoch 00039: val_weighted_dice_loss did not improve from 0.23707
Epoch 40/150
 - 1584s - loss: 0.0226 - weighted_dice_loss: 0.0226 - val_loss: 0.3019 - val_weighted_dice_loss: 0.3019

Epoch 00040: val_weighted_dice_loss did not improve from 0.23707
Epoch 41/150
 - 1584s - loss: 0.0222 - weighted_dice_loss: 0.0222 - val_loss: 0.2793 - val_weighted_dice_loss: 0.2793

Epoch 00041: val_weighted_dice_loss did not improve from 0.23707
Epoch 42/150
 - 1579s - loss: 0.0220 - weighted_dice_loss: 0.0220 - val_loss: 0.2624 - val_weighted_dice_loss: 0.2624

Epoch 00042: val_weighted_dice_loss did not improve from 0.23707
Epoch 43/150
 - 1581s - loss: 0.0218 - weighted_dice_loss: 0.0218 - val_loss: 0.2773 - val_weighted_dice_loss: 0.2773

Epoch 00043: val_weighted_dice_loss did not improve from 0.23707
Epoch 44/150
 - 1582s - loss: 0.0213 - weighted_dice_loss: 0.0213 - val_loss: 0.2770 - val_weighted_dice_loss: 0.2770

Epoch 00044: val_weighted_dice_loss did not improve from 0.23707
Epoch 45/150
 - 1583s - loss: 0.0210 - weighted_dice_loss: 0.0210 - val_loss: 0.2733 - val_weighted_dice_loss: 0.2733

Epoch 00045: val_weighted_dice_loss did not improve from 0.23707
Epoch 46/150
 - 1584s - loss: 0.0209 - weighted_dice_loss: 0.0209 - val_loss: 0.2766 - val_weighted_dice_loss: 0.2766

Epoch 00046: val_weighted_dice_loss did not improve from 0.23707
Epoch 47/150
 - 1577s - loss: 0.0205 - weighted_dice_loss: 0.0205 - val_loss: 0.2727 - val_weighted_dice_loss: 0.2727

Epoch 00047: val_weighted_dice_loss did not improve from 0.23707
Epoch 48/150
 - 1580s - loss: 0.0204 - weighted_dice_loss: 0.0204 - val_loss: 0.2747 - val_weighted_dice_loss: 0.2747

Epoch 00048: val_weighted_dice_loss did not improve from 0.23707
Epoch 49/150
 - 1582s - loss: 0.0203 - weighted_dice_loss: 0.0203 - val_loss: 0.2573 - val_weighted_dice_loss: 0.2573

Epoch 00049: val_weighted_dice_loss did not improve from 0.23707
Epoch 50/150
 - 1582s - loss: 0.0198 - weighted_dice_loss: 0.0198 - val_loss: 0.2660 - val_weighted_dice_loss: 0.2660

Epoch 00050: val_weighted_dice_loss did not improve from 0.23707
Epoch 51/150
 - 1585s - loss: 0.0197 - weighted_dice_loss: 0.0197 - val_loss: 0.2709 - val_weighted_dice_loss: 0.2709

Epoch 00051: val_weighted_dice_loss did not improve from 0.23707
Epoch 52/150
 - 1578s - loss: 0.0195 - weighted_dice_loss: 0.0195 - val_loss: 0.2652 - val_weighted_dice_loss: 0.2652

Epoch 00052: val_weighted_dice_loss did not improve from 0.23707
Epoch 53/150
 - 1580s - loss: 0.0192 - weighted_dice_loss: 0.0192 - val_loss: 0.2793 - val_weighted_dice_loss: 0.2793

Epoch 00053: val_weighted_dice_loss did not improve from 0.23707
Epoch 54/150
 - 1586s - loss: 0.0189 - weighted_dice_loss: 0.0189 - val_loss: 0.2968 - val_weighted_dice_loss: 0.2968

Epoch 00054: val_weighted_dice_loss did not improve from 0.23707
Epoch 55/150
 - 1579s - loss: 0.0188 - weighted_dice_loss: 0.0188 - val_loss: 0.2651 - val_weighted_dice_loss: 0.2651

Epoch 00055: val_weighted_dice_loss did not improve from 0.23707
Epoch 56/150
 - 1582s - loss: 0.0187 - weighted_dice_loss: 0.0187 - val_loss: 0.2443 - val_weighted_dice_loss: 0.2443

Epoch 00056: val_weighted_dice_loss did not improve from 0.23707
Epoch 57/150
 - 1580s - loss: 0.0184 - weighted_dice_loss: 0.0184 - val_loss: 0.2936 - val_weighted_dice_loss: 0.2936

Epoch 00057: val_weighted_dice_loss did not improve from 0.23707
Epoch 58/150
 - 1582s - loss: 0.0183 - weighted_dice_loss: 0.0183 - val_loss: 0.2785 - val_weighted_dice_loss: 0.2785

Epoch 00058: val_weighted_dice_loss did not improve from 0.23707
Epoch 59/150
 - 1591s - loss: 0.0180 - weighted_dice_loss: 0.0180 - val_loss: 0.2897 - val_weighted_dice_loss: 0.2897

Epoch 00059: val_weighted_dice_loss did not improve from 0.23707
Epoch 60/150
 - 1580s - loss: 0.0179 - weighted_dice_loss: 0.0179 - val_loss: 0.2691 - val_weighted_dice_loss: 0.2691

Epoch 00060: val_weighted_dice_loss did not improve from 0.23707
Epoch 61/150
 - 1589s - loss: 0.0177 - weighted_dice_loss: 0.0177 - val_loss: 0.2731 - val_weighted_dice_loss: 0.2731

Epoch 00061: val_weighted_dice_loss did not improve from 0.23707
Epoch 62/150
 - 1582s - loss: 0.0175 - weighted_dice_loss: 0.0175 - val_loss: 0.2611 - val_weighted_dice_loss: 0.2611

Epoch 00062: val_weighted_dice_loss did not improve from 0.23707
Epoch 63/150
 - 1603s - loss: 0.0175 - weighted_dice_loss: 0.0175 - val_loss: 0.2784 - val_weighted_dice_loss: 0.2784

Epoch 00063: val_weighted_dice_loss did not improve from 0.23707
Epoch 64/150
 - 1583s - loss: 0.0172 - weighted_dice_loss: 0.0172 - val_loss: 0.2892 - val_weighted_dice_loss: 0.2892

Epoch 00064: val_weighted_dice_loss did not improve from 0.23707
Epoch 65/150
 - 1583s - loss: 0.0170 - weighted_dice_loss: 0.0170 - val_loss: 0.2712 - val_weighted_dice_loss: 0.2712

Epoch 00065: val_weighted_dice_loss did not improve from 0.23707
Epoch 66/150
 - 1580s - loss: 0.0169 - weighted_dice_loss: 0.0169 - val_loss: 0.2828 - val_weighted_dice_loss: 0.2828

Epoch 00066: val_weighted_dice_loss did not improve from 0.23707
Epoch 67/150
 - 1585s - loss: 0.0168 - weighted_dice_loss: 0.0168 - val_loss: 0.2729 - val_weighted_dice_loss: 0.2729

Epoch 00067: val_weighted_dice_loss did not improve from 0.23707
Epoch 68/150
 - 1580s - loss: 0.0166 - weighted_dice_loss: 0.0166 - val_loss: 0.2905 - val_weighted_dice_loss: 0.2905

Epoch 00068: val_weighted_dice_loss did not improve from 0.23707
Epoch 69/150
 - 1579s - loss: 0.0166 - weighted_dice_loss: 0.0166 - val_loss: 0.2938 - val_weighted_dice_loss: 0.2938

Epoch 00069: val_weighted_dice_loss did not improve from 0.23707
Epoch 70/150
 - 1583s - loss: 0.0164 - weighted_dice_loss: 0.0164 - val_loss: 0.3017 - val_weighted_dice_loss: 0.3017

Epoch 00070: val_weighted_dice_loss did not improve from 0.23707
Epoch 71/150
 - 1578s - loss: 0.0162 - weighted_dice_loss: 0.0162 - val_loss: 0.2625 - val_weighted_dice_loss: 0.2625

Epoch 00071: val_weighted_dice_loss did not improve from 0.23707
Epoch 72/150
 - 1582s - loss: 0.0161 - weighted_dice_loss: 0.0161 - val_loss: 0.2896 - val_weighted_dice_loss: 0.2896

Epoch 00072: val_weighted_dice_loss did not improve from 0.23707
Epoch 73/150
 - 1584s - loss: 0.0160 - weighted_dice_loss: 0.0160 - val_loss: 0.2866 - val_weighted_dice_loss: 0.2866

Epoch 00073: val_weighted_dice_loss did not improve from 0.23707
Epoch 74/150
 - 1582s - loss: 0.0159 - weighted_dice_loss: 0.0159 - val_loss: 0.2885 - val_weighted_dice_loss: 0.2885

Epoch 00074: val_weighted_dice_loss did not improve from 0.23707
Epoch 75/150
 - 1581s - loss: 0.0158 - weighted_dice_loss: 0.0158 - val_loss: 0.2564 - val_weighted_dice_loss: 0.2564

Epoch 00075: val_weighted_dice_loss did not improve from 0.23707
Epoch 76/150
 - 1590s - loss: 0.0156 - weighted_dice_loss: 0.0156 - val_loss: 0.2592 - val_weighted_dice_loss: 0.2592

Epoch 00076: val_weighted_dice_loss did not improve from 0.23707
Epoch 77/150
 - 1589s - loss: 0.0155 - weighted_dice_loss: 0.0155 - val_loss: 0.2584 - val_weighted_dice_loss: 0.2584

Epoch 00077: val_weighted_dice_loss did not improve from 0.23707
Epoch 78/150
 - 1586s - loss: 0.0154 - weighted_dice_loss: 0.0154 - val_loss: 0.2857 - val_weighted_dice_loss: 0.2857

Epoch 00078: val_weighted_dice_loss did not improve from 0.23707
Epoch 79/150
 - 1587s - loss: 0.0153 - weighted_dice_loss: 0.0153 - val_loss: 0.2757 - val_weighted_dice_loss: 0.2757

Epoch 00079: val_weighted_dice_loss did not improve from 0.23707
Epoch 80/150
 - 1586s - loss: 0.0153 - weighted_dice_loss: 0.0153 - val_loss: 0.2860 - val_weighted_dice_loss: 0.2860

Epoch 00080: val_weighted_dice_loss did not improve from 0.23707
Epoch 81/150
 - 1588s - loss: 0.0150 - weighted_dice_loss: 0.0150 - val_loss: 0.2732 - val_weighted_dice_loss: 0.2732

Epoch 00081: val_weighted_dice_loss did not improve from 0.23707
Epoch 82/150
 - 1588s - loss: 0.0150 - weighted_dice_loss: 0.0150 - val_loss: 0.2885 - val_weighted_dice_loss: 0.2885

Epoch 00082: val_weighted_dice_loss did not improve from 0.23707
Epoch 83/150
 - 1587s - loss: 0.0149 - weighted_dice_loss: 0.0149 - val_loss: 0.2702 - val_weighted_dice_loss: 0.2702

Epoch 00083: val_weighted_dice_loss did not improve from 0.23707
Epoch 84/150
 - 1583s - loss: 0.0148 - weighted_dice_loss: 0.0148 - val_loss: 0.2600 - val_weighted_dice_loss: 0.2600

Epoch 00084: val_weighted_dice_loss did not improve from 0.23707
Epoch 85/150
 - 1585s - loss: 0.0147 - weighted_dice_loss: 0.0147 - val_loss: 0.2760 - val_weighted_dice_loss: 0.2760

Epoch 00085: val_weighted_dice_loss did not improve from 0.23707
Epoch 86/150
 - 1585s - loss: 0.0145 - weighted_dice_loss: 0.0145 - val_loss: 0.2592 - val_weighted_dice_loss: 0.2592

Epoch 00086: val_weighted_dice_loss did not improve from 0.23707
Epoch 87/150
 - 1583s - loss: 0.0145 - weighted_dice_loss: 0.0145 - val_loss: 0.2614 - val_weighted_dice_loss: 0.2614

Epoch 00087: val_weighted_dice_loss did not improve from 0.23707
Epoch 88/150
 - 1584s - loss: 0.0144 - weighted_dice_loss: 0.0144 - val_loss: 0.2731 - val_weighted_dice_loss: 0.2731

Epoch 00088: val_weighted_dice_loss did not improve from 0.23707
Epoch 89/150
 - 1585s - loss: 0.0143 - weighted_dice_loss: 0.0143 - val_loss: 0.2803 - val_weighted_dice_loss: 0.2803

Epoch 00089: val_weighted_dice_loss did not improve from 0.23707
Epoch 90/150
 - 1586s - loss: 0.0142 - weighted_dice_loss: 0.0142 - val_loss: 0.2778 - val_weighted_dice_loss: 0.2778

Epoch 00090: val_weighted_dice_loss did not improve from 0.23707
Epoch 91/150
 - 1587s - loss: 0.0141 - weighted_dice_loss: 0.0141 - val_loss: 0.2735 - val_weighted_dice_loss: 0.2735

Epoch 00091: val_weighted_dice_loss did not improve from 0.23707
Epoch 92/150
 - 1587s - loss: 0.0140 - weighted_dice_loss: 0.0140 - val_loss: 0.2807 - val_weighted_dice_loss: 0.2807

Epoch 00092: val_weighted_dice_loss did not improve from 0.23707
Epoch 93/150
 - 1588s - loss: 0.0139 - weighted_dice_loss: 0.0139 - val_loss: 0.2844 - val_weighted_dice_loss: 0.2844

Epoch 00093: val_weighted_dice_loss did not improve from 0.23707
Epoch 94/150
 - 1584s - loss: 0.0139 - weighted_dice_loss: 0.0139 - val_loss: 0.2586 - val_weighted_dice_loss: 0.2586

Epoch 00094: val_weighted_dice_loss did not improve from 0.23707
Epoch 95/150
 - 1587s - loss: 0.0138 - weighted_dice_loss: 0.0138 - val_loss: 0.2512 - val_weighted_dice_loss: 0.2512

Epoch 00095: val_weighted_dice_loss did not improve from 0.23707
Epoch 96/150
 - 1584s - loss: 0.0136 - weighted_dice_loss: 0.0136 - val_loss: 0.2820 - val_weighted_dice_loss: 0.2820

Epoch 00096: val_weighted_dice_loss did not improve from 0.23707
Epoch 97/150
 - 1584s - loss: 0.0135 - weighted_dice_loss: 0.0135 - val_loss: 0.2861 - val_weighted_dice_loss: 0.2861

Epoch 00097: val_weighted_dice_loss did not improve from 0.23707
Epoch 98/150
 - 1585s - loss: 0.0135 - weighted_dice_loss: 0.0135 - val_loss: 0.2721 - val_weighted_dice_loss: 0.2721

Epoch 00098: val_weighted_dice_loss did not improve from 0.23707
Epoch 99/150
 - 1585s - loss: 0.0134 - weighted_dice_loss: 0.0134 - val_loss: 0.2674 - val_weighted_dice_loss: 0.2674

Epoch 00099: val_weighted_dice_loss did not improve from 0.23707
Epoch 100/150
 - 1586s - loss: 0.0133 - weighted_dice_loss: 0.0133 - val_loss: 0.2474 - val_weighted_dice_loss: 0.2474

Epoch 00100: val_weighted_dice_loss did not improve from 0.23707
Epoch 101/150
 - 1586s - loss: 0.0133 - weighted_dice_loss: 0.0133 - val_loss: 0.2750 - val_weighted_dice_loss: 0.2750

Epoch 00101: val_weighted_dice_loss did not improve from 0.23707
Epoch 102/150
 - 1586s - loss: 0.0132 - weighted_dice_loss: 0.0132 - val_loss: 0.2677 - val_weighted_dice_loss: 0.2677

Epoch 00102: val_weighted_dice_loss did not improve from 0.23707
Epoch 103/150
 - 1588s - loss: 0.0131 - weighted_dice_loss: 0.0131 - val_loss: 0.2761 - val_weighted_dice_loss: 0.2761

Epoch 00103: val_weighted_dice_loss did not improve from 0.23707
Epoch 104/150
 - 1585s - loss: 0.0130 - weighted_dice_loss: 0.0130 - val_loss: 0.2743 - val_weighted_dice_loss: 0.2743

Epoch 00104: val_weighted_dice_loss did not improve from 0.23707
Epoch 105/150
 - 1585s - loss: 0.0130 - weighted_dice_loss: 0.0130 - val_loss: 0.2670 - val_weighted_dice_loss: 0.2670

Epoch 00105: val_weighted_dice_loss did not improve from 0.23707
Epoch 106/150
 - 1585s - loss: 0.0128 - weighted_dice_loss: 0.0128 - val_loss: 0.2604 - val_weighted_dice_loss: 0.2604

Epoch 00106: val_weighted_dice_loss did not improve from 0.23707
Epoch 107/150
 - 1586s - loss: 0.0128 - weighted_dice_loss: 0.0128 - val_loss: 0.2627 - val_weighted_dice_loss: 0.2627

Epoch 00107: val_weighted_dice_loss did not improve from 0.23707
Epoch 108/150
 - 1583s - loss: 0.0127 - weighted_dice_loss: 0.0127 - val_loss: 0.2726 - val_weighted_dice_loss: 0.2726

Epoch 00108: val_weighted_dice_loss did not improve from 0.23707
Epoch 109/150
 - 1588s - loss: 0.0127 - weighted_dice_loss: 0.0127 - val_loss: 0.2604 - val_weighted_dice_loss: 0.2604

Epoch 00109: val_weighted_dice_loss did not improve from 0.23707
Epoch 110/150
 - 1583s - loss: 0.0126 - weighted_dice_loss: 0.0126 - val_loss: 0.2722 - val_weighted_dice_loss: 0.2722

Epoch 00110: val_weighted_dice_loss did not improve from 0.23707
Epoch 111/150
 - 1590s - loss: 0.0125 - weighted_dice_loss: 0.0125 - val_loss: 0.2761 - val_weighted_dice_loss: 0.2761

Epoch 00111: val_weighted_dice_loss did not improve from 0.23707
Epoch 112/150
 - 1584s - loss: 0.0124 - weighted_dice_loss: 0.0124 - val_loss: 0.2794 - val_weighted_dice_loss: 0.2794

Epoch 00112: val_weighted_dice_loss did not improve from 0.23707
Epoch 113/150
 - 1584s - loss: 0.0124 - weighted_dice_loss: 0.0124 - val_loss: 0.2805 - val_weighted_dice_loss: 0.2805

Epoch 00113: val_weighted_dice_loss did not improve from 0.23707
Epoch 114/150
 - 1588s - loss: 0.0123 - weighted_dice_loss: 0.0123 - val_loss: 0.2755 - val_weighted_dice_loss: 0.2755

Epoch 00114: val_weighted_dice_loss did not improve from 0.23707
Epoch 115/150
 - 1587s - loss: 0.0122 - weighted_dice_loss: 0.0122 - val_loss: 0.2670 - val_weighted_dice_loss: 0.2670

Epoch 00115: val_weighted_dice_loss did not improve from 0.23707
Epoch 116/150
 - 1579s - loss: 0.0122 - weighted_dice_loss: 0.0122 - val_loss: 0.2851 - val_weighted_dice_loss: 0.2851

Epoch 00116: val_weighted_dice_loss did not improve from 0.23707
Epoch 117/150
 - 1584s - loss: 0.0121 - weighted_dice_loss: 0.0121 - val_loss: 0.2819 - val_weighted_dice_loss: 0.2819

Epoch 00117: val_weighted_dice_loss did not improve from 0.23707
Epoch 118/150
 - 1583s - loss: 0.0121 - weighted_dice_loss: 0.0121 - val_loss: 0.2848 - val_weighted_dice_loss: 0.2848

Epoch 00118: val_weighted_dice_loss did not improve from 0.23707
Epoch 119/150
 - 1584s - loss: 0.0120 - weighted_dice_loss: 0.0120 - val_loss: 0.2778 - val_weighted_dice_loss: 0.2778

Epoch 00119: val_weighted_dice_loss did not improve from 0.23707
Epoch 120/150
 - 1583s - loss: 0.0120 - weighted_dice_loss: 0.0120 - val_loss: 0.2981 - val_weighted_dice_loss: 0.2981

Epoch 00120: val_weighted_dice_loss did not improve from 0.23707
Epoch 121/150
 - 1584s - loss: 0.0119 - weighted_dice_loss: 0.0119 - val_loss: 0.2725 - val_weighted_dice_loss: 0.2725

Epoch 00121: val_weighted_dice_loss did not improve from 0.23707
Epoch 122/150
 - 1586s - loss: 0.0118 - weighted_dice_loss: 0.0118 - val_loss: 0.2688 - val_weighted_dice_loss: 0.2688

Epoch 00122: val_weighted_dice_loss did not improve from 0.23707
Epoch 123/150
 - 1586s - loss: 0.0118 - weighted_dice_loss: 0.0118 - val_loss: 0.2945 - val_weighted_dice_loss: 0.2945

Epoch 00123: val_weighted_dice_loss did not improve from 0.23707
Epoch 124/150
 - 1584s - loss: 0.0117 - weighted_dice_loss: 0.0117 - val_loss: 0.2822 - val_weighted_dice_loss: 0.2822

Epoch 00124: val_weighted_dice_loss did not improve from 0.23707
Epoch 125/150
 - 1582s - loss: 0.0117 - weighted_dice_loss: 0.0117 - val_loss: 0.2729 - val_weighted_dice_loss: 0.2729

Epoch 00125: val_weighted_dice_loss did not improve from 0.23707
Epoch 126/150
 - 1586s - loss: 0.0116 - weighted_dice_loss: 0.0116 - val_loss: 0.2784 - val_weighted_dice_loss: 0.2784

Epoch 00126: val_weighted_dice_loss did not improve from 0.23707
Epoch 127/150
 - 1585s - loss: 0.0115 - weighted_dice_loss: 0.0115 - val_loss: 0.2722 - val_weighted_dice_loss: 0.2722

Epoch 00127: val_weighted_dice_loss did not improve from 0.23707
Epoch 128/150
 - 1585s - loss: 0.0114 - weighted_dice_loss: 0.0114 - val_loss: 0.2800 - val_weighted_dice_loss: 0.2800

Epoch 00128: val_weighted_dice_loss did not improve from 0.23707
Epoch 129/150
 - 1589s - loss: 0.0115 - weighted_dice_loss: 0.0115 - val_loss: 0.2868 - val_weighted_dice_loss: 0.2868

Epoch 00129: val_weighted_dice_loss did not improve from 0.23707
Epoch 130/150
 - 1587s - loss: 0.0113 - weighted_dice_loss: 0.0113 - val_loss: 0.2744 - val_weighted_dice_loss: 0.2744

Epoch 00130: val_weighted_dice_loss did not improve from 0.23707
Epoch 131/150
 - 1583s - loss: 0.0113 - weighted_dice_loss: 0.0113 - val_loss: 0.2738 - val_weighted_dice_loss: 0.2738

Epoch 00131: val_weighted_dice_loss did not improve from 0.23707
Epoch 132/150
 - 1585s - loss: 0.0113 - weighted_dice_loss: 0.0113 - val_loss: 0.2729 - val_weighted_dice_loss: 0.2729

Epoch 00132: val_weighted_dice_loss did not improve from 0.23707
Epoch 133/150
 - 1584s - loss: 0.0112 - weighted_dice_loss: 0.0112 - val_loss: 0.2784 - val_weighted_dice_loss: 0.2784

Epoch 00133: val_weighted_dice_loss did not improve from 0.23707
Epoch 134/150
 - 1583s - loss: 0.0111 - weighted_dice_loss: 0.0111 - val_loss: 0.2816 - val_weighted_dice_loss: 0.2816

Epoch 00134: val_weighted_dice_loss did not improve from 0.23707
Epoch 135/150
 - 1585s - loss: 0.0111 - weighted_dice_loss: 0.0111 - val_loss: 0.2797 - val_weighted_dice_loss: 0.2797

Epoch 00135: val_weighted_dice_loss did not improve from 0.23707
Epoch 136/150
 - 1587s - loss: 0.0110 - weighted_dice_loss: 0.0110 - val_loss: 0.2751 - val_weighted_dice_loss: 0.2751

Epoch 00136: val_weighted_dice_loss did not improve from 0.23707
Epoch 137/150
 - 1585s - loss: 0.0110 - weighted_dice_loss: 0.0110 - val_loss: 0.2839 - val_weighted_dice_loss: 0.2839

Epoch 00137: val_weighted_dice_loss did not improve from 0.23707
Epoch 138/150
 - 1583s - loss: 0.0110 - weighted_dice_loss: 0.0110 - val_loss: 0.2740 - val_weighted_dice_loss: 0.2740

Epoch 00138: val_weighted_dice_loss did not improve from 0.23707
Epoch 139/150
 - 1583s - loss: 0.0109 - weighted_dice_loss: 0.0109 - val_loss: 0.2873 - val_weighted_dice_loss: 0.2873

Epoch 00139: val_weighted_dice_loss did not improve from 0.23707
Epoch 140/150
 - 1584s - loss: 0.0109 - weighted_dice_loss: 0.0109 - val_loss: 0.2816 - val_weighted_dice_loss: 0.2816

Epoch 00140: val_weighted_dice_loss did not improve from 0.23707
Epoch 141/150
 - 1582s - loss: 0.0108 - weighted_dice_loss: 0.0108 - val_loss: 0.2740 - val_weighted_dice_loss: 0.2740

Epoch 00141: val_weighted_dice_loss did not improve from 0.23707
Epoch 142/150
 - 1584s - loss: 0.0108 - weighted_dice_loss: 0.0108 - val_loss: 0.2791 - val_weighted_dice_loss: 0.2791

Epoch 00142: val_weighted_dice_loss did not improve from 0.23707
Epoch 143/150
 - 1584s - loss: 0.0107 - weighted_dice_loss: 0.0107 - val_loss: 0.2827 - val_weighted_dice_loss: 0.2827

Epoch 00143: val_weighted_dice_loss did not improve from 0.23707
Epoch 144/150
 - 1583s - loss: 0.0107 - weighted_dice_loss: 0.0107 - val_loss: 0.2746 - val_weighted_dice_loss: 0.2746

Epoch 00144: val_weighted_dice_loss did not improve from 0.23707
Epoch 145/150
 - 1586s - loss: 0.0107 - weighted_dice_loss: 0.0107 - val_loss: 0.2673 - val_weighted_dice_loss: 0.2673

Epoch 00145: val_weighted_dice_loss did not improve from 0.23707
Epoch 146/150
 - 1585s - loss: 0.0106 - weighted_dice_loss: 0.0106 - val_loss: 0.2674 - val_weighted_dice_loss: 0.2674

Epoch 00146: val_weighted_dice_loss did not improve from 0.23707
Epoch 147/150
 - 1583s - loss: 0.0106 - weighted_dice_loss: 0.0106 - val_loss: 0.2836 - val_weighted_dice_loss: 0.2836

Epoch 00147: val_weighted_dice_loss did not improve from 0.23707
Epoch 148/150
 - 1586s - loss: 0.0105 - weighted_dice_loss: 0.0105 - val_loss: 0.2903 - val_weighted_dice_loss: 0.2903

Epoch 00148: val_weighted_dice_loss did not improve from 0.23707
Epoch 149/150
 - 1585s - loss: 0.0105 - weighted_dice_loss: 0.0105 - val_loss: 0.2864 - val_weighted_dice_loss: 0.2864

Epoch 00149: val_weighted_dice_loss did not improve from 0.23707
Epoch 150/150
 - 1592s - loss: 0.0104 - weighted_dice_loss: 0.0104 - val_loss: 0.2800 - val_weighted_dice_loss: 0.2800

Epoch 00150: val_weighted_dice_loss did not improve from 0.23707
Finished training.
