2020-05-20 17:18:45.521352: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-05-20 17:18:45.533803: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz
2020-05-20 17:18:45.534266: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5566dbf93b00 executing computations on platform Host. Devices:
2020-05-20 17:18:45.534300: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-05-20 17:18:45.534918: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-05-20 17:18:45.681478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.681884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-05-20 17:18:45.681925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.682197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-05-20 17:18:45.683818: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 17:18:45.687886: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-05-20 17:18:45.690331: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-05-20 17:18:45.692016: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-05-20 17:18:45.694416: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-05-20 17:18:45.696372: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-05-20 17:18:45.699958: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-20 17:18:45.700031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.700411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.700713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.701047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.701320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-20 17:18:45.701337: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 17:18:45.702176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-20 17:18:45.702185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-20 17:18:45.702192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-05-20 17:18:45.702200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-05-20 17:18:45.702273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.702616: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.702911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.703248: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.703580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-05-20 17:18:45.703888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.704186: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.704461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7507 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-05-20 17:18:45.705845: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5566dd2d64d0 executing computations on platform CUDA. Devices:
2020-05-20 17:18:45.705858: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-05-20 17:18:45.705862: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From segmentation.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

WARNING:tensorflow:From segmentation.py:33: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From segmentation.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-05-20 17:18:45.706658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.706986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-05-20 17:18:45.707022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.707294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-05-20 17:18:45.707311: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-20 17:18:45.707320: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-05-20 17:18:45.707327: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-05-20 17:18:45.707335: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-05-20 17:18:45.707342: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-05-20 17:18:45.707352: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-05-20 17:18:45.707360: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-20 17:18:45.707389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.707727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.708018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.708349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.708620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-20 17:18:45.708637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-20 17:18:45.708643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-20 17:18:45.708647: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-05-20 17:18:45.708650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-05-20 17:18:45.708704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.709592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.709887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.710201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-05-20 17:18:45.710236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-20 17:18:45.710508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7507 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-05-20 17:19:26.388287: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
Epoch 1/150
 - 1009s - loss: 0.5175 - weighted_dice_loss: 0.5193 - val_loss: 0.4044 - val_weighted_dice_loss: 0.4068

Epoch 00001: val_weighted_dice_loss improved from inf to 0.40679, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 2/150
 - 969s - loss: 0.3933 - weighted_dice_loss: 0.3955 - val_loss: 0.3825 - val_weighted_dice_loss: 0.3848

Epoch 00002: val_weighted_dice_loss improved from 0.40679 to 0.38485, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 3/150
 - 970s - loss: 0.3612 - weighted_dice_loss: 0.3633 - val_loss: 0.3568 - val_weighted_dice_loss: 0.3589

Epoch 00003: val_weighted_dice_loss improved from 0.38485 to 0.35894, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 4/150
 - 971s - loss: 0.3497 - weighted_dice_loss: 0.3517 - val_loss: 0.3566 - val_weighted_dice_loss: 0.3588

Epoch 00004: val_weighted_dice_loss improved from 0.35894 to 0.35882, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 5/150
 - 970s - loss: 0.3432 - weighted_dice_loss: 0.3452 - val_loss: 0.4731 - val_weighted_dice_loss: 0.4760

Epoch 00005: val_weighted_dice_loss did not improve from 0.35882
Epoch 6/150
 - 970s - loss: 0.3358 - weighted_dice_loss: 0.3378 - val_loss: 0.3340 - val_weighted_dice_loss: 0.3361

Epoch 00006: val_weighted_dice_loss improved from 0.35882 to 0.33605, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 7/150
 - 970s - loss: 0.3326 - weighted_dice_loss: 0.3345 - val_loss: 0.3337 - val_weighted_dice_loss: 0.3357

Epoch 00007: val_weighted_dice_loss improved from 0.33605 to 0.33570, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 8/150
 - 970s - loss: 0.3272 - weighted_dice_loss: 0.3291 - val_loss: 0.3245 - val_weighted_dice_loss: 0.3265

Epoch 00008: val_weighted_dice_loss improved from 0.33570 to 0.32653, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 9/150
 - 970s - loss: 0.3235 - weighted_dice_loss: 0.3253 - val_loss: 0.4210 - val_weighted_dice_loss: 0.4243

Epoch 00009: val_weighted_dice_loss did not improve from 0.32653
Epoch 10/150
 - 970s - loss: 0.3205 - weighted_dice_loss: 0.3224 - val_loss: 0.3348 - val_weighted_dice_loss: 0.3368

Epoch 00010: val_weighted_dice_loss did not improve from 0.32653
Epoch 11/150
 - 970s - loss: 0.3175 - weighted_dice_loss: 0.3193 - val_loss: 0.3267 - val_weighted_dice_loss: 0.3289

Epoch 00011: val_weighted_dice_loss did not improve from 0.32653
Epoch 12/150
 - 970s - loss: 0.3144 - weighted_dice_loss: 0.3162 - val_loss: 0.3239 - val_weighted_dice_loss: 0.3259

Epoch 00012: val_weighted_dice_loss improved from 0.32653 to 0.32587, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 13/150
 - 970s - loss: 0.3108 - weighted_dice_loss: 0.3126 - val_loss: 0.3123 - val_weighted_dice_loss: 0.3142

Epoch 00013: val_weighted_dice_loss improved from 0.32587 to 0.31418, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 14/150
 - 970s - loss: 0.3096 - weighted_dice_loss: 0.3113 - val_loss: 0.3982 - val_weighted_dice_loss: 0.4000

Epoch 00014: val_weighted_dice_loss did not improve from 0.31418
Epoch 15/150
 - 970s - loss: 0.3066 - weighted_dice_loss: 0.3083 - val_loss: 0.3316 - val_weighted_dice_loss: 0.3338

Epoch 00015: val_weighted_dice_loss did not improve from 0.31418
Epoch 16/150
 - 969s - loss: 0.3052 - weighted_dice_loss: 0.3069 - val_loss: 0.3580 - val_weighted_dice_loss: 0.3600

Epoch 00016: val_weighted_dice_loss did not improve from 0.31418
Epoch 17/150
 - 970s - loss: 0.3024 - weighted_dice_loss: 0.3041 - val_loss: 0.3093 - val_weighted_dice_loss: 0.3112

Epoch 00017: val_weighted_dice_loss improved from 0.31418 to 0.31125, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 18/150
 - 970s - loss: 0.3014 - weighted_dice_loss: 0.3031 - val_loss: 0.3101 - val_weighted_dice_loss: 0.3120

Epoch 00018: val_weighted_dice_loss did not improve from 0.31125
Epoch 19/150
 - 970s - loss: 0.2991 - weighted_dice_loss: 0.3007 - val_loss: 0.3238 - val_weighted_dice_loss: 0.3259

Epoch 00019: val_weighted_dice_loss did not improve from 0.31125
Epoch 20/150
 - 970s - loss: 0.2974 - weighted_dice_loss: 0.2991 - val_loss: 0.3037 - val_weighted_dice_loss: 0.3056

Epoch 00020: val_weighted_dice_loss improved from 0.31125 to 0.30555, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 21/150
 - 970s - loss: 0.2954 - weighted_dice_loss: 0.2970 - val_loss: 0.3033 - val_weighted_dice_loss: 0.3051

Epoch 00021: val_weighted_dice_loss improved from 0.30555 to 0.30506, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 22/150
 - 970s - loss: 0.2946 - weighted_dice_loss: 0.2962 - val_loss: 0.2988 - val_weighted_dice_loss: 0.3006

Epoch 00022: val_weighted_dice_loss improved from 0.30506 to 0.30062, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 23/150
 - 970s - loss: 0.2929 - weighted_dice_loss: 0.2945 - val_loss: 0.2985 - val_weighted_dice_loss: 0.3002

Epoch 00023: val_weighted_dice_loss improved from 0.30062 to 0.30021, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 24/150
 - 970s - loss: 0.2913 - weighted_dice_loss: 0.2929 - val_loss: 0.2991 - val_weighted_dice_loss: 0.3009

Epoch 00024: val_weighted_dice_loss did not improve from 0.30021
Epoch 25/150
 - 970s - loss: 0.2903 - weighted_dice_loss: 0.2919 - val_loss: 0.3063 - val_weighted_dice_loss: 0.3081

Epoch 00025: val_weighted_dice_loss did not improve from 0.30021
Epoch 26/150
 - 970s - loss: 0.2890 - weighted_dice_loss: 0.2906 - val_loss: 0.3418 - val_weighted_dice_loss: 0.3422

Epoch 00026: val_weighted_dice_loss did not improve from 0.30021
Epoch 27/150
 - 970s - loss: 0.2876 - weighted_dice_loss: 0.2892 - val_loss: 0.3141 - val_weighted_dice_loss: 0.3161

Epoch 00027: val_weighted_dice_loss did not improve from 0.30021
Epoch 28/150
 - 970s - loss: 0.2867 - weighted_dice_loss: 0.2883 - val_loss: 0.3118 - val_weighted_dice_loss: 0.3138

Epoch 00028: val_weighted_dice_loss did not improve from 0.30021
Epoch 29/150
 - 970s - loss: 0.2853 - weighted_dice_loss: 0.2869 - val_loss: 0.3033 - val_weighted_dice_loss: 0.3047

Epoch 00029: val_weighted_dice_loss did not improve from 0.30021
Epoch 30/150
 - 971s - loss: 0.2841 - weighted_dice_loss: 0.2856 - val_loss: 0.2955 - val_weighted_dice_loss: 0.2973

Epoch 00030: val_weighted_dice_loss improved from 0.30021 to 0.29726, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 31/150
 - 970s - loss: 0.2834 - weighted_dice_loss: 0.2849 - val_loss: 0.2956 - val_weighted_dice_loss: 0.2974

Epoch 00031: val_weighted_dice_loss did not improve from 0.29726
Epoch 32/150
 - 972s - loss: 0.2821 - weighted_dice_loss: 0.2836 - val_loss: 0.2931 - val_weighted_dice_loss: 0.2949

Epoch 00032: val_weighted_dice_loss improved from 0.29726 to 0.29491, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 33/150
 - 970s - loss: 0.2816 - weighted_dice_loss: 0.2832 - val_loss: 0.2888 - val_weighted_dice_loss: 0.2905

Epoch 00033: val_weighted_dice_loss improved from 0.29491 to 0.29048, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 34/150
 - 970s - loss: 0.2805 - weighted_dice_loss: 0.2820 - val_loss: 0.2893 - val_weighted_dice_loss: 0.2910

Epoch 00034: val_weighted_dice_loss did not improve from 0.29048
Epoch 35/150
 - 971s - loss: 0.2795 - weighted_dice_loss: 0.2810 - val_loss: 0.2952 - val_weighted_dice_loss: 0.2970

Epoch 00035: val_weighted_dice_loss did not improve from 0.29048
Epoch 36/150
 - 970s - loss: 0.2786 - weighted_dice_loss: 0.2801 - val_loss: 0.2910 - val_weighted_dice_loss: 0.2928

Epoch 00036: val_weighted_dice_loss did not improve from 0.29048
Epoch 37/150
 - 970s - loss: 0.2778 - weighted_dice_loss: 0.2793 - val_loss: 0.2898 - val_weighted_dice_loss: 0.2915

Epoch 00037: val_weighted_dice_loss did not improve from 0.29048
Epoch 38/150
 - 970s - loss: 0.2769 - weighted_dice_loss: 0.2784 - val_loss: 0.2957 - val_weighted_dice_loss: 0.2974

Epoch 00038: val_weighted_dice_loss did not improve from 0.29048
Epoch 39/150
 - 971s - loss: 0.2762 - weighted_dice_loss: 0.2777 - val_loss: 0.2865 - val_weighted_dice_loss: 0.2882

Epoch 00039: val_weighted_dice_loss improved from 0.29048 to 0.28818, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 40/150
 - 970s - loss: 0.2755 - weighted_dice_loss: 0.2769 - val_loss: 0.2858 - val_weighted_dice_loss: 0.2874

Epoch 00040: val_weighted_dice_loss improved from 0.28818 to 0.28739, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 41/150
 - 970s - loss: 0.2746 - weighted_dice_loss: 0.2760 - val_loss: 0.2849 - val_weighted_dice_loss: 0.2865

Epoch 00041: val_weighted_dice_loss improved from 0.28739 to 0.28652, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 42/150
 - 970s - loss: 0.2740 - weighted_dice_loss: 0.2754 - val_loss: 0.2919 - val_weighted_dice_loss: 0.2935

Epoch 00042: val_weighted_dice_loss did not improve from 0.28652
Epoch 43/150
 - 971s - loss: 0.2736 - weighted_dice_loss: 0.2750 - val_loss: 0.2968 - val_weighted_dice_loss: 0.2986

Epoch 00043: val_weighted_dice_loss did not improve from 0.28652
Epoch 44/150
 - 970s - loss: 0.2725 - weighted_dice_loss: 0.2740 - val_loss: 0.2833 - val_weighted_dice_loss: 0.2850

Epoch 00044: val_weighted_dice_loss improved from 0.28652 to 0.28496, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 45/150
 - 970s - loss: 0.2720 - weighted_dice_loss: 0.2735 - val_loss: 0.2797 - val_weighted_dice_loss: 0.2813

Epoch 00045: val_weighted_dice_loss improved from 0.28496 to 0.28126, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_(5k).h5
Epoch 46/150
 - 970s - loss: 0.2714 - weighted_dice_loss: 0.2728 - val_loss: 0.2933 - val_weighted_dice_loss: 0.2950

Epoch 00046: val_weighted_dice_loss did not improve from 0.28126
Epoch 47/150
 - 970s - loss: 0.2710 - weighted_dice_loss: 0.2724 - val_loss: 0.2838 - val_weighted_dice_loss: 0.2853

Epoch 00047: val_weighted_dice_loss did not improve from 0.28126
Epoch 48/150
 - 970s - loss: 0.2705 - weighted_dice_loss: 0.2719 - val_loss: 0.2905 - val_weighted_dice_loss: 0.2922

Epoch 00048: val_weighted_dice_loss did not improve from 0.28126
Epoch 49/150
 - 970s - loss: 0.2697 - weighted_dice_loss: 0.2711 - val_loss: 0.2825 - val_weighted_dice_loss: 0.2841

Epoch 00049: val_weighted_dice_loss did not improve from 0.28126
Epoch 50/150
 - 970s - loss: 0.2694 - weighted_dice_loss: 0.2708 - val_loss: 0.2885 - val_weighted_dice_loss: 0.2902

Epoch 00050: val_weighted_dice_loss did not improve from 0.28126
Epoch 51/150
 - 970s - loss: 0.2687 - weighted_dice_loss: 0.2701 - val_loss: 0.2801 - val_weighted_dice_loss: 0.2817

Epoch 00051: val_weighted_dice_loss did not improve from 0.28126
Epoch 52/150
 - 970s - loss: 0.2682 - weighted_dice_loss: 0.2696 - val_loss: 0.2819 - val_weighted_dice_loss: 0.2835

Epoch 00052: val_weighted_dice_loss did not improve from 0.28126
Epoch 53/150
 - 970s - loss: 0.2675 - weighted_dice_loss: 0.2689 - val_loss: 0.2817 - val_weighted_dice_loss: 0.2833

Epoch 00053: val_weighted_dice_loss did not improve from 0.28126
Epoch 54/150
 - 971s - loss: 0.2668 - weighted_dice_loss: 0.2682 - val_loss: 0.2797 - val_weighted_dice_loss: 0.2813

Epoch 00054: val_weighted_dice_loss did not improve from 0.28126
Epoch 55/150
 - 971s - loss: 0.2667 - weighted_dice_loss: 0.2681 - val_loss: 0.2827 - val_weighted_dice_loss: 0.2843

Epoch 00055: val_weighted_dice_loss did not improve from 0.28126
Epoch 56/150
 - 970s - loss: 0.2662 - weighted_dice_loss: 0.2675 - val_loss: 0.3265 - val_weighted_dice_loss: 0.3284

Epoch 00056: val_weighted_dice_loss did not improve from 0.28126
Epoch 57/150
 - 970s - loss: 0.2652 - weighted_dice_loss: 0.2666 - val_loss: 0.2798 - val_weighted_dice_loss: 0.2814

Epoch 00057: val_weighted_dice_loss did not improve from 0.28126
Epoch 58/150
 - 971s - loss: 0.2652 - weighted_dice_loss: 0.2666 - val_loss: 0.2799 - val_weighted_dice_loss: 0.2815

Epoch 00058: val_weighted_dice_loss did not improve from 0.28126
Epoch 59/150
 - 973s - loss: 0.2645 - weighted_dice_loss: 0.2659 - val_loss: 0.8081 - val_weighted_dice_loss: 0.8104
