nohup: ignoring input
2020-08-21 16:17:49.521621: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX
2020-08-21 16:17:49.548980: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3601770000 Hz
2020-08-21 16:17:49.550282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5625db6766a0 executing computations on platform Host. Devices:
2020-08-21 16:17:49.550336: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-08-21 16:17:49.565361: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-08-21 16:17:49.841125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:49.842561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
2020-08-21 16:17:49.853683: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-08-21 16:17:50.001711: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-08-21 16:17:50.085566: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-08-21 16:17:50.165374: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-08-21 16:17:50.312490: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-08-21 16:17:50.381541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-08-21 16:17:50.694776: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-08-21 16:17:50.695151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.696943: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.698430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-08-21 16:17:50.698541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-08-21 16:17:50.845907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-21 16:17:50.845979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-08-21 16:17:50.846004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-08-21 16:17:50.846245: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.847096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.847916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.848689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-08-21 16:17:50.854374: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5625dc183280 executing computations on platform CUDA. Devices:
2020-08-21 16:17:50.854453: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From segmentation.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

WARNING:tensorflow:From segmentation.py:33: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From segmentation.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-08-21 16:17:50.859004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.860325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7715
pciBusID: 0000:01:00.0
2020-08-21 16:17:50.860408: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-08-21 16:17:50.860468: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-08-21 16:17:50.860520: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-08-21 16:17:50.860570: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-08-21 16:17:50.860619: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-08-21 16:17:50.860667: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-08-21 16:17:50.860716: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-08-21 16:17:50.860890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.862254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.863498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
2020-08-21 16:17:50.863573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-21 16:17:50.863609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-08-21 16:17:50.863635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
2020-08-21 16:17:50.863865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.865239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-08-21 16:17:50.866520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7561 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-08-21 16:27:21.888064: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7

Reading data...
Finished reading data.

Reading data...
Finished reading data.

Training 4 classes with 26040 images (0 real and 26040 GAN images):

Epoch 1/150
 - 1620s - loss: 0.4007 - weighted_dice_loss: 0.4007 - val_loss: 0.4635 - val_weighted_dice_loss: 0.4635

Epoch 00001: val_weighted_dice_loss improved from inf to 0.46352, saving model to ./Unet-weights/4_classes_0_reals_26040_GANs.h5
Epoch 2/150
 - 1576s - loss: 0.2174 - weighted_dice_loss: 0.2174 - val_loss: 0.4955 - val_weighted_dice_loss: 0.4955

Epoch 00002: val_weighted_dice_loss did not improve from 0.46352
Epoch 3/150
 - 1576s - loss: 0.1929 - weighted_dice_loss: 0.1929 - val_loss: 0.4423 - val_weighted_dice_loss: 0.4423

Epoch 00003: val_weighted_dice_loss improved from 0.46352 to 0.44232, saving model to ./Unet-weights/4_classes_0_reals_26040_GANs.h5
Epoch 4/150
 - 1577s - loss: 0.1733 - weighted_dice_loss: 0.1733 - val_loss: 0.4517 - val_weighted_dice_loss: 0.4517

Epoch 00004: val_weighted_dice_loss did not improve from 0.44232
Epoch 5/150
 - 1572s - loss: 0.1632 - weighted_dice_loss: 0.1632 - val_loss: 0.5629 - val_weighted_dice_loss: 0.5629

Epoch 00005: val_weighted_dice_loss did not improve from 0.44232
Epoch 6/150
 - 1572s - loss: 0.1562 - weighted_dice_loss: 0.1562 - val_loss: 0.4440 - val_weighted_dice_loss: 0.4440

Epoch 00006: val_weighted_dice_loss did not improve from 0.44232
Epoch 7/150
 - 1579s - loss: 0.1485 - weighted_dice_loss: 0.1485 - val_loss: 0.4196 - val_weighted_dice_loss: 0.4196

Epoch 00007: val_weighted_dice_loss improved from 0.44232 to 0.41962, saving model to ./Unet-weights/4_classes_0_reals_26040_GANs.h5
Epoch 8/150
 - 1571s - loss: 0.1405 - weighted_dice_loss: 0.1405 - val_loss: 0.5002 - val_weighted_dice_loss: 0.5002

Epoch 00008: val_weighted_dice_loss did not improve from 0.41962
Epoch 9/150
 - 1574s - loss: 0.1365 - weighted_dice_loss: 0.1365 - val_loss: 0.3966 - val_weighted_dice_loss: 0.3966

Epoch 00009: val_weighted_dice_loss improved from 0.41962 to 0.39664, saving model to ./Unet-weights/4_classes_0_reals_26040_GANs.h5
Epoch 10/150
 - 1572s - loss: 0.1323 - weighted_dice_loss: 0.1323 - val_loss: 0.4821 - val_weighted_dice_loss: 0.4821

Epoch 00010: val_weighted_dice_loss did not improve from 0.39664
Epoch 11/150
 - 1570s - loss: 0.1287 - weighted_dice_loss: 0.1287 - val_loss: 0.4403 - val_weighted_dice_loss: 0.4403

Epoch 00011: val_weighted_dice_loss did not improve from 0.39664
Epoch 12/150
 - 1571s - loss: 0.1293 - weighted_dice_loss: 0.1293 - val_loss: 0.4541 - val_weighted_dice_loss: 0.4541

Epoch 00012: val_weighted_dice_loss did not improve from 0.39664
Epoch 13/150
 - 1575s - loss: 0.1217 - weighted_dice_loss: 0.1217 - val_loss: 0.4609 - val_weighted_dice_loss: 0.4609

Epoch 00013: val_weighted_dice_loss did not improve from 0.39664
Epoch 14/150
 - 1575s - loss: 0.1208 - weighted_dice_loss: 0.1208 - val_loss: 0.4189 - val_weighted_dice_loss: 0.4189

Epoch 00014: val_weighted_dice_loss did not improve from 0.39664
Epoch 15/150
 - 1573s - loss: 0.1175 - weighted_dice_loss: 0.1175 - val_loss: 0.3977 - val_weighted_dice_loss: 0.3977

Epoch 00015: val_weighted_dice_loss did not improve from 0.39664
Epoch 16/150
 - 1572s - loss: 0.1159 - weighted_dice_loss: 0.1159 - val_loss: 0.4695 - val_weighted_dice_loss: 0.4695

Epoch 00016: val_weighted_dice_loss did not improve from 0.39664
Epoch 17/150
 - 1576s - loss: 0.1132 - weighted_dice_loss: 0.1132 - val_loss: 0.4607 - val_weighted_dice_loss: 0.4607

Epoch 00017: val_weighted_dice_loss did not improve from 0.39664
Epoch 18/150
 - 1577s - loss: 0.1113 - weighted_dice_loss: 0.1113 - val_loss: 0.4662 - val_weighted_dice_loss: 0.4662

Epoch 00018: val_weighted_dice_loss did not improve from 0.39664
Epoch 19/150
 - 1571s - loss: 0.1100 - weighted_dice_loss: 0.1100 - val_loss: 0.6978 - val_weighted_dice_loss: 0.6978

Epoch 00019: val_weighted_dice_loss did not improve from 0.39664
Epoch 20/150
 - 1579s - loss: 0.1091 - weighted_dice_loss: 0.1091 - val_loss: 0.4533 - val_weighted_dice_loss: 0.4533

Epoch 00020: val_weighted_dice_loss did not improve from 0.39664
Epoch 21/150
 - 1571s - loss: 0.1072 - weighted_dice_loss: 0.1072 - val_loss: 0.4812 - val_weighted_dice_loss: 0.4812

Epoch 00021: val_weighted_dice_loss did not improve from 0.39664
Epoch 22/150
 - 1572s - loss: 0.1054 - weighted_dice_loss: 0.1054 - val_loss: 0.4494 - val_weighted_dice_loss: 0.4494

Epoch 00022: val_weighted_dice_loss did not improve from 0.39664
Epoch 23/150
 - 1575s - loss: 0.1060 - weighted_dice_loss: 0.1060 - val_loss: 0.4430 - val_weighted_dice_loss: 0.4430

Epoch 00023: val_weighted_dice_loss did not improve from 0.39664
Epoch 24/150
 - 1574s - loss: 0.1027 - weighted_dice_loss: 0.1027 - val_loss: 0.4087 - val_weighted_dice_loss: 0.4087

Epoch 00024: val_weighted_dice_loss did not improve from 0.39664
Epoch 25/150
 - 1582s - loss: 0.1018 - weighted_dice_loss: 0.1018 - val_loss: 0.4339 - val_weighted_dice_loss: 0.4339

Epoch 00025: val_weighted_dice_loss did not improve from 0.39664
Epoch 26/150
 - 1571s - loss: 0.1008 - weighted_dice_loss: 0.1008 - val_loss: 0.4149 - val_weighted_dice_loss: 0.4149

Epoch 00026: val_weighted_dice_loss did not improve from 0.39664
Epoch 27/150
 - 1569s - loss: 0.0992 - weighted_dice_loss: 0.0992 - val_loss: 0.4123 - val_weighted_dice_loss: 0.4123

Epoch 00027: val_weighted_dice_loss did not improve from 0.39664
Epoch 28/150
 - 1573s - loss: 0.0978 - weighted_dice_loss: 0.0978 - val_loss: 0.5312 - val_weighted_dice_loss: 0.5312

Epoch 00028: val_weighted_dice_loss did not improve from 0.39664
Epoch 29/150
 - 1574s - loss: 0.0970 - weighted_dice_loss: 0.0970 - val_loss: 0.4235 - val_weighted_dice_loss: 0.4235

Epoch 00029: val_weighted_dice_loss did not improve from 0.39664
Epoch 30/150
 - 1577s - loss: 0.0963 - weighted_dice_loss: 0.0963 - val_loss: 0.4525 - val_weighted_dice_loss: 0.4525

Epoch 00030: val_weighted_dice_loss did not improve from 0.39664
Epoch 31/150
 - 1575s - loss: 0.0953 - weighted_dice_loss: 0.0953 - val_loss: 0.4284 - val_weighted_dice_loss: 0.4284

Epoch 00031: val_weighted_dice_loss did not improve from 0.39664
Epoch 32/150
 - 1576s - loss: 0.0942 - weighted_dice_loss: 0.0942 - val_loss: 0.4231 - val_weighted_dice_loss: 0.4231

Epoch 00032: val_weighted_dice_loss did not improve from 0.39664
Epoch 33/150
 - 1574s - loss: 0.0930 - weighted_dice_loss: 0.0930 - val_loss: 0.4772 - val_weighted_dice_loss: 0.4772

Epoch 00033: val_weighted_dice_loss did not improve from 0.39664
Epoch 34/150
 - 1575s - loss: 0.0923 - weighted_dice_loss: 0.0923 - val_loss: 0.4397 - val_weighted_dice_loss: 0.4397

Epoch 00034: val_weighted_dice_loss did not improve from 0.39664
Epoch 35/150
 - 1573s - loss: 0.0915 - weighted_dice_loss: 0.0915 - val_loss: 0.4539 - val_weighted_dice_loss: 0.4539

Epoch 00035: val_weighted_dice_loss did not improve from 0.39664
Epoch 36/150
 - 1576s - loss: 0.0900 - weighted_dice_loss: 0.0900 - val_loss: 0.4364 - val_weighted_dice_loss: 0.4364

Epoch 00036: val_weighted_dice_loss did not improve from 0.39664
Epoch 37/150
 - 1578s - loss: 0.0897 - weighted_dice_loss: 0.0897 - val_loss: 0.4224 - val_weighted_dice_loss: 0.4224

Epoch 00037: val_weighted_dice_loss did not improve from 0.39664
Epoch 38/150
 - 1573s - loss: 0.0891 - weighted_dice_loss: 0.0891 - val_loss: 0.4881 - val_weighted_dice_loss: 0.4881

Epoch 00038: val_weighted_dice_loss did not improve from 0.39664
Epoch 39/150
 - 1576s - loss: 0.0875 - weighted_dice_loss: 0.0875 - val_loss: 0.4585 - val_weighted_dice_loss: 0.4585

Epoch 00039: val_weighted_dice_loss did not improve from 0.39664
Epoch 40/150
 - 1573s - loss: 0.0873 - weighted_dice_loss: 0.0873 - val_loss: 0.4242 - val_weighted_dice_loss: 0.4242

Epoch 00040: val_weighted_dice_loss did not improve from 0.39664
Epoch 41/150
 - 1577s - loss: 0.0864 - weighted_dice_loss: 0.0864 - val_loss: 0.4407 - val_weighted_dice_loss: 0.4407

Epoch 00041: val_weighted_dice_loss did not improve from 0.39664
Epoch 42/150
 - 1575s - loss: 0.0861 - weighted_dice_loss: 0.0861 - val_loss: 0.4691 - val_weighted_dice_loss: 0.4691

Epoch 00042: val_weighted_dice_loss did not improve from 0.39664
Epoch 43/150
 - 1576s - loss: 0.0853 - weighted_dice_loss: 0.0853 - val_loss: 0.4324 - val_weighted_dice_loss: 0.4324

Epoch 00043: val_weighted_dice_loss did not improve from 0.39664
Epoch 44/150
 - 1570s - loss: 0.0847 - weighted_dice_loss: 0.0847 - val_loss: 0.4646 - val_weighted_dice_loss: 0.4646

Epoch 00044: val_weighted_dice_loss did not improve from 0.39664
Epoch 45/150
 - 1579s - loss: 0.0836 - weighted_dice_loss: 0.0836 - val_loss: 0.4502 - val_weighted_dice_loss: 0.4502

Epoch 00045: val_weighted_dice_loss did not improve from 0.39664
Epoch 46/150
 - 1576s - loss: 0.0839 - weighted_dice_loss: 0.0839 - val_loss: 0.5248 - val_weighted_dice_loss: 0.5248

Epoch 00046: val_weighted_dice_loss did not improve from 0.39664
Epoch 47/150
 - 1577s - loss: 0.0823 - weighted_dice_loss: 0.0823 - val_loss: 0.4246 - val_weighted_dice_loss: 0.4246

Epoch 00047: val_weighted_dice_loss did not improve from 0.39664
Epoch 48/150
 - 1571s - loss: 0.0821 - weighted_dice_loss: 0.0821 - val_loss: 0.4477 - val_weighted_dice_loss: 0.4477

Epoch 00048: val_weighted_dice_loss did not improve from 0.39664
Epoch 49/150
 - 1578s - loss: 0.0816 - weighted_dice_loss: 0.0816 - val_loss: 0.4307 - val_weighted_dice_loss: 0.4307

Epoch 00049: val_weighted_dice_loss did not improve from 0.39664
Epoch 50/150
 - 1577s - loss: 0.0807 - weighted_dice_loss: 0.0807 - val_loss: 0.3838 - val_weighted_dice_loss: 0.3838

Epoch 00050: val_weighted_dice_loss improved from 0.39664 to 0.38382, saving model to ./Unet-weights/4_classes_0_reals_26040_GANs.h5
Epoch 51/150
 - 1577s - loss: 0.0803 - weighted_dice_loss: 0.0803 - val_loss: 0.4225 - val_weighted_dice_loss: 0.4225

Epoch 00051: val_weighted_dice_loss did not improve from 0.38382
Epoch 52/150
 - 1581s - loss: 0.0797 - weighted_dice_loss: 0.0797 - val_loss: 0.4357 - val_weighted_dice_loss: 0.4357

Epoch 00052: val_weighted_dice_loss did not improve from 0.38382
Epoch 53/150
 - 1580s - loss: 0.0789 - weighted_dice_loss: 0.0789 - val_loss: 0.4173 - val_weighted_dice_loss: 0.4173

Epoch 00053: val_weighted_dice_loss did not improve from 0.38382
Epoch 54/150
 - 1581s - loss: 0.0784 - weighted_dice_loss: 0.0784 - val_loss: 0.4173 - val_weighted_dice_loss: 0.4173

Epoch 00054: val_weighted_dice_loss did not improve from 0.38382
Epoch 55/150
 - 1579s - loss: 0.0783 - weighted_dice_loss: 0.0783 - val_loss: 0.4235 - val_weighted_dice_loss: 0.4235

Epoch 00055: val_weighted_dice_loss did not improve from 0.38382
Epoch 56/150
 - 1580s - loss: 0.0780 - weighted_dice_loss: 0.0780 - val_loss: 0.4431 - val_weighted_dice_loss: 0.4431

Epoch 00056: val_weighted_dice_loss did not improve from 0.38382
Epoch 57/150
 - 1583s - loss: 0.0771 - weighted_dice_loss: 0.0771 - val_loss: 0.4369 - val_weighted_dice_loss: 0.4369

Epoch 00057: val_weighted_dice_loss did not improve from 0.38382
Epoch 58/150
 - 1575s - loss: 0.0765 - weighted_dice_loss: 0.0765 - val_loss: 0.4653 - val_weighted_dice_loss: 0.4653

Epoch 00058: val_weighted_dice_loss did not improve from 0.38382
Epoch 59/150
 - 1586s - loss: 0.0762 - weighted_dice_loss: 0.0762 - val_loss: 0.4260 - val_weighted_dice_loss: 0.4260

Epoch 00059: val_weighted_dice_loss did not improve from 0.38382
Epoch 60/150
 - 1578s - loss: 0.0760 - weighted_dice_loss: 0.0760 - val_loss: 0.4121 - val_weighted_dice_loss: 0.4121

Epoch 00060: val_weighted_dice_loss did not improve from 0.38382
Epoch 61/150
 - 1574s - loss: 0.0751 - weighted_dice_loss: 0.0751 - val_loss: 0.4275 - val_weighted_dice_loss: 0.4275

Epoch 00061: val_weighted_dice_loss did not improve from 0.38382
Epoch 62/150
 - 1577s - loss: 0.0746 - weighted_dice_loss: 0.0746 - val_loss: 0.4411 - val_weighted_dice_loss: 0.4411

Epoch 00062: val_weighted_dice_loss did not improve from 0.38382
Epoch 63/150
 - 1579s - loss: 0.0745 - weighted_dice_loss: 0.0745 - val_loss: 0.4206 - val_weighted_dice_loss: 0.4206

Epoch 00063: val_weighted_dice_loss did not improve from 0.38382
Epoch 64/150
 - 1578s - loss: 0.0740 - weighted_dice_loss: 0.0740 - val_loss: 0.4428 - val_weighted_dice_loss: 0.4428

Epoch 00064: val_weighted_dice_loss did not improve from 0.38382
Epoch 65/150
 - 1579s - loss: 0.0736 - weighted_dice_loss: 0.0736 - val_loss: 0.4446 - val_weighted_dice_loss: 0.4446

Epoch 00065: val_weighted_dice_loss did not improve from 0.38382
Epoch 66/150
 - 1575s - loss: 0.0733 - weighted_dice_loss: 0.0733 - val_loss: 0.4393 - val_weighted_dice_loss: 0.4393

Epoch 00066: val_weighted_dice_loss did not improve from 0.38382
Epoch 67/150
 - 1578s - loss: 0.0729 - weighted_dice_loss: 0.0729 - val_loss: 0.4560 - val_weighted_dice_loss: 0.4560

Epoch 00067: val_weighted_dice_loss did not improve from 0.38382
Epoch 68/150
 - 1574s - loss: 0.0724 - weighted_dice_loss: 0.0724 - val_loss: 0.4569 - val_weighted_dice_loss: 0.4569

Epoch 00068: val_weighted_dice_loss did not improve from 0.38382
Epoch 69/150
 - 1574s - loss: 0.0721 - weighted_dice_loss: 0.0721 - val_loss: 0.4578 - val_weighted_dice_loss: 0.4578

Epoch 00069: val_weighted_dice_loss did not improve from 0.38382
Epoch 70/150
 - 1576s - loss: 0.0716 - weighted_dice_loss: 0.0716 - val_loss: 0.4369 - val_weighted_dice_loss: 0.4369

Epoch 00070: val_weighted_dice_loss did not improve from 0.38382
Epoch 71/150
 - 1577s - loss: 0.0715 - weighted_dice_loss: 0.0715 - val_loss: 0.4044 - val_weighted_dice_loss: 0.4044

Epoch 00071: val_weighted_dice_loss did not improve from 0.38382
Epoch 72/150
 - 1572s - loss: 0.0709 - weighted_dice_loss: 0.0709 - val_loss: 0.4320 - val_weighted_dice_loss: 0.4320

Epoch 00072: val_weighted_dice_loss did not improve from 0.38382
Epoch 73/150
 - 1575s - loss: 0.0707 - weighted_dice_loss: 0.0707 - val_loss: 0.4410 - val_weighted_dice_loss: 0.4410

Epoch 00073: val_weighted_dice_loss did not improve from 0.38382
Epoch 74/150
 - 1579s - loss: 0.0704 - weighted_dice_loss: 0.0704 - val_loss: 0.4574 - val_weighted_dice_loss: 0.4574

Epoch 00074: val_weighted_dice_loss did not improve from 0.38382
Epoch 75/150
 - 1574s - loss: 0.0703 - weighted_dice_loss: 0.0703 - val_loss: 0.4303 - val_weighted_dice_loss: 0.4303

Epoch 00075: val_weighted_dice_loss did not improve from 0.38382
Epoch 76/150
 - 1579s - loss: 0.0696 - weighted_dice_loss: 0.0696 - val_loss: 0.4526 - val_weighted_dice_loss: 0.4526

Epoch 00076: val_weighted_dice_loss did not improve from 0.38382
Epoch 77/150
 - 1610s - loss: 0.0694 - weighted_dice_loss: 0.0694 - val_loss: 0.4287 - val_weighted_dice_loss: 0.4287

Epoch 00077: val_weighted_dice_loss did not improve from 0.38382
Epoch 78/150
 - 1575s - loss: 0.0685 - weighted_dice_loss: 0.0685 - val_loss: 0.4087 - val_weighted_dice_loss: 0.4087

Epoch 00078: val_weighted_dice_loss did not improve from 0.38382
Epoch 79/150
 - 1576s - loss: 0.0683 - weighted_dice_loss: 0.0683 - val_loss: 0.4354 - val_weighted_dice_loss: 0.4354

Epoch 00079: val_weighted_dice_loss did not improve from 0.38382
Epoch 80/150
 - 1574s - loss: 0.0682 - weighted_dice_loss: 0.0682 - val_loss: 0.4376 - val_weighted_dice_loss: 0.4376

Epoch 00080: val_weighted_dice_loss did not improve from 0.38382
Epoch 81/150
 - 1578s - loss: 0.0682 - weighted_dice_loss: 0.0682 - val_loss: 0.4510 - val_weighted_dice_loss: 0.4510

Epoch 00081: val_weighted_dice_loss did not improve from 0.38382
Epoch 82/150
 - 1574s - loss: 0.0675 - weighted_dice_loss: 0.0675 - val_loss: 0.4318 - val_weighted_dice_loss: 0.4318

Epoch 00082: val_weighted_dice_loss did not improve from 0.38382
Epoch 83/150
 - 1575s - loss: 0.0674 - weighted_dice_loss: 0.0674 - val_loss: 0.4329 - val_weighted_dice_loss: 0.4329

Epoch 00083: val_weighted_dice_loss did not improve from 0.38382
Epoch 84/150
 - 1574s - loss: 0.0670 - weighted_dice_loss: 0.0670 - val_loss: 0.4252 - val_weighted_dice_loss: 0.4252

Epoch 00084: val_weighted_dice_loss did not improve from 0.38382
Epoch 85/150
 - 1574s - loss: 0.0670 - weighted_dice_loss: 0.0670 - val_loss: 0.4362 - val_weighted_dice_loss: 0.4362

Epoch 00085: val_weighted_dice_loss did not improve from 0.38382
Epoch 86/150
 - 1577s - loss: 0.0664 - weighted_dice_loss: 0.0664 - val_loss: 0.4342 - val_weighted_dice_loss: 0.4342

Epoch 00086: val_weighted_dice_loss did not improve from 0.38382
Epoch 87/150
 - 1576s - loss: 0.0660 - weighted_dice_loss: 0.0660 - val_loss: 0.4390 - val_weighted_dice_loss: 0.4390

Epoch 00087: val_weighted_dice_loss did not improve from 0.38382
Epoch 88/150
 - 1575s - loss: 0.0658 - weighted_dice_loss: 0.0658 - val_loss: 0.4313 - val_weighted_dice_loss: 0.4313

Epoch 00088: val_weighted_dice_loss did not improve from 0.38382
Epoch 89/150
 - 1574s - loss: 0.0655 - weighted_dice_loss: 0.0655 - val_loss: 0.4534 - val_weighted_dice_loss: 0.4534

Epoch 00089: val_weighted_dice_loss did not improve from 0.38382
Epoch 90/150
 - 1574s - loss: 0.0655 - weighted_dice_loss: 0.0655 - val_loss: 0.4343 - val_weighted_dice_loss: 0.4343

Epoch 00090: val_weighted_dice_loss did not improve from 0.38382
Epoch 91/150
 - 1577s - loss: 0.0649 - weighted_dice_loss: 0.0649 - val_loss: 0.4193 - val_weighted_dice_loss: 0.4193

Epoch 00091: val_weighted_dice_loss did not improve from 0.38382
Epoch 92/150
 - 1578s - loss: 0.0645 - weighted_dice_loss: 0.0645 - val_loss: 0.4440 - val_weighted_dice_loss: 0.4440

Epoch 00092: val_weighted_dice_loss did not improve from 0.38382
Epoch 93/150
 - 1574s - loss: 0.0645 - weighted_dice_loss: 0.0645 - val_loss: 0.4221 - val_weighted_dice_loss: 0.4221

Epoch 00093: val_weighted_dice_loss did not improve from 0.38382
Epoch 94/150
 - 1577s - loss: 0.0644 - weighted_dice_loss: 0.0644 - val_loss: 0.4306 - val_weighted_dice_loss: 0.4306

Epoch 00094: val_weighted_dice_loss did not improve from 0.38382
Epoch 95/150
 - 1577s - loss: 0.0638 - weighted_dice_loss: 0.0638 - val_loss: 0.4383 - val_weighted_dice_loss: 0.4383

Epoch 00095: val_weighted_dice_loss did not improve from 0.38382
Epoch 96/150
 - 1573s - loss: 0.0637 - weighted_dice_loss: 0.0637 - val_loss: 0.4213 - val_weighted_dice_loss: 0.4213

Epoch 00096: val_weighted_dice_loss did not improve from 0.38382
Epoch 97/150
 - 1580s - loss: 0.0634 - weighted_dice_loss: 0.0634 - val_loss: 0.4475 - val_weighted_dice_loss: 0.4475

Epoch 00097: val_weighted_dice_loss did not improve from 0.38382
Epoch 98/150
 - 1576s - loss: 0.0633 - weighted_dice_loss: 0.0633 - val_loss: 0.4409 - val_weighted_dice_loss: 0.4409

Epoch 00098: val_weighted_dice_loss did not improve from 0.38382
Epoch 99/150
 - 1578s - loss: 0.0632 - weighted_dice_loss: 0.0632 - val_loss: 0.4485 - val_weighted_dice_loss: 0.4485

Epoch 00099: val_weighted_dice_loss did not improve from 0.38382
Epoch 100/150
 - 1573s - loss: 0.0626 - weighted_dice_loss: 0.0626 - val_loss: 0.4415 - val_weighted_dice_loss: 0.4415

Epoch 00100: val_weighted_dice_loss did not improve from 0.38382
Epoch 101/150
 - 1576s - loss: 0.0626 - weighted_dice_loss: 0.0626 - val_loss: 0.4447 - val_weighted_dice_loss: 0.4447

Epoch 00101: val_weighted_dice_loss did not improve from 0.38382
Epoch 102/150
 - 1574s - loss: 0.0625 - weighted_dice_loss: 0.0625 - val_loss: 0.4419 - val_weighted_dice_loss: 0.4419

Epoch 00102: val_weighted_dice_loss did not improve from 0.38382
Epoch 103/150
 - 1573s - loss: 0.0619 - weighted_dice_loss: 0.0619 - val_loss: 0.4498 - val_weighted_dice_loss: 0.4498

Epoch 00103: val_weighted_dice_loss did not improve from 0.38382
Epoch 104/150
 - 1578s - loss: 0.0620 - weighted_dice_loss: 0.0620 - val_loss: 0.4463 - val_weighted_dice_loss: 0.4463

Epoch 00104: val_weighted_dice_loss did not improve from 0.38382
Epoch 105/150
 - 1591s - loss: 0.0619 - weighted_dice_loss: 0.0619 - val_loss: 0.4483 - val_weighted_dice_loss: 0.4483

Epoch 00105: val_weighted_dice_loss did not improve from 0.38382
Epoch 106/150
 - 1578s - loss: 0.0613 - weighted_dice_loss: 0.0613 - val_loss: 0.4125 - val_weighted_dice_loss: 0.4125

Epoch 00106: val_weighted_dice_loss did not improve from 0.38382
Epoch 107/150
 - 1578s - loss: 0.0611 - weighted_dice_loss: 0.0611 - val_loss: 0.4574 - val_weighted_dice_loss: 0.4574

Epoch 00107: val_weighted_dice_loss did not improve from 0.38382
Epoch 108/150
 - 1575s - loss: 0.0610 - weighted_dice_loss: 0.0610 - val_loss: 0.4648 - val_weighted_dice_loss: 0.4648

Epoch 00108: val_weighted_dice_loss did not improve from 0.38382
Epoch 109/150
 - 1577s - loss: 0.0611 - weighted_dice_loss: 0.0611 - val_loss: 0.4336 - val_weighted_dice_loss: 0.4336

Epoch 00109: val_weighted_dice_loss did not improve from 0.38382
Epoch 110/150
 - 1579s - loss: 0.0606 - weighted_dice_loss: 0.0606 - val_loss: 0.4280 - val_weighted_dice_loss: 0.4280

Epoch 00110: val_weighted_dice_loss did not improve from 0.38382
Epoch 111/150
 - 1582s - loss: 0.0601 - weighted_dice_loss: 0.0601 - val_loss: 0.4316 - val_weighted_dice_loss: 0.4316

Epoch 00111: val_weighted_dice_loss did not improve from 0.38382
Epoch 112/150
 - 1581s - loss: 0.0601 - weighted_dice_loss: 0.0601 - val_loss: 0.4498 - val_weighted_dice_loss: 0.4498

Epoch 00112: val_weighted_dice_loss did not improve from 0.38382
Epoch 113/150
 - 1580s - loss: 0.0599 - weighted_dice_loss: 0.0599 - val_loss: 0.4383 - val_weighted_dice_loss: 0.4383

Epoch 00113: val_weighted_dice_loss did not improve from 0.38382
Epoch 114/150
 - 1578s - loss: 0.0597 - weighted_dice_loss: 0.0597 - val_loss: 0.4309 - val_weighted_dice_loss: 0.4309

Epoch 00114: val_weighted_dice_loss did not improve from 0.38382
Epoch 115/150
 - 1582s - loss: 0.0594 - weighted_dice_loss: 0.0594 - val_loss: 0.4505 - val_weighted_dice_loss: 0.4505

Epoch 00115: val_weighted_dice_loss did not improve from 0.38382
Epoch 116/150
 - 1580s - loss: 0.0593 - weighted_dice_loss: 0.0593 - val_loss: 0.4263 - val_weighted_dice_loss: 0.4263

Epoch 00116: val_weighted_dice_loss did not improve from 0.38382
Epoch 117/150
 - 1580s - loss: 0.0591 - weighted_dice_loss: 0.0591 - val_loss: 0.4326 - val_weighted_dice_loss: 0.4326

Epoch 00117: val_weighted_dice_loss did not improve from 0.38382
Epoch 118/150
 - 1578s - loss: 0.0590 - weighted_dice_loss: 0.0590 - val_loss: 0.4581 - val_weighted_dice_loss: 0.4581

Epoch 00118: val_weighted_dice_loss did not improve from 0.38382
Epoch 119/150
 - 1580s - loss: 0.0589 - weighted_dice_loss: 0.0589 - val_loss: 0.4281 - val_weighted_dice_loss: 0.4281

Epoch 00119: val_weighted_dice_loss did not improve from 0.38382
Epoch 120/150
 - 1575s - loss: 0.0587 - weighted_dice_loss: 0.0587 - val_loss: 0.4320 - val_weighted_dice_loss: 0.4320

Epoch 00120: val_weighted_dice_loss did not improve from 0.38382
Epoch 121/150
 - 1577s - loss: 0.0585 - weighted_dice_loss: 0.0585 - val_loss: 0.4274 - val_weighted_dice_loss: 0.4274

Epoch 00121: val_weighted_dice_loss did not improve from 0.38382
Epoch 122/150
 - 1576s - loss: 0.0581 - weighted_dice_loss: 0.0581 - val_loss: 0.4514 - val_weighted_dice_loss: 0.4514

Epoch 00122: val_weighted_dice_loss did not improve from 0.38382
Epoch 123/150
 - 1577s - loss: 0.0580 - weighted_dice_loss: 0.0580 - val_loss: 0.4409 - val_weighted_dice_loss: 0.4409

Epoch 00123: val_weighted_dice_loss did not improve from 0.38382
Epoch 124/150
 - 1575s - loss: 0.0578 - weighted_dice_loss: 0.0578 - val_loss: 0.4369 - val_weighted_dice_loss: 0.4369

Epoch 00124: val_weighted_dice_loss did not improve from 0.38382
Epoch 125/150
 - 1576s - loss: 0.0576 - weighted_dice_loss: 0.0576 - val_loss: 0.4395 - val_weighted_dice_loss: 0.4395

Epoch 00125: val_weighted_dice_loss did not improve from 0.38382
Epoch 126/150
 - 1577s - loss: 0.0573 - weighted_dice_loss: 0.0573 - val_loss: 0.4525 - val_weighted_dice_loss: 0.4525

Epoch 00126: val_weighted_dice_loss did not improve from 0.38382
Epoch 127/150
 - 1573s - loss: 0.0573 - weighted_dice_loss: 0.0573 - val_loss: 0.4372 - val_weighted_dice_loss: 0.4372

Epoch 00127: val_weighted_dice_loss did not improve from 0.38382
Epoch 128/150
 - 1577s - loss: 0.0571 - weighted_dice_loss: 0.0571 - val_loss: 0.4464 - val_weighted_dice_loss: 0.4464

Epoch 00128: val_weighted_dice_loss did not improve from 0.38382
Epoch 129/150
 - 1574s - loss: 0.0571 - weighted_dice_loss: 0.0571 - val_loss: 0.4298 - val_weighted_dice_loss: 0.4298

Epoch 00129: val_weighted_dice_loss did not improve from 0.38382
Epoch 130/150
 - 1580s - loss: 0.0566 - weighted_dice_loss: 0.0566 - val_loss: 0.4395 - val_weighted_dice_loss: 0.4395

Epoch 00130: val_weighted_dice_loss did not improve from 0.38382
Epoch 131/150
 - 1576s - loss: 0.0565 - weighted_dice_loss: 0.0565 - val_loss: 0.4326 - val_weighted_dice_loss: 0.4326

Epoch 00131: val_weighted_dice_loss did not improve from 0.38382
Epoch 132/150
 - 1576s - loss: 0.0564 - weighted_dice_loss: 0.0564 - val_loss: 0.4458 - val_weighted_dice_loss: 0.4458

Epoch 00132: val_weighted_dice_loss did not improve from 0.38382
Epoch 133/150
 - 1576s - loss: 0.0563 - weighted_dice_loss: 0.0563 - val_loss: 0.4606 - val_weighted_dice_loss: 0.4606

Epoch 00133: val_weighted_dice_loss did not improve from 0.38382
Epoch 134/150
 - 1576s - loss: 0.0562 - weighted_dice_loss: 0.0562 - val_loss: 0.4293 - val_weighted_dice_loss: 0.4293

Epoch 00134: val_weighted_dice_loss did not improve from 0.38382
Epoch 135/150
 - 1578s - loss: 0.0560 - weighted_dice_loss: 0.0560 - val_loss: 0.4417 - val_weighted_dice_loss: 0.4417

Epoch 00135: val_weighted_dice_loss did not improve from 0.38382
Epoch 136/150
 - 1577s - loss: 0.0557 - weighted_dice_loss: 0.0557 - val_loss: 0.4370 - val_weighted_dice_loss: 0.4370

Epoch 00136: val_weighted_dice_loss did not improve from 0.38382
Epoch 137/150
 - 1573s - loss: 0.0557 - weighted_dice_loss: 0.0557 - val_loss: 0.4385 - val_weighted_dice_loss: 0.4385

Epoch 00137: val_weighted_dice_loss did not improve from 0.38382
Epoch 138/150
 - 1578s - loss: 0.0556 - weighted_dice_loss: 0.0556 - val_loss: 0.4382 - val_weighted_dice_loss: 0.4382

Epoch 00138: val_weighted_dice_loss did not improve from 0.38382
Epoch 139/150
 - 1579s - loss: 0.0551 - weighted_dice_loss: 0.0551 - val_loss: 0.4195 - val_weighted_dice_loss: 0.4195

Epoch 00139: val_weighted_dice_loss did not improve from 0.38382
Epoch 140/150
 - 1574s - loss: 0.0552 - weighted_dice_loss: 0.0552 - val_loss: 0.4404 - val_weighted_dice_loss: 0.4404

Epoch 00140: val_weighted_dice_loss did not improve from 0.38382
Epoch 141/150
 - 1577s - loss: 0.0551 - weighted_dice_loss: 0.0551 - val_loss: 0.4303 - val_weighted_dice_loss: 0.4303

Epoch 00141: val_weighted_dice_loss did not improve from 0.38382
Epoch 142/150
 - 1574s - loss: 0.0548 - weighted_dice_loss: 0.0548 - val_loss: 0.4486 - val_weighted_dice_loss: 0.4486

Epoch 00142: val_weighted_dice_loss did not improve from 0.38382
Epoch 143/150
 - 1575s - loss: 0.0548 - weighted_dice_loss: 0.0548 - val_loss: 0.4397 - val_weighted_dice_loss: 0.4397

Epoch 00143: val_weighted_dice_loss did not improve from 0.38382
Epoch 144/150
 - 1575s - loss: 0.0546 - weighted_dice_loss: 0.0546 - val_loss: 0.4360 - val_weighted_dice_loss: 0.4360

Epoch 00144: val_weighted_dice_loss did not improve from 0.38382
Epoch 145/150
 - 1577s - loss: 0.0545 - weighted_dice_loss: 0.0545 - val_loss: 0.4399 - val_weighted_dice_loss: 0.4399

Epoch 00145: val_weighted_dice_loss did not improve from 0.38382
Epoch 146/150
 - 1577s - loss: 0.0543 - weighted_dice_loss: 0.0543 - val_loss: 0.4237 - val_weighted_dice_loss: 0.4237

Epoch 00146: val_weighted_dice_loss did not improve from 0.38382
Epoch 147/150
 - 1578s - loss: 0.0540 - weighted_dice_loss: 0.0540 - val_loss: 0.4313 - val_weighted_dice_loss: 0.4313

Epoch 00147: val_weighted_dice_loss did not improve from 0.38382
Epoch 148/150
 - 1578s - loss: 0.0538 - weighted_dice_loss: 0.0538 - val_loss: 0.4383 - val_weighted_dice_loss: 0.4383

Epoch 00148: val_weighted_dice_loss did not improve from 0.38382
Epoch 149/150
 - 1582s - loss: 0.0538 - weighted_dice_loss: 0.0538 - val_loss: 0.4307 - val_weighted_dice_loss: 0.4307

Epoch 00149: val_weighted_dice_loss did not improve from 0.38382
Epoch 150/150
 - 1578s - loss: 0.0537 - weighted_dice_loss: 0.0537 - val_loss: 0.4333 - val_weighted_dice_loss: 0.4333

Epoch 00150: val_weighted_dice_loss did not improve from 0.38382
Finished training.
