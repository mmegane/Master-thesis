nohup: ignoring input
2020-07-21 10:37:53.984366: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-07-21 10:37:53.996539: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz
2020-07-21 10:37:53.997430: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e005011970 executing computations on platform Host. Devices:
2020-07-21 10:37:53.997481: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-07-21 10:37:53.999262: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-07-21 10:37:54.164345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.164718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-07-21 10:37:54.164757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.165036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-07-21 10:37:54.166769: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-07-21 10:37:54.170841: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-07-21 10:37:54.173467: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-07-21 10:37:54.175201: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-07-21 10:37:54.177721: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-07-21 10:37:54.179638: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-07-21 10:37:54.183315: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-07-21 10:37:54.183389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.183782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.184087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.184425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.184706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-07-21 10:37:54.184726: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-07-21 10:37:54.185578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-21 10:37:54.185588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-07-21 10:37:54.185595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-07-21 10:37:54.185603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-07-21 10:37:54.185681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.186029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.186330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.186673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.187011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10319 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-07-21 10:37:54.187450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.187759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.188041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7514 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-07-21 10:37:54.189320: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e00635f720 executing computations on platform CUDA. Devices:
2020-07-21 10:37:54.189332: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-07-21 10:37:54.189337: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From segmentation.py:20: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

WARNING:tensorflow:From segmentation.py:33: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From segmentation.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-07-21 10:37:54.190251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.190587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-07-21 10:37:54.190623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.190965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-07-21 10:37:54.190985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-07-21 10:37:54.190994: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-07-21 10:37:54.191002: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-07-21 10:37:54.191010: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-07-21 10:37:54.191020: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-07-21 10:37:54.191029: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-07-21 10:37:54.191036: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-07-21 10:37:54.191067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.191409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.191741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.192097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.192375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-07-21 10:37:54.192394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-21 10:37:54.192399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-07-21 10:37:54.192404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-07-21 10:37:54.192407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-07-21 10:37:54.192462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.192840: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.193140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.193462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10319 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-07-21 10:37:54.193497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-21 10:37:54.193779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7514 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-07-21 10:41:02.231541: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7

Reading data...
Finished reading data.

Reading data...
Finished reading data.

Training 7 classes with 50000 images (26040 real and 23960 GAN images):

Epoch 1/150
 - 1599s - loss: 0.3636 - weighted_dice_loss: 0.3636 - val_loss: 0.3484 - val_weighted_dice_loss: 0.3484

Epoch 00001: val_weighted_dice_loss improved from inf to 0.34836, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 2/150
 - 1559s - loss: 0.2377 - weighted_dice_loss: 0.2377 - val_loss: 0.2291 - val_weighted_dice_loss: 0.2291

Epoch 00002: val_weighted_dice_loss improved from 0.34836 to 0.22911, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 3/150
 - 1561s - loss: 0.2162 - weighted_dice_loss: 0.2162 - val_loss: 0.2225 - val_weighted_dice_loss: 0.2225

Epoch 00003: val_weighted_dice_loss improved from 0.22911 to 0.22247, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 4/150
 - 1562s - loss: 0.2030 - weighted_dice_loss: 0.2030 - val_loss: 0.2251 - val_weighted_dice_loss: 0.2251

Epoch 00004: val_weighted_dice_loss did not improve from 0.22247
Epoch 5/150
 - 1558s - loss: 0.1918 - weighted_dice_loss: 0.1918 - val_loss: 0.2395 - val_weighted_dice_loss: 0.2395

Epoch 00005: val_weighted_dice_loss did not improve from 0.22247
Epoch 6/150
 - 1558s - loss: 0.1824 - weighted_dice_loss: 0.1824 - val_loss: 0.1992 - val_weighted_dice_loss: 0.1992

Epoch 00006: val_weighted_dice_loss improved from 0.22247 to 0.19921, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 7/150
 - 1558s - loss: 0.1732 - weighted_dice_loss: 0.1732 - val_loss: 0.1890 - val_weighted_dice_loss: 0.1890

Epoch 00007: val_weighted_dice_loss improved from 0.19921 to 0.18901, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 8/150
 - 1559s - loss: 0.1657 - weighted_dice_loss: 0.1657 - val_loss: 0.1829 - val_weighted_dice_loss: 0.1829

Epoch 00008: val_weighted_dice_loss improved from 0.18901 to 0.18292, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 9/150
 - 1557s - loss: 0.1595 - weighted_dice_loss: 0.1595 - val_loss: 0.1955 - val_weighted_dice_loss: 0.1955

Epoch 00009: val_weighted_dice_loss did not improve from 0.18292
Epoch 10/150
 - 1556s - loss: 0.1539 - weighted_dice_loss: 0.1539 - val_loss: 0.1883 - val_weighted_dice_loss: 0.1883

Epoch 00010: val_weighted_dice_loss did not improve from 0.18292
Epoch 11/150
 - 1558s - loss: 0.1497 - weighted_dice_loss: 0.1497 - val_loss: 0.1763 - val_weighted_dice_loss: 0.1763

Epoch 00011: val_weighted_dice_loss improved from 0.18292 to 0.17630, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 12/150
 - 1559s - loss: 0.1452 - weighted_dice_loss: 0.1452 - val_loss: 0.1729 - val_weighted_dice_loss: 0.1729

Epoch 00012: val_weighted_dice_loss improved from 0.17630 to 0.17290, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 13/150
 - 1560s - loss: 0.1415 - weighted_dice_loss: 0.1415 - val_loss: 0.1856 - val_weighted_dice_loss: 0.1856

Epoch 00013: val_weighted_dice_loss did not improve from 0.17290
Epoch 14/150
 - 1559s - loss: 0.1380 - weighted_dice_loss: 0.1380 - val_loss: 0.1657 - val_weighted_dice_loss: 0.1657

Epoch 00014: val_weighted_dice_loss improved from 0.17290 to 0.16575, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 15/150
 - 1558s - loss: 0.1351 - weighted_dice_loss: 0.1351 - val_loss: 0.1602 - val_weighted_dice_loss: 0.1602

Epoch 00015: val_weighted_dice_loss improved from 0.16575 to 0.16025, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 16/150
 - 1556s - loss: 0.1324 - weighted_dice_loss: 0.1324 - val_loss: 0.1639 - val_weighted_dice_loss: 0.1639

Epoch 00016: val_weighted_dice_loss did not improve from 0.16025
Epoch 17/150
 - 1557s - loss: 0.1295 - weighted_dice_loss: 0.1295 - val_loss: 0.3029 - val_weighted_dice_loss: 0.3029

Epoch 00017: val_weighted_dice_loss did not improve from 0.16025
Epoch 18/150
 - 1559s - loss: 0.1271 - weighted_dice_loss: 0.1271 - val_loss: 0.1548 - val_weighted_dice_loss: 0.1548

Epoch 00018: val_weighted_dice_loss improved from 0.16025 to 0.15485, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 19/150
 - 1556s - loss: 0.1249 - weighted_dice_loss: 0.1249 - val_loss: 0.1476 - val_weighted_dice_loss: 0.1476

Epoch 00019: val_weighted_dice_loss improved from 0.15485 to 0.14760, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 20/150
 - 1558s - loss: 0.1229 - weighted_dice_loss: 0.1229 - val_loss: 0.1603 - val_weighted_dice_loss: 0.1603

Epoch 00020: val_weighted_dice_loss did not improve from 0.14760
Epoch 21/150
 - 1558s - loss: 0.1210 - weighted_dice_loss: 0.1210 - val_loss: 0.1444 - val_weighted_dice_loss: 0.1444

Epoch 00021: val_weighted_dice_loss improved from 0.14760 to 0.14445, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 22/150
 - 1557s - loss: 0.1191 - weighted_dice_loss: 0.1191 - val_loss: 0.1428 - val_weighted_dice_loss: 0.1428

Epoch 00022: val_weighted_dice_loss improved from 0.14445 to 0.14278, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 23/150
 - 1558s - loss: 0.1175 - weighted_dice_loss: 0.1175 - val_loss: 0.1514 - val_weighted_dice_loss: 0.1514

Epoch 00023: val_weighted_dice_loss did not improve from 0.14278
Epoch 24/150
 - 1557s - loss: 0.1158 - weighted_dice_loss: 0.1158 - val_loss: 0.1418 - val_weighted_dice_loss: 0.1418

Epoch 00024: val_weighted_dice_loss improved from 0.14278 to 0.14180, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 25/150
 - 1559s - loss: 0.1143 - weighted_dice_loss: 0.1143 - val_loss: 0.1386 - val_weighted_dice_loss: 0.1386

Epoch 00025: val_weighted_dice_loss improved from 0.14180 to 0.13859, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 26/150
 - 1559s - loss: 0.1130 - weighted_dice_loss: 0.1130 - val_loss: 0.1411 - val_weighted_dice_loss: 0.1411

Epoch 00026: val_weighted_dice_loss did not improve from 0.13859
Epoch 27/150
 - 1557s - loss: 0.1115 - weighted_dice_loss: 0.1115 - val_loss: 0.1379 - val_weighted_dice_loss: 0.1379

Epoch 00027: val_weighted_dice_loss improved from 0.13859 to 0.13794, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 28/150
 - 1556s - loss: 0.1103 - weighted_dice_loss: 0.1103 - val_loss: 0.1399 - val_weighted_dice_loss: 0.1399

Epoch 00028: val_weighted_dice_loss did not improve from 0.13794
Epoch 29/150
 - 1556s - loss: 0.1092 - weighted_dice_loss: 0.1092 - val_loss: 0.1444 - val_weighted_dice_loss: 0.1444

Epoch 00029: val_weighted_dice_loss did not improve from 0.13794
Epoch 30/150
 - 1559s - loss: 0.1079 - weighted_dice_loss: 0.1079 - val_loss: 0.1707 - val_weighted_dice_loss: 0.1707

Epoch 00030: val_weighted_dice_loss did not improve from 0.13794
Epoch 31/150
 - 1558s - loss: 0.1068 - weighted_dice_loss: 0.1068 - val_loss: 0.1406 - val_weighted_dice_loss: 0.1406

Epoch 00031: val_weighted_dice_loss did not improve from 0.13794
Epoch 32/150
 - 1558s - loss: 0.1057 - weighted_dice_loss: 0.1057 - val_loss: 0.1353 - val_weighted_dice_loss: 0.1353

Epoch 00032: val_weighted_dice_loss improved from 0.13794 to 0.13527, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 33/150
 - 1558s - loss: 0.1048 - weighted_dice_loss: 0.1048 - val_loss: 0.1504 - val_weighted_dice_loss: 0.1504

Epoch 00033: val_weighted_dice_loss did not improve from 0.13527
Epoch 34/150
 - 1559s - loss: 0.1038 - weighted_dice_loss: 0.1038 - val_loss: 0.1357 - val_weighted_dice_loss: 0.1357

Epoch 00034: val_weighted_dice_loss did not improve from 0.13527
Epoch 35/150
 - 1557s - loss: 0.1028 - weighted_dice_loss: 0.1028 - val_loss: 0.1360 - val_weighted_dice_loss: 0.1360

Epoch 00035: val_weighted_dice_loss did not improve from 0.13527
Epoch 36/150
 - 1558s - loss: 0.1019 - weighted_dice_loss: 0.1019 - val_loss: 0.1347 - val_weighted_dice_loss: 0.1347

Epoch 00036: val_weighted_dice_loss improved from 0.13527 to 0.13473, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 37/150
 - 1556s - loss: 0.1010 - weighted_dice_loss: 0.1010 - val_loss: 0.1270 - val_weighted_dice_loss: 0.1270

Epoch 00037: val_weighted_dice_loss improved from 0.13473 to 0.12702, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 38/150
 - 1557s - loss: 0.1002 - weighted_dice_loss: 0.1002 - val_loss: 0.1410 - val_weighted_dice_loss: 0.1410

Epoch 00038: val_weighted_dice_loss did not improve from 0.12702
Epoch 39/150
 - 1557s - loss: 0.0993 - weighted_dice_loss: 0.0993 - val_loss: 0.1290 - val_weighted_dice_loss: 0.1290

Epoch 00039: val_weighted_dice_loss did not improve from 0.12702
Epoch 40/150
 - 1557s - loss: 0.0986 - weighted_dice_loss: 0.0986 - val_loss: 0.1294 - val_weighted_dice_loss: 0.1294

Epoch 00040: val_weighted_dice_loss did not improve from 0.12702
Epoch 41/150
 - 1557s - loss: 0.0979 - weighted_dice_loss: 0.0979 - val_loss: 0.1279 - val_weighted_dice_loss: 0.1279

Epoch 00041: val_weighted_dice_loss did not improve from 0.12702
Epoch 42/150
 - 1557s - loss: 0.0971 - weighted_dice_loss: 0.0971 - val_loss: 0.1783 - val_weighted_dice_loss: 0.1783

Epoch 00042: val_weighted_dice_loss did not improve from 0.12702
Epoch 43/150
 - 1557s - loss: 0.0964 - weighted_dice_loss: 0.0964 - val_loss: 0.1348 - val_weighted_dice_loss: 0.1348

Epoch 00043: val_weighted_dice_loss did not improve from 0.12702
Epoch 44/150
 - 1557s - loss: 0.0958 - weighted_dice_loss: 0.0958 - val_loss: 0.1275 - val_weighted_dice_loss: 0.1275

Epoch 00044: val_weighted_dice_loss did not improve from 0.12702
Epoch 45/150
 - 1557s - loss: 0.0950 - weighted_dice_loss: 0.0950 - val_loss: 0.1317 - val_weighted_dice_loss: 0.1317

Epoch 00045: val_weighted_dice_loss did not improve from 0.12702
Epoch 46/150
 - 1557s - loss: 0.0945 - weighted_dice_loss: 0.0945 - val_loss: 0.8936 - val_weighted_dice_loss: 0.8936

Epoch 00046: val_weighted_dice_loss did not improve from 0.12702
Epoch 47/150
 - 1558s - loss: 0.0937 - weighted_dice_loss: 0.0937 - val_loss: 0.1226 - val_weighted_dice_loss: 0.1226

Epoch 00047: val_weighted_dice_loss improved from 0.12702 to 0.12263, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 48/150
 - 1557s - loss: 0.0932 - weighted_dice_loss: 0.0932 - val_loss: 0.1272 - val_weighted_dice_loss: 0.1272

Epoch 00048: val_weighted_dice_loss did not improve from 0.12263
Epoch 49/150
 - 1557s - loss: 0.0927 - weighted_dice_loss: 0.0927 - val_loss: 0.1273 - val_weighted_dice_loss: 0.1273

Epoch 00049: val_weighted_dice_loss did not improve from 0.12263
Epoch 50/150
 - 1557s - loss: 0.0921 - weighted_dice_loss: 0.0921 - val_loss: 0.1398 - val_weighted_dice_loss: 0.1398

Epoch 00050: val_weighted_dice_loss did not improve from 0.12263
Epoch 51/150
 - 1557s - loss: 0.0916 - weighted_dice_loss: 0.0916 - val_loss: 0.1243 - val_weighted_dice_loss: 0.1243

Epoch 00051: val_weighted_dice_loss did not improve from 0.12263
Epoch 52/150
 - 1558s - loss: 0.0909 - weighted_dice_loss: 0.0909 - val_loss: 0.1251 - val_weighted_dice_loss: 0.1251

Epoch 00052: val_weighted_dice_loss did not improve from 0.12263
Epoch 53/150
 - 1558s - loss: 0.0905 - weighted_dice_loss: 0.0905 - val_loss: 0.1237 - val_weighted_dice_loss: 0.1237

Epoch 00053: val_weighted_dice_loss did not improve from 0.12263
Epoch 54/150
 - 1557s - loss: 0.0901 - weighted_dice_loss: 0.0901 - val_loss: 0.1223 - val_weighted_dice_loss: 0.1223

Epoch 00054: val_weighted_dice_loss improved from 0.12263 to 0.12230, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 55/150
 - 1557s - loss: 0.0895 - weighted_dice_loss: 0.0895 - val_loss: 0.1255 - val_weighted_dice_loss: 0.1255

Epoch 00055: val_weighted_dice_loss did not improve from 0.12230
Epoch 56/150
 - 1557s - loss: 0.0891 - weighted_dice_loss: 0.0891 - val_loss: 0.1219 - val_weighted_dice_loss: 0.1219

Epoch 00056: val_weighted_dice_loss improved from 0.12230 to 0.12194, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 57/150
 - 1556s - loss: 0.0886 - weighted_dice_loss: 0.0886 - val_loss: 0.3096 - val_weighted_dice_loss: 0.3096

Epoch 00057: val_weighted_dice_loss did not improve from 0.12194
Epoch 58/150
 - 1557s - loss: 0.0882 - weighted_dice_loss: 0.0882 - val_loss: 0.1223 - val_weighted_dice_loss: 0.1223

Epoch 00058: val_weighted_dice_loss did not improve from 0.12194
Epoch 59/150
 - 1558s - loss: 0.0878 - weighted_dice_loss: 0.0878 - val_loss: 0.1196 - val_weighted_dice_loss: 0.1196

Epoch 00059: val_weighted_dice_loss improved from 0.12194 to 0.11964, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 60/150
 - 1558s - loss: 0.0873 - weighted_dice_loss: 0.0873 - val_loss: 0.1314 - val_weighted_dice_loss: 0.1314

Epoch 00060: val_weighted_dice_loss did not improve from 0.11964
Epoch 61/150
 - 1557s - loss: 0.0869 - weighted_dice_loss: 0.0869 - val_loss: 0.1237 - val_weighted_dice_loss: 0.1237

Epoch 00061: val_weighted_dice_loss did not improve from 0.11964
Epoch 62/150
 - 1558s - loss: 0.0864 - weighted_dice_loss: 0.0864 - val_loss: 0.1221 - val_weighted_dice_loss: 0.1221

Epoch 00062: val_weighted_dice_loss did not improve from 0.11964
Epoch 63/150
 - 1557s - loss: 0.0860 - weighted_dice_loss: 0.0860 - val_loss: 0.1230 - val_weighted_dice_loss: 0.1230

Epoch 00063: val_weighted_dice_loss did not improve from 0.11964
Epoch 64/150
 - 1557s - loss: 0.0855 - weighted_dice_loss: 0.0855 - val_loss: 0.1195 - val_weighted_dice_loss: 0.1195

Epoch 00064: val_weighted_dice_loss improved from 0.11964 to 0.11946, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 65/150
 - 1556s - loss: 0.0852 - weighted_dice_loss: 0.0852 - val_loss: 0.1215 - val_weighted_dice_loss: 0.1215

Epoch 00065: val_weighted_dice_loss did not improve from 0.11946
Epoch 66/150
 - 1557s - loss: 0.0850 - weighted_dice_loss: 0.0850 - val_loss: 0.1509 - val_weighted_dice_loss: 0.1509

Epoch 00066: val_weighted_dice_loss did not improve from 0.11946
Epoch 67/150
 - 1557s - loss: 0.0847 - weighted_dice_loss: 0.0847 - val_loss: 0.4189 - val_weighted_dice_loss: 0.4189

Epoch 00067: val_weighted_dice_loss did not improve from 0.11946
Epoch 68/150
 - 1558s - loss: 0.0843 - weighted_dice_loss: 0.0843 - val_loss: 0.1395 - val_weighted_dice_loss: 0.1395

Epoch 00068: val_weighted_dice_loss did not improve from 0.11946
Epoch 69/150
 - 1557s - loss: 0.0839 - weighted_dice_loss: 0.0839 - val_loss: 0.1236 - val_weighted_dice_loss: 0.1236

Epoch 00069: val_weighted_dice_loss did not improve from 0.11946
Epoch 70/150
 - 1557s - loss: 0.0836 - weighted_dice_loss: 0.0836 - val_loss: 0.3713 - val_weighted_dice_loss: 0.3713

Epoch 00070: val_weighted_dice_loss did not improve from 0.11946
Epoch 71/150
 - 1557s - loss: 0.0833 - weighted_dice_loss: 0.0833 - val_loss: 0.1167 - val_weighted_dice_loss: 0.1167

Epoch 00071: val_weighted_dice_loss improved from 0.11946 to 0.11675, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 72/150
 - 1556s - loss: 0.0827 - weighted_dice_loss: 0.0827 - val_loss: 0.1248 - val_weighted_dice_loss: 0.1248

Epoch 00072: val_weighted_dice_loss did not improve from 0.11675
Epoch 73/150
 - 1557s - loss: 0.0825 - weighted_dice_loss: 0.0825 - val_loss: 0.4072 - val_weighted_dice_loss: 0.4072

Epoch 00073: val_weighted_dice_loss did not improve from 0.11675
Epoch 74/150
 - 1558s - loss: 0.0821 - weighted_dice_loss: 0.0821 - val_loss: 0.1168 - val_weighted_dice_loss: 0.1168

Epoch 00074: val_weighted_dice_loss did not improve from 0.11675
Epoch 75/150
 - 1558s - loss: 0.0820 - weighted_dice_loss: 0.0820 - val_loss: 0.1153 - val_weighted_dice_loss: 0.1153

Epoch 00075: val_weighted_dice_loss improved from 0.11675 to 0.11527, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 76/150
 - 1558s - loss: 0.0816 - weighted_dice_loss: 0.0816 - val_loss: 0.1245 - val_weighted_dice_loss: 0.1245

Epoch 00076: val_weighted_dice_loss did not improve from 0.11527
Epoch 77/150
 - 1557s - loss: 0.0813 - weighted_dice_loss: 0.0813 - val_loss: 0.1242 - val_weighted_dice_loss: 0.1242

Epoch 00077: val_weighted_dice_loss did not improve from 0.11527
Epoch 78/150
 - 1557s - loss: 0.0810 - weighted_dice_loss: 0.0810 - val_loss: 0.1189 - val_weighted_dice_loss: 0.1189

Epoch 00078: val_weighted_dice_loss did not improve from 0.11527
Epoch 79/150
 - 1557s - loss: 0.0807 - weighted_dice_loss: 0.0807 - val_loss: 0.1179 - val_weighted_dice_loss: 0.1179

Epoch 00079: val_weighted_dice_loss did not improve from 0.11527
Epoch 80/150
 - 1558s - loss: 0.0805 - weighted_dice_loss: 0.0805 - val_loss: 0.1242 - val_weighted_dice_loss: 0.1242

Epoch 00080: val_weighted_dice_loss did not improve from 0.11527
Epoch 81/150
 - 1558s - loss: 0.0801 - weighted_dice_loss: 0.0801 - val_loss: 0.1166 - val_weighted_dice_loss: 0.1166

Epoch 00081: val_weighted_dice_loss did not improve from 0.11527
Epoch 82/150
 - 1558s - loss: 0.0797 - weighted_dice_loss: 0.0797 - val_loss: 0.1157 - val_weighted_dice_loss: 0.1157

Epoch 00082: val_weighted_dice_loss did not improve from 0.11527
Epoch 83/150
 - 1558s - loss: 0.0796 - weighted_dice_loss: 0.0796 - val_loss: 0.1738 - val_weighted_dice_loss: 0.1738

Epoch 00083: val_weighted_dice_loss did not improve from 0.11527
Epoch 84/150
 - 1557s - loss: 0.0793 - weighted_dice_loss: 0.0793 - val_loss: 0.2788 - val_weighted_dice_loss: 0.2788

Epoch 00084: val_weighted_dice_loss did not improve from 0.11527
Epoch 85/150
 - 1557s - loss: 0.0790 - weighted_dice_loss: 0.0790 - val_loss: 0.1140 - val_weighted_dice_loss: 0.1140

Epoch 00085: val_weighted_dice_loss improved from 0.11527 to 0.11400, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 86/150
 - 1558s - loss: 0.0788 - weighted_dice_loss: 0.0788 - val_loss: 0.5003 - val_weighted_dice_loss: 0.5003

Epoch 00086: val_weighted_dice_loss did not improve from 0.11400
Epoch 87/150
 - 1558s - loss: 0.0786 - weighted_dice_loss: 0.0786 - val_loss: 0.1145 - val_weighted_dice_loss: 0.1145

Epoch 00087: val_weighted_dice_loss did not improve from 0.11400
Epoch 88/150
 - 1558s - loss: 0.0783 - weighted_dice_loss: 0.0783 - val_loss: 0.1147 - val_weighted_dice_loss: 0.1147

Epoch 00088: val_weighted_dice_loss did not improve from 0.11400
Epoch 89/150
 - 1560s - loss: 0.0780 - weighted_dice_loss: 0.0780 - val_loss: 0.1146 - val_weighted_dice_loss: 0.1146

Epoch 00089: val_weighted_dice_loss did not improve from 0.11400
Epoch 90/150
 - 1557s - loss: 0.0777 - weighted_dice_loss: 0.0777 - val_loss: 0.1207 - val_weighted_dice_loss: 0.1207

Epoch 00090: val_weighted_dice_loss did not improve from 0.11400
Epoch 91/150
 - 1559s - loss: 0.0776 - weighted_dice_loss: 0.0776 - val_loss: 0.1550 - val_weighted_dice_loss: 0.1550

Epoch 00091: val_weighted_dice_loss did not improve from 0.11400
Epoch 92/150
 - 1558s - loss: 0.0773 - weighted_dice_loss: 0.0773 - val_loss: 0.1153 - val_weighted_dice_loss: 0.1153

Epoch 00092: val_weighted_dice_loss did not improve from 0.11400
Epoch 93/150
 - 1557s - loss: 0.0770 - weighted_dice_loss: 0.0770 - val_loss: 0.1496 - val_weighted_dice_loss: 0.1496

Epoch 00093: val_weighted_dice_loss did not improve from 0.11400
Epoch 94/150
 - 1556s - loss: 0.0769 - weighted_dice_loss: 0.0769 - val_loss: 0.1146 - val_weighted_dice_loss: 0.1146

Epoch 00094: val_weighted_dice_loss did not improve from 0.11400
Epoch 95/150
 - 1558s - loss: 0.0765 - weighted_dice_loss: 0.0765 - val_loss: 0.1636 - val_weighted_dice_loss: 0.1636

Epoch 00095: val_weighted_dice_loss did not improve from 0.11400
Epoch 96/150
 - 1558s - loss: 0.0763 - weighted_dice_loss: 0.0763 - val_loss: 0.1156 - val_weighted_dice_loss: 0.1156

Epoch 00096: val_weighted_dice_loss did not improve from 0.11400
Epoch 97/150
 - 1558s - loss: 0.0761 - weighted_dice_loss: 0.0761 - val_loss: 0.1240 - val_weighted_dice_loss: 0.1240

Epoch 00097: val_weighted_dice_loss did not improve from 0.11400
Epoch 98/150
 - 1560s - loss: 0.0759 - weighted_dice_loss: 0.0759 - val_loss: 0.1391 - val_weighted_dice_loss: 0.1391

Epoch 00098: val_weighted_dice_loss did not improve from 0.11400
Epoch 99/150
 - 1558s - loss: 0.0757 - weighted_dice_loss: 0.0757 - val_loss: 0.1136 - val_weighted_dice_loss: 0.1136

Epoch 00099: val_weighted_dice_loss improved from 0.11400 to 0.11358, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 100/150
 - 1559s - loss: 0.0755 - weighted_dice_loss: 0.0755 - val_loss: 0.1141 - val_weighted_dice_loss: 0.1141

Epoch 00100: val_weighted_dice_loss did not improve from 0.11358
Epoch 101/150
 - 1558s - loss: 0.0752 - weighted_dice_loss: 0.0752 - val_loss: 0.1171 - val_weighted_dice_loss: 0.1171

Epoch 00101: val_weighted_dice_loss did not improve from 0.11358
Epoch 102/150
 - 1558s - loss: 0.0750 - weighted_dice_loss: 0.0750 - val_loss: 0.2724 - val_weighted_dice_loss: 0.2724

Epoch 00102: val_weighted_dice_loss did not improve from 0.11358
Epoch 103/150
 - 1558s - loss: 0.0748 - weighted_dice_loss: 0.0748 - val_loss: 0.1197 - val_weighted_dice_loss: 0.1197

Epoch 00103: val_weighted_dice_loss did not improve from 0.11358
Epoch 104/150
 - 1559s - loss: 0.0746 - weighted_dice_loss: 0.0746 - val_loss: 0.1520 - val_weighted_dice_loss: 0.1520

Epoch 00104: val_weighted_dice_loss did not improve from 0.11358
Epoch 105/150
 - 1558s - loss: 0.0744 - weighted_dice_loss: 0.0744 - val_loss: 0.1158 - val_weighted_dice_loss: 0.1158

Epoch 00105: val_weighted_dice_loss did not improve from 0.11358
Epoch 106/150
 - 1559s - loss: 0.0743 - weighted_dice_loss: 0.0743 - val_loss: 0.2851 - val_weighted_dice_loss: 0.2851

Epoch 00106: val_weighted_dice_loss did not improve from 0.11358
Epoch 107/150
 - 1558s - loss: 0.0740 - weighted_dice_loss: 0.0740 - val_loss: 0.1212 - val_weighted_dice_loss: 0.1212

Epoch 00107: val_weighted_dice_loss did not improve from 0.11358
Epoch 108/150
 - 1558s - loss: 0.0738 - weighted_dice_loss: 0.0738 - val_loss: 0.2227 - val_weighted_dice_loss: 0.2227

Epoch 00108: val_weighted_dice_loss did not improve from 0.11358
Epoch 109/150
 - 1557s - loss: 0.0737 - weighted_dice_loss: 0.0737 - val_loss: 0.1140 - val_weighted_dice_loss: 0.1140

Epoch 00109: val_weighted_dice_loss did not improve from 0.11358
Epoch 110/150
 - 1557s - loss: 0.0734 - weighted_dice_loss: 0.0734 - val_loss: 0.5224 - val_weighted_dice_loss: 0.5224

Epoch 00110: val_weighted_dice_loss did not improve from 0.11358
Epoch 111/150
 - 1556s - loss: 0.0732 - weighted_dice_loss: 0.0732 - val_loss: 0.3628 - val_weighted_dice_loss: 0.3628

Epoch 00111: val_weighted_dice_loss did not improve from 0.11358
Epoch 112/150
 - 1558s - loss: 0.0731 - weighted_dice_loss: 0.0731 - val_loss: 0.1115 - val_weighted_dice_loss: 0.1115

Epoch 00112: val_weighted_dice_loss improved from 0.11358 to 0.11147, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 113/150
 - 1557s - loss: 0.0729 - weighted_dice_loss: 0.0729 - val_loss: 0.1175 - val_weighted_dice_loss: 0.1175

Epoch 00113: val_weighted_dice_loss did not improve from 0.11147
Epoch 114/150
 - 1560s - loss: 0.0727 - weighted_dice_loss: 0.0727 - val_loss: 0.1134 - val_weighted_dice_loss: 0.1134

Epoch 00114: val_weighted_dice_loss did not improve from 0.11147
Epoch 115/150
 - 1559s - loss: 0.0725 - weighted_dice_loss: 0.0725 - val_loss: 0.1174 - val_weighted_dice_loss: 0.1174

Epoch 00115: val_weighted_dice_loss did not improve from 0.11147
Epoch 116/150
 - 1558s - loss: 0.0723 - weighted_dice_loss: 0.0723 - val_loss: 0.1136 - val_weighted_dice_loss: 0.1136

Epoch 00116: val_weighted_dice_loss did not improve from 0.11147
Epoch 117/150
 - 1559s - loss: 0.0722 - weighted_dice_loss: 0.0722 - val_loss: 0.1181 - val_weighted_dice_loss: 0.1181

Epoch 00117: val_weighted_dice_loss did not improve from 0.11147
Epoch 118/150
 - 1557s - loss: 0.0720 - weighted_dice_loss: 0.0720 - val_loss: 0.3598 - val_weighted_dice_loss: 0.3598

Epoch 00118: val_weighted_dice_loss did not improve from 0.11147
Epoch 119/150
 - 1558s - loss: 0.0718 - weighted_dice_loss: 0.0718 - val_loss: 0.1160 - val_weighted_dice_loss: 0.1160

Epoch 00119: val_weighted_dice_loss did not improve from 0.11147
Epoch 120/150
 - 1558s - loss: 0.0717 - weighted_dice_loss: 0.0717 - val_loss: 0.1202 - val_weighted_dice_loss: 0.1202

Epoch 00120: val_weighted_dice_loss did not improve from 0.11147
Epoch 121/150
 - 1558s - loss: 0.0716 - weighted_dice_loss: 0.0716 - val_loss: 0.1156 - val_weighted_dice_loss: 0.1156

Epoch 00121: val_weighted_dice_loss did not improve from 0.11147
Epoch 122/150
 - 1559s - loss: 0.0712 - weighted_dice_loss: 0.0712 - val_loss: 0.1155 - val_weighted_dice_loss: 0.1155

Epoch 00122: val_weighted_dice_loss did not improve from 0.11147
Epoch 123/150
 - 1558s - loss: 0.0712 - weighted_dice_loss: 0.0712 - val_loss: 0.2704 - val_weighted_dice_loss: 0.2704

Epoch 00123: val_weighted_dice_loss did not improve from 0.11147
Epoch 124/150
 - 1558s - loss: 0.0710 - weighted_dice_loss: 0.0710 - val_loss: 0.1195 - val_weighted_dice_loss: 0.1195

Epoch 00124: val_weighted_dice_loss did not improve from 0.11147
Epoch 125/150
 - 1558s - loss: 0.0709 - weighted_dice_loss: 0.0709 - val_loss: 0.1152 - val_weighted_dice_loss: 0.1152

Epoch 00125: val_weighted_dice_loss did not improve from 0.11147
Epoch 126/150
 - 1559s - loss: 0.0708 - weighted_dice_loss: 0.0708 - val_loss: 0.1254 - val_weighted_dice_loss: 0.1254

Epoch 00126: val_weighted_dice_loss did not improve from 0.11147
Epoch 127/150
 - 1558s - loss: 0.0706 - weighted_dice_loss: 0.0706 - val_loss: 0.1374 - val_weighted_dice_loss: 0.1374

Epoch 00127: val_weighted_dice_loss did not improve from 0.11147
Epoch 128/150
 - 1559s - loss: 0.0704 - weighted_dice_loss: 0.0704 - val_loss: 0.5380 - val_weighted_dice_loss: 0.5380

Epoch 00128: val_weighted_dice_loss did not improve from 0.11147
Epoch 129/150
 - 1560s - loss: 0.0702 - weighted_dice_loss: 0.0702 - val_loss: 0.1878 - val_weighted_dice_loss: 0.1878

Epoch 00129: val_weighted_dice_loss did not improve from 0.11147
Epoch 130/150
 - 1558s - loss: 0.0701 - weighted_dice_loss: 0.0701 - val_loss: 0.8810 - val_weighted_dice_loss: 0.8810

Epoch 00130: val_weighted_dice_loss did not improve from 0.11147
Epoch 131/150
 - 1557s - loss: 0.0700 - weighted_dice_loss: 0.0700 - val_loss: 0.5709 - val_weighted_dice_loss: 0.5709

Epoch 00131: val_weighted_dice_loss did not improve from 0.11147
Epoch 132/150
 - 1559s - loss: 0.0698 - weighted_dice_loss: 0.0698 - val_loss: 0.1340 - val_weighted_dice_loss: 0.1340

Epoch 00132: val_weighted_dice_loss did not improve from 0.11147
Epoch 133/150
 - 1559s - loss: 0.0697 - weighted_dice_loss: 0.0697 - val_loss: 0.1343 - val_weighted_dice_loss: 0.1343

Epoch 00133: val_weighted_dice_loss did not improve from 0.11147
Epoch 134/150
 - 1559s - loss: 0.0694 - weighted_dice_loss: 0.0694 - val_loss: 0.3883 - val_weighted_dice_loss: 0.3883

Epoch 00134: val_weighted_dice_loss did not improve from 0.11147
Epoch 135/150
 - 1557s - loss: 0.0694 - weighted_dice_loss: 0.0694 - val_loss: 0.1130 - val_weighted_dice_loss: 0.1130

Epoch 00135: val_weighted_dice_loss did not improve from 0.11147
Epoch 136/150
 - 1558s - loss: 0.0692 - weighted_dice_loss: 0.0692 - val_loss: 0.1107 - val_weighted_dice_loss: 0.1107

Epoch 00136: val_weighted_dice_loss improved from 0.11147 to 0.11069, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 137/150
 - 1558s - loss: 0.0692 - weighted_dice_loss: 0.0692 - val_loss: 0.3029 - val_weighted_dice_loss: 0.3029

Epoch 00137: val_weighted_dice_loss did not improve from 0.11069
Epoch 138/150
 - 1557s - loss: 0.0690 - weighted_dice_loss: 0.0690 - val_loss: 0.1108 - val_weighted_dice_loss: 0.1108

Epoch 00138: val_weighted_dice_loss did not improve from 0.11069
Epoch 139/150
 - 1559s - loss: 0.0688 - weighted_dice_loss: 0.0688 - val_loss: 0.1342 - val_weighted_dice_loss: 0.1342

Epoch 00139: val_weighted_dice_loss did not improve from 0.11069
Epoch 140/150
 - 1560s - loss: 0.0687 - weighted_dice_loss: 0.0687 - val_loss: 0.1097 - val_weighted_dice_loss: 0.1097

Epoch 00140: val_weighted_dice_loss improved from 0.11069 to 0.10973, saving model to ./Unet-weights/7_classes_26040_reals_23960_GANs.h5
Epoch 141/150
 - 1557s - loss: 0.0686 - weighted_dice_loss: 0.0686 - val_loss: 0.1133 - val_weighted_dice_loss: 0.1133

Epoch 00141: val_weighted_dice_loss did not improve from 0.10973
Epoch 142/150
 - 1558s - loss: 0.0684 - weighted_dice_loss: 0.0684 - val_loss: 0.1215 - val_weighted_dice_loss: 0.1215

Epoch 00142: val_weighted_dice_loss did not improve from 0.10973
Epoch 143/150
 - 1558s - loss: 0.0683 - weighted_dice_loss: 0.0683 - val_loss: 0.1138 - val_weighted_dice_loss: 0.1138

Epoch 00143: val_weighted_dice_loss did not improve from 0.10973
Epoch 144/150
 - 1559s - loss: 0.0682 - weighted_dice_loss: 0.0682 - val_loss: 0.1176 - val_weighted_dice_loss: 0.1176

Epoch 00144: val_weighted_dice_loss did not improve from 0.10973
Epoch 145/150
 - 1558s - loss: 0.0680 - weighted_dice_loss: 0.0680 - val_loss: 0.1103 - val_weighted_dice_loss: 0.1103

Epoch 00145: val_weighted_dice_loss did not improve from 0.10973
Epoch 146/150
 - 1558s - loss: 0.0679 - weighted_dice_loss: 0.0679 - val_loss: 0.4295 - val_weighted_dice_loss: 0.4295

Epoch 00146: val_weighted_dice_loss did not improve from 0.10973
Epoch 147/150
 - 1558s - loss: 0.0677 - weighted_dice_loss: 0.0677 - val_loss: 0.1193 - val_weighted_dice_loss: 0.1193

Epoch 00147: val_weighted_dice_loss did not improve from 0.10973
Epoch 148/150
 - 1558s - loss: 0.0676 - weighted_dice_loss: 0.0676 - val_loss: 0.2664 - val_weighted_dice_loss: 0.2664

Epoch 00148: val_weighted_dice_loss did not improve from 0.10973
Epoch 149/150
 - 1559s - loss: 0.0675 - weighted_dice_loss: 0.0675 - val_loss: 0.1125 - val_weighted_dice_loss: 0.1125

Epoch 00149: val_weighted_dice_loss did not improve from 0.10973
Epoch 150/150
 - 1558s - loss: 0.0673 - weighted_dice_loss: 0.0673 - val_loss: 0.1136 - val_weighted_dice_loss: 0.1136

Epoch 00150: val_weighted_dice_loss did not improve from 0.10973
Finished training.
