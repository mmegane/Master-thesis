2020-05-17 21:06:09.667477: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-05-17 21:06:09.687032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz
2020-05-17 21:06:09.688064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596b50b07f0 executing computations on platform Host. Devices:
2020-05-17 21:06:09.688125: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-05-17 21:06:09.690059: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-05-17 21:06:09.849879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.850237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-05-17 21:06:09.850276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.850555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-05-17 21:06:09.851859: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-17 21:06:09.854937: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-05-17 21:06:09.856997: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-05-17 21:06:09.858392: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-05-17 21:06:09.860538: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-05-17 21:06:09.861850: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-05-17 21:06:09.864853: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-17 21:06:09.864925: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.865305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.865608: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.865942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.866216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-17 21:06:09.866234: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-17 21:06:09.867580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-17 21:06:09.867592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-17 21:06:09.867600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-05-17 21:06:09.867608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-05-17 21:06:09.867688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.868031: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.868328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.868671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.869000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-05-17 21:06:09.869348: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.869652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.869928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7507 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-05-17 21:06:09.871198: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5596b63f3260 executing computations on platform CUDA. Devices:
2020-05-17 21:06:09.871209: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-05-17 21:06:09.871214: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
WARNING:tensorflow:From segmentation.py:18: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

WARNING:tensorflow:From segmentation.py:31: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From segmentation.py:33: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-05-17 21:06:09.872030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.872354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.65
pciBusID: 0000:02:00.0
2020-05-17 21:06:09.872388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.872664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: GeForce GTX 1070 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.683
pciBusID: 0000:01:00.0
2020-05-17 21:06:09.872682: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.1
2020-05-17 21:06:09.872691: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
2020-05-17 21:06:09.872699: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10
2020-05-17 21:06:09.872707: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10
2020-05-17 21:06:09.872714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10
2020-05-17 21:06:09.872724: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10
2020-05-17 21:06:09.872732: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-05-17 21:06:09.872761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.873095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.873387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.873723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.873993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0, 1
2020-05-17 21:06:09.874009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-05-17 21:06:09.874014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 
2020-05-17 21:06:09.874019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N N 
2020-05-17 21:06:09.874022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   N N 
2020-05-17 21:06:09.874076: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.874412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.874744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.875060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10311 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)
2020-05-17 21:06:09.875094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-05-17 21:06:09.875367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7507 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/mehfo331/.conda/envs/thesis/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

2020-05-17 21:06:56.359057: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
Epoch 1/150
 - 1164s - loss: 0.4834 - weighted_dice_loss: 0.4865 - val_loss: 0.5743 - val_weighted_dice_loss: 0.5775

Epoch 00001: val_weighted_dice_loss improved from inf to 0.57752, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 2/150
 - 1124s - loss: 0.3145 - weighted_dice_loss: 0.3177 - val_loss: 0.2850 - val_weighted_dice_loss: 0.2886

Epoch 00002: val_weighted_dice_loss improved from 0.57752 to 0.28861, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 3/150
 - 1127s - loss: 0.2353 - weighted_dice_loss: 0.2383 - val_loss: 0.2591 - val_weighted_dice_loss: 0.2626

Epoch 00003: val_weighted_dice_loss improved from 0.28861 to 0.26256, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 4/150
 - 1126s - loss: 0.2226 - weighted_dice_loss: 0.2255 - val_loss: 0.2346 - val_weighted_dice_loss: 0.2377

Epoch 00004: val_weighted_dice_loss improved from 0.26256 to 0.23773, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 5/150
 - 1126s - loss: 0.2112 - weighted_dice_loss: 0.2140 - val_loss: 0.2236 - val_weighted_dice_loss: 0.2268

Epoch 00005: val_weighted_dice_loss improved from 0.23773 to 0.22683, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 6/150
 - 1126s - loss: 0.2028 - weighted_dice_loss: 0.2055 - val_loss: 0.2282 - val_weighted_dice_loss: 0.2313

Epoch 00006: val_weighted_dice_loss did not improve from 0.22683
Epoch 7/150
 - 1127s - loss: 0.1965 - weighted_dice_loss: 0.1992 - val_loss: 0.2118 - val_weighted_dice_loss: 0.2146

Epoch 00007: val_weighted_dice_loss improved from 0.22683 to 0.21463, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 8/150
 - 1126s - loss: 0.1900 - weighted_dice_loss: 0.1925 - val_loss: 0.2231 - val_weighted_dice_loss: 0.2260

Epoch 00008: val_weighted_dice_loss did not improve from 0.21463
Epoch 9/150
 - 1125s - loss: 0.1841 - weighted_dice_loss: 0.1866 - val_loss: 0.2136 - val_weighted_dice_loss: 0.2163

Epoch 00009: val_weighted_dice_loss did not improve from 0.21463
Epoch 10/150
 - 1125s - loss: 0.1788 - weighted_dice_loss: 0.1813 - val_loss: 0.2116 - val_weighted_dice_loss: 0.2146

Epoch 00010: val_weighted_dice_loss improved from 0.21463 to 0.21463, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 11/150
 - 1125s - loss: 0.1743 - weighted_dice_loss: 0.1767 - val_loss: 0.1973 - val_weighted_dice_loss: 0.2000

Epoch 00011: val_weighted_dice_loss improved from 0.21463 to 0.20001, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 12/150
 - 1126s - loss: 0.1695 - weighted_dice_loss: 0.1719 - val_loss: 0.1894 - val_weighted_dice_loss: 0.1921

Epoch 00012: val_weighted_dice_loss improved from 0.20001 to 0.19214, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 13/150
 - 1128s - loss: 0.1652 - weighted_dice_loss: 0.1675 - val_loss: 0.1827 - val_weighted_dice_loss: 0.1854

Epoch 00013: val_weighted_dice_loss improved from 0.19214 to 0.18538, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 14/150
 - 1125s - loss: 0.1613 - weighted_dice_loss: 0.1635 - val_loss: 0.1894 - val_weighted_dice_loss: 0.1922

Epoch 00014: val_weighted_dice_loss did not improve from 0.18538
Epoch 15/150
 - 1126s - loss: 0.1574 - weighted_dice_loss: 0.1596 - val_loss: 0.1795 - val_weighted_dice_loss: 0.1820

Epoch 00015: val_weighted_dice_loss improved from 0.18538 to 0.18203, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 16/150
 - 1126s - loss: 0.1547 - weighted_dice_loss: 0.1569 - val_loss: 0.1857 - val_weighted_dice_loss: 0.1883

Epoch 00016: val_weighted_dice_loss did not improve from 0.18203
Epoch 17/150
 - 1125s - loss: 0.1507 - weighted_dice_loss: 0.1528 - val_loss: 0.1922 - val_weighted_dice_loss: 0.1948

Epoch 00017: val_weighted_dice_loss did not improve from 0.18203
Epoch 18/150
 - 1125s - loss: 0.1487 - weighted_dice_loss: 0.1508 - val_loss: 0.1753 - val_weighted_dice_loss: 0.1778

Epoch 00018: val_weighted_dice_loss improved from 0.18203 to 0.17783, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 19/150
 - 1125s - loss: 0.1460 - weighted_dice_loss: 0.1480 - val_loss: 0.1686 - val_weighted_dice_loss: 0.1710

Epoch 00019: val_weighted_dice_loss improved from 0.17783 to 0.17104, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 20/150
 - 1125s - loss: 0.1435 - weighted_dice_loss: 0.1455 - val_loss: 0.1773 - val_weighted_dice_loss: 0.1799

Epoch 00020: val_weighted_dice_loss did not improve from 0.17104
Epoch 21/150
 - 1125s - loss: 0.1413 - weighted_dice_loss: 0.1433 - val_loss: 0.1665 - val_weighted_dice_loss: 0.1689

Epoch 00021: val_weighted_dice_loss improved from 0.17104 to 0.16891, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 22/150
 - 1125s - loss: 0.1392 - weighted_dice_loss: 0.1412 - val_loss: 0.1626 - val_weighted_dice_loss: 0.1649

Epoch 00022: val_weighted_dice_loss improved from 0.16891 to 0.16493, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 23/150
 - 1125s - loss: 0.1374 - weighted_dice_loss: 0.1393 - val_loss: 0.1632 - val_weighted_dice_loss: 0.1655

Epoch 00023: val_weighted_dice_loss did not improve from 0.16493
Epoch 24/150
 - 1125s - loss: 0.1355 - weighted_dice_loss: 0.1374 - val_loss: 0.1675 - val_weighted_dice_loss: 0.1699

Epoch 00024: val_weighted_dice_loss did not improve from 0.16493
Epoch 25/150
 - 1125s - loss: 0.1336 - weighted_dice_loss: 0.1355 - val_loss: 0.1627 - val_weighted_dice_loss: 0.1651

Epoch 00025: val_weighted_dice_loss did not improve from 0.16493
Epoch 26/150
 - 1125s - loss: 0.1320 - weighted_dice_loss: 0.1339 - val_loss: 0.1553 - val_weighted_dice_loss: 0.1576

Epoch 00026: val_weighted_dice_loss improved from 0.16493 to 0.15756, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 27/150
 - 1125s - loss: 0.1304 - weighted_dice_loss: 0.1322 - val_loss: 0.1594 - val_weighted_dice_loss: 0.1617

Epoch 00027: val_weighted_dice_loss did not improve from 0.15756
Epoch 28/150
 - 1125s - loss: 0.1290 - weighted_dice_loss: 0.1308 - val_loss: 0.1614 - val_weighted_dice_loss: 0.1636

Epoch 00028: val_weighted_dice_loss did not improve from 0.15756
Epoch 29/150
 - 1125s - loss: 0.1275 - weighted_dice_loss: 0.1293 - val_loss: 0.1614 - val_weighted_dice_loss: 0.1636

Epoch 00029: val_weighted_dice_loss did not improve from 0.15756
Epoch 30/150
 - 1126s - loss: 0.1263 - weighted_dice_loss: 0.1281 - val_loss: 0.1717 - val_weighted_dice_loss: 0.1742

Epoch 00030: val_weighted_dice_loss did not improve from 0.15756
Epoch 31/150
 - 1125s - loss: 0.1250 - weighted_dice_loss: 0.1267 - val_loss: 0.1495 - val_weighted_dice_loss: 0.1516

Epoch 00031: val_weighted_dice_loss improved from 0.15756 to 0.15162, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 32/150
 - 1125s - loss: 0.1240 - weighted_dice_loss: 0.1258 - val_loss: 0.1529 - val_weighted_dice_loss: 0.1551

Epoch 00032: val_weighted_dice_loss did not improve from 0.15162
Epoch 33/150
 - 1125s - loss: 0.1224 - weighted_dice_loss: 0.1241 - val_loss: 0.1434 - val_weighted_dice_loss: 0.1454

Epoch 00033: val_weighted_dice_loss improved from 0.15162 to 0.14540, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 34/150
 - 1125s - loss: 0.1215 - weighted_dice_loss: 0.1233 - val_loss: 0.1484 - val_weighted_dice_loss: 0.1506

Epoch 00034: val_weighted_dice_loss did not improve from 0.14540
Epoch 35/150
 - 1126s - loss: 0.1204 - weighted_dice_loss: 0.1221 - val_loss: 0.1460 - val_weighted_dice_loss: 0.1481

Epoch 00035: val_weighted_dice_loss did not improve from 0.14540
Epoch 36/150
 - 1125s - loss: 0.1194 - weighted_dice_loss: 0.1211 - val_loss: 0.1520 - val_weighted_dice_loss: 0.1542

Epoch 00036: val_weighted_dice_loss did not improve from 0.14540
Epoch 37/150
 - 1125s - loss: 0.1183 - weighted_dice_loss: 0.1200 - val_loss: 0.1460 - val_weighted_dice_loss: 0.1482

Epoch 00037: val_weighted_dice_loss did not improve from 0.14540
Epoch 38/150
 - 1125s - loss: 0.1175 - weighted_dice_loss: 0.1191 - val_loss: 0.1394 - val_weighted_dice_loss: 0.1413

Epoch 00038: val_weighted_dice_loss improved from 0.14540 to 0.14134, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 39/150
 - 1125s - loss: 0.1165 - weighted_dice_loss: 0.1182 - val_loss: 0.1566 - val_weighted_dice_loss: 0.1588

Epoch 00039: val_weighted_dice_loss did not improve from 0.14134
Epoch 40/150
 - 1125s - loss: 0.1157 - weighted_dice_loss: 0.1174 - val_loss: 0.1478 - val_weighted_dice_loss: 0.1499

Epoch 00040: val_weighted_dice_loss did not improve from 0.14134
Epoch 41/150
 - 1125s - loss: 0.1147 - weighted_dice_loss: 0.1163 - val_loss: 0.1480 - val_weighted_dice_loss: 0.1501

Epoch 00041: val_weighted_dice_loss did not improve from 0.14134
Epoch 42/150
 - 1125s - loss: 0.1139 - weighted_dice_loss: 0.1155 - val_loss: 0.1383 - val_weighted_dice_loss: 0.1403

Epoch 00042: val_weighted_dice_loss improved from 0.14134 to 0.14032, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 43/150
 - 1125s - loss: 0.1132 - weighted_dice_loss: 0.1148 - val_loss: 0.1434 - val_weighted_dice_loss: 0.1455

Epoch 00043: val_weighted_dice_loss did not improve from 0.14032
Epoch 44/150
 - 1125s - loss: 0.1123 - weighted_dice_loss: 0.1140 - val_loss: 0.1413 - val_weighted_dice_loss: 0.1433

Epoch 00044: val_weighted_dice_loss did not improve from 0.14032
Epoch 45/150
 - 1125s - loss: 0.1114 - weighted_dice_loss: 0.1130 - val_loss: 0.1470 - val_weighted_dice_loss: 0.1490

Epoch 00045: val_weighted_dice_loss did not improve from 0.14032
Epoch 46/150
 - 1125s - loss: 0.1109 - weighted_dice_loss: 0.1125 - val_loss: 0.1369 - val_weighted_dice_loss: 0.1389

Epoch 00046: val_weighted_dice_loss improved from 0.14032 to 0.13887, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 47/150
 - 1126s - loss: 0.1101 - weighted_dice_loss: 0.1117 - val_loss: 0.1437 - val_weighted_dice_loss: 0.1458

Epoch 00047: val_weighted_dice_loss did not improve from 0.13887
Epoch 48/150
 - 1125s - loss: 0.1094 - weighted_dice_loss: 0.1110 - val_loss: 0.1458 - val_weighted_dice_loss: 0.1479

Epoch 00048: val_weighted_dice_loss did not improve from 0.13887
Epoch 49/150
 - 1126s - loss: 0.1086 - weighted_dice_loss: 0.1102 - val_loss: 0.1397 - val_weighted_dice_loss: 0.1417

Epoch 00049: val_weighted_dice_loss did not improve from 0.13887
Epoch 50/150
 - 1126s - loss: 0.1080 - weighted_dice_loss: 0.1096 - val_loss: 0.1365 - val_weighted_dice_loss: 0.1385

Epoch 00050: val_weighted_dice_loss improved from 0.13887 to 0.13848, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 51/150
 - 1126s - loss: 0.1074 - weighted_dice_loss: 0.1089 - val_loss: 0.1363 - val_weighted_dice_loss: 0.1382

Epoch 00051: val_weighted_dice_loss improved from 0.13848 to 0.13820, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 52/150
 - 1126s - loss: 0.1069 - weighted_dice_loss: 0.1085 - val_loss: 0.1668 - val_weighted_dice_loss: 0.1691

Epoch 00052: val_weighted_dice_loss did not improve from 0.13820
Epoch 53/150
 - 1125s - loss: 0.1063 - weighted_dice_loss: 0.1079 - val_loss: 0.1318 - val_weighted_dice_loss: 0.1337

Epoch 00053: val_weighted_dice_loss improved from 0.13820 to 0.13369, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 54/150
 - 1125s - loss: 0.1056 - weighted_dice_loss: 0.1071 - val_loss: 0.1356 - val_weighted_dice_loss: 0.1375

Epoch 00054: val_weighted_dice_loss did not improve from 0.13369
Epoch 55/150
 - 1125s - loss: 0.1049 - weighted_dice_loss: 0.1064 - val_loss: 0.1351 - val_weighted_dice_loss: 0.1371

Epoch 00055: val_weighted_dice_loss did not improve from 0.13369
Epoch 56/150
 - 1126s - loss: 0.1045 - weighted_dice_loss: 0.1060 - val_loss: 0.1392 - val_weighted_dice_loss: 0.1411

Epoch 00056: val_weighted_dice_loss did not improve from 0.13369
Epoch 57/150
 - 1126s - loss: 0.1039 - weighted_dice_loss: 0.1054 - val_loss: 0.1302 - val_weighted_dice_loss: 0.1320

Epoch 00057: val_weighted_dice_loss improved from 0.13369 to 0.13201, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 58/150
 - 1126s - loss: 0.1034 - weighted_dice_loss: 0.1049 - val_loss: 0.1355 - val_weighted_dice_loss: 0.1375

Epoch 00058: val_weighted_dice_loss did not improve from 0.13201
Epoch 59/150
 - 1125s - loss: 0.1030 - weighted_dice_loss: 0.1045 - val_loss: 0.1385 - val_weighted_dice_loss: 0.1405

Epoch 00059: val_weighted_dice_loss did not improve from 0.13201
Epoch 60/150
 - 1126s - loss: 0.1024 - weighted_dice_loss: 0.1038 - val_loss: 0.1355 - val_weighted_dice_loss: 0.1375

Epoch 00060: val_weighted_dice_loss did not improve from 0.13201
Epoch 61/150
 - 1125s - loss: 0.1019 - weighted_dice_loss: 0.1034 - val_loss: 0.1313 - val_weighted_dice_loss: 0.1331

Epoch 00061: val_weighted_dice_loss did not improve from 0.13201
Epoch 62/150
 - 1125s - loss: 0.1014 - weighted_dice_loss: 0.1029 - val_loss: 0.1329 - val_weighted_dice_loss: 0.1348

Epoch 00062: val_weighted_dice_loss did not improve from 0.13201
Epoch 63/150
 - 1125s - loss: 0.1009 - weighted_dice_loss: 0.1024 - val_loss: 0.1296 - val_weighted_dice_loss: 0.1314

Epoch 00063: val_weighted_dice_loss improved from 0.13201 to 0.13141, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 64/150
 - 1126s - loss: 0.1005 - weighted_dice_loss: 0.1019 - val_loss: 0.1437 - val_weighted_dice_loss: 0.1457

Epoch 00064: val_weighted_dice_loss did not improve from 0.13141
Epoch 65/150
 - 1125s - loss: 0.1000 - weighted_dice_loss: 0.1014 - val_loss: 0.1297 - val_weighted_dice_loss: 0.1316

Epoch 00065: val_weighted_dice_loss did not improve from 0.13141
Epoch 66/150
 - 1125s - loss: 0.0997 - weighted_dice_loss: 0.1011 - val_loss: 0.1258 - val_weighted_dice_loss: 0.1276

Epoch 00066: val_weighted_dice_loss improved from 0.13141 to 0.12763, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 67/150
 - 1125s - loss: 0.0991 - weighted_dice_loss: 0.1006 - val_loss: 0.1306 - val_weighted_dice_loss: 0.1324

Epoch 00067: val_weighted_dice_loss did not improve from 0.12763
Epoch 68/150
 - 1125s - loss: 0.0987 - weighted_dice_loss: 0.1001 - val_loss: 0.1263 - val_weighted_dice_loss: 0.1281

Epoch 00068: val_weighted_dice_loss did not improve from 0.12763
Epoch 69/150
 - 1125s - loss: 0.0984 - weighted_dice_loss: 0.0998 - val_loss: 0.1422 - val_weighted_dice_loss: 0.1441

Epoch 00069: val_weighted_dice_loss did not improve from 0.12763
Epoch 70/150
 - 1126s - loss: 0.0980 - weighted_dice_loss: 0.0994 - val_loss: 0.1316 - val_weighted_dice_loss: 0.1335

Epoch 00070: val_weighted_dice_loss did not improve from 0.12763
Epoch 71/150
 - 1126s - loss: 0.0973 - weighted_dice_loss: 0.0987 - val_loss: 0.1318 - val_weighted_dice_loss: 0.1338

Epoch 00071: val_weighted_dice_loss did not improve from 0.12763
Epoch 72/150
 - 1125s - loss: 0.0972 - weighted_dice_loss: 0.0986 - val_loss: 0.1311 - val_weighted_dice_loss: 0.1330

Epoch 00072: val_weighted_dice_loss did not improve from 0.12763
Epoch 73/150
 - 1125s - loss: 0.0967 - weighted_dice_loss: 0.0981 - val_loss: 0.1388 - val_weighted_dice_loss: 0.1408

Epoch 00073: val_weighted_dice_loss did not improve from 0.12763
Epoch 74/150
 - 1125s - loss: 0.0963 - weighted_dice_loss: 0.0977 - val_loss: 0.1277 - val_weighted_dice_loss: 0.1295

Epoch 00074: val_weighted_dice_loss did not improve from 0.12763
Epoch 75/150
 - 1126s - loss: 0.0960 - weighted_dice_loss: 0.0974 - val_loss: 0.1329 - val_weighted_dice_loss: 0.1348

Epoch 00075: val_weighted_dice_loss did not improve from 0.12763
Epoch 76/150
 - 1125s - loss: 0.0957 - weighted_dice_loss: 0.0971 - val_loss: 0.1284 - val_weighted_dice_loss: 0.1302

Epoch 00076: val_weighted_dice_loss did not improve from 0.12763
Epoch 77/150
 - 1126s - loss: 0.0953 - weighted_dice_loss: 0.0966 - val_loss: 0.1244 - val_weighted_dice_loss: 0.1261

Epoch 00077: val_weighted_dice_loss improved from 0.12763 to 0.12613, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 78/150
 - 1127s - loss: 0.0948 - weighted_dice_loss: 0.0962 - val_loss: 0.1372 - val_weighted_dice_loss: 0.1391

Epoch 00078: val_weighted_dice_loss did not improve from 0.12613
Epoch 79/150
 - 1125s - loss: 0.0946 - weighted_dice_loss: 0.0959 - val_loss: 0.1243 - val_weighted_dice_loss: 0.1261

Epoch 00079: val_weighted_dice_loss improved from 0.12613 to 0.12611, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 80/150
 - 1126s - loss: 0.0942 - weighted_dice_loss: 0.0956 - val_loss: 0.1265 - val_weighted_dice_loss: 0.1283

Epoch 00080: val_weighted_dice_loss did not improve from 0.12611
Epoch 81/150
 - 1126s - loss: 0.0938 - weighted_dice_loss: 0.0952 - val_loss: 0.1282 - val_weighted_dice_loss: 0.1300

Epoch 00081: val_weighted_dice_loss did not improve from 0.12611
Epoch 82/150
 - 1126s - loss: 0.0935 - weighted_dice_loss: 0.0949 - val_loss: 0.1241 - val_weighted_dice_loss: 0.1259

Epoch 00082: val_weighted_dice_loss improved from 0.12611 to 0.12589, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 83/150
 - 1125s - loss: 0.0931 - weighted_dice_loss: 0.0945 - val_loss: 0.1281 - val_weighted_dice_loss: 0.1299

Epoch 00083: val_weighted_dice_loss did not improve from 0.12589
Epoch 84/150
 - 1126s - loss: 0.0930 - weighted_dice_loss: 0.0943 - val_loss: 0.1265 - val_weighted_dice_loss: 0.1283

Epoch 00084: val_weighted_dice_loss did not improve from 0.12589
Epoch 85/150
 - 1125s - loss: 0.0925 - weighted_dice_loss: 0.0938 - val_loss: 0.1295 - val_weighted_dice_loss: 0.1313

Epoch 00085: val_weighted_dice_loss did not improve from 0.12589
Epoch 86/150
 - 1126s - loss: 0.0924 - weighted_dice_loss: 0.0937 - val_loss: 0.1330 - val_weighted_dice_loss: 0.1349

Epoch 00086: val_weighted_dice_loss did not improve from 0.12589
Epoch 87/150
 - 1126s - loss: 0.0921 - weighted_dice_loss: 0.0934 - val_loss: 0.1226 - val_weighted_dice_loss: 0.1244

Epoch 00087: val_weighted_dice_loss improved from 0.12589 to 0.12436, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 88/150
 - 1125s - loss: 0.0917 - weighted_dice_loss: 0.0930 - val_loss: 0.1258 - val_weighted_dice_loss: 0.1275

Epoch 00088: val_weighted_dice_loss did not improve from 0.12436
Epoch 89/150
 - 1126s - loss: 0.0915 - weighted_dice_loss: 0.0929 - val_loss: 0.1226 - val_weighted_dice_loss: 0.1244

Epoch 00089: val_weighted_dice_loss did not improve from 0.12436
Epoch 90/150
 - 1126s - loss: 0.0912 - weighted_dice_loss: 0.0925 - val_loss: 0.1295 - val_weighted_dice_loss: 0.1313

Epoch 00090: val_weighted_dice_loss did not improve from 0.12436
Epoch 91/150
 - 1126s - loss: 0.0909 - weighted_dice_loss: 0.0922 - val_loss: 0.1335 - val_weighted_dice_loss: 0.1353

Epoch 00091: val_weighted_dice_loss did not improve from 0.12436
Epoch 92/150
 - 1126s - loss: 0.0907 - weighted_dice_loss: 0.0920 - val_loss: 0.1331 - val_weighted_dice_loss: 0.1349

Epoch 00092: val_weighted_dice_loss did not improve from 0.12436
Epoch 93/150
 - 1126s - loss: 0.0903 - weighted_dice_loss: 0.0916 - val_loss: 0.1295 - val_weighted_dice_loss: 0.1315

Epoch 00093: val_weighted_dice_loss did not improve from 0.12436
Epoch 94/150
 - 1125s - loss: 0.0899 - weighted_dice_loss: 0.0912 - val_loss: 0.1246 - val_weighted_dice_loss: 0.1264

Epoch 00094: val_weighted_dice_loss did not improve from 0.12436
Epoch 95/150
 - 1125s - loss: 0.0897 - weighted_dice_loss: 0.0910 - val_loss: 0.1245 - val_weighted_dice_loss: 0.1262

Epoch 00095: val_weighted_dice_loss did not improve from 0.12436
Epoch 96/150
 - 1125s - loss: 0.0895 - weighted_dice_loss: 0.0908 - val_loss: 0.1221 - val_weighted_dice_loss: 0.1239

Epoch 00096: val_weighted_dice_loss improved from 0.12436 to 0.12386, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 97/150
 - 1126s - loss: 0.0893 - weighted_dice_loss: 0.0906 - val_loss: 0.1285 - val_weighted_dice_loss: 0.1302

Epoch 00097: val_weighted_dice_loss did not improve from 0.12386
Epoch 98/150
 - 1125s - loss: 0.0890 - weighted_dice_loss: 0.0903 - val_loss: 0.1255 - val_weighted_dice_loss: 0.1273

Epoch 00098: val_weighted_dice_loss did not improve from 0.12386
Epoch 99/150
 - 1126s - loss: 0.0887 - weighted_dice_loss: 0.0900 - val_loss: 0.1213 - val_weighted_dice_loss: 0.1230

Epoch 00099: val_weighted_dice_loss improved from 0.12386 to 0.12297, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 100/150
 - 1125s - loss: 0.0885 - weighted_dice_loss: 0.0898 - val_loss: 0.1278 - val_weighted_dice_loss: 0.1297

Epoch 00100: val_weighted_dice_loss did not improve from 0.12297
Epoch 101/150
 - 1126s - loss: 0.0883 - weighted_dice_loss: 0.0896 - val_loss: 0.1263 - val_weighted_dice_loss: 0.1282

Epoch 00101: val_weighted_dice_loss did not improve from 0.12297
Epoch 102/150
 - 1126s - loss: 0.0881 - weighted_dice_loss: 0.0893 - val_loss: 0.1300 - val_weighted_dice_loss: 0.1318

Epoch 00102: val_weighted_dice_loss did not improve from 0.12297
Epoch 103/150
 - 1126s - loss: 0.0877 - weighted_dice_loss: 0.0890 - val_loss: 0.1295 - val_weighted_dice_loss: 0.1314

Epoch 00103: val_weighted_dice_loss did not improve from 0.12297
Epoch 104/150
 - 1126s - loss: 0.0876 - weighted_dice_loss: 0.0889 - val_loss: 0.1262 - val_weighted_dice_loss: 0.1280

Epoch 00104: val_weighted_dice_loss did not improve from 0.12297
Epoch 105/150
 - 1125s - loss: 0.0873 - weighted_dice_loss: 0.0886 - val_loss: 0.1203 - val_weighted_dice_loss: 0.1220

Epoch 00105: val_weighted_dice_loss improved from 0.12297 to 0.12198, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 106/150
 - 1125s - loss: 0.0872 - weighted_dice_loss: 0.0885 - val_loss: 0.1246 - val_weighted_dice_loss: 0.1264

Epoch 00106: val_weighted_dice_loss did not improve from 0.12198
Epoch 107/150
 - 1124s - loss: 0.0869 - weighted_dice_loss: 0.0882 - val_loss: 0.1294 - val_weighted_dice_loss: 0.1313

Epoch 00107: val_weighted_dice_loss did not improve from 0.12198
Epoch 108/150
 - 1126s - loss: 0.0868 - weighted_dice_loss: 0.0880 - val_loss: 0.1234 - val_weighted_dice_loss: 0.1252

Epoch 00108: val_weighted_dice_loss did not improve from 0.12198
Epoch 109/150
 - 1125s - loss: 0.0865 - weighted_dice_loss: 0.0878 - val_loss: 0.1231 - val_weighted_dice_loss: 0.1249

Epoch 00109: val_weighted_dice_loss did not improve from 0.12198
Epoch 110/150
 - 1125s - loss: 0.0862 - weighted_dice_loss: 0.0875 - val_loss: 0.1223 - val_weighted_dice_loss: 0.1240

Epoch 00110: val_weighted_dice_loss did not improve from 0.12198
Epoch 111/150
 - 1125s - loss: 0.0861 - weighted_dice_loss: 0.0873 - val_loss: 0.1340 - val_weighted_dice_loss: 0.1358

Epoch 00111: val_weighted_dice_loss did not improve from 0.12198
Epoch 112/150
 - 1125s - loss: 0.0859 - weighted_dice_loss: 0.0871 - val_loss: 0.1227 - val_weighted_dice_loss: 0.1245

Epoch 00112: val_weighted_dice_loss did not improve from 0.12198
Epoch 113/150
 - 1125s - loss: 0.0856 - weighted_dice_loss: 0.0869 - val_loss: 0.1294 - val_weighted_dice_loss: 0.1312

Epoch 00113: val_weighted_dice_loss did not improve from 0.12198
Epoch 114/150
 - 1128s - loss: 0.0855 - weighted_dice_loss: 0.0868 - val_loss: 0.1257 - val_weighted_dice_loss: 0.1275

Epoch 00114: val_weighted_dice_loss did not improve from 0.12198
Epoch 115/150
 - 1125s - loss: 0.0853 - weighted_dice_loss: 0.0865 - val_loss: 0.1244 - val_weighted_dice_loss: 0.1262

Epoch 00115: val_weighted_dice_loss did not improve from 0.12198
Epoch 116/150
 - 1125s - loss: 0.0851 - weighted_dice_loss: 0.0864 - val_loss: 0.1243 - val_weighted_dice_loss: 0.1260

Epoch 00116: val_weighted_dice_loss did not improve from 0.12198
Epoch 117/150
 - 1126s - loss: 0.0848 - weighted_dice_loss: 0.0860 - val_loss: 0.1256 - val_weighted_dice_loss: 0.1274

Epoch 00117: val_weighted_dice_loss did not improve from 0.12198
Epoch 118/150
 - 1126s - loss: 0.0848 - weighted_dice_loss: 0.0860 - val_loss: 0.1191 - val_weighted_dice_loss: 0.1208

Epoch 00118: val_weighted_dice_loss improved from 0.12198 to 0.12076, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 119/150
 - 1126s - loss: 0.0845 - weighted_dice_loss: 0.0857 - val_loss: 0.1269 - val_weighted_dice_loss: 0.1287

Epoch 00119: val_weighted_dice_loss did not improve from 0.12076
Epoch 120/150
 - 1126s - loss: 0.0843 - weighted_dice_loss: 0.0855 - val_loss: 0.1243 - val_weighted_dice_loss: 0.1261

Epoch 00120: val_weighted_dice_loss did not improve from 0.12076
Epoch 121/150
 - 1125s - loss: 0.0840 - weighted_dice_loss: 0.0852 - val_loss: 0.1297 - val_weighted_dice_loss: 0.1315

Epoch 00121: val_weighted_dice_loss did not improve from 0.12076
Epoch 122/150
 - 1125s - loss: 0.0840 - weighted_dice_loss: 0.0852 - val_loss: 0.1290 - val_weighted_dice_loss: 0.1308

Epoch 00122: val_weighted_dice_loss did not improve from 0.12076
Epoch 123/150
 - 1126s - loss: 0.0838 - weighted_dice_loss: 0.0851 - val_loss: 0.1199 - val_weighted_dice_loss: 0.1216

Epoch 00123: val_weighted_dice_loss did not improve from 0.12076
Epoch 124/150
 - 1126s - loss: 0.0835 - weighted_dice_loss: 0.0847 - val_loss: 0.1274 - val_weighted_dice_loss: 0.1293

Epoch 00124: val_weighted_dice_loss did not improve from 0.12076
Epoch 125/150
 - 1125s - loss: 0.0833 - weighted_dice_loss: 0.0845 - val_loss: 0.1268 - val_weighted_dice_loss: 0.1286

Epoch 00125: val_weighted_dice_loss did not improve from 0.12076
Epoch 126/150
 - 1126s - loss: 0.0834 - weighted_dice_loss: 0.0846 - val_loss: 0.1276 - val_weighted_dice_loss: 0.1294

Epoch 00126: val_weighted_dice_loss did not improve from 0.12076
Epoch 127/150
 - 1126s - loss: 0.0831 - weighted_dice_loss: 0.0843 - val_loss: 0.1207 - val_weighted_dice_loss: 0.1225

Epoch 00127: val_weighted_dice_loss did not improve from 0.12076
Epoch 128/150
 - 1125s - loss: 0.0830 - weighted_dice_loss: 0.0842 - val_loss: 0.1228 - val_weighted_dice_loss: 0.1246

Epoch 00128: val_weighted_dice_loss did not improve from 0.12076
Epoch 129/150
 - 1126s - loss: 0.0827 - weighted_dice_loss: 0.0839 - val_loss: 0.1227 - val_weighted_dice_loss: 0.1244

Epoch 00129: val_weighted_dice_loss did not improve from 0.12076
Epoch 130/150
 - 1126s - loss: 0.0825 - weighted_dice_loss: 0.0837 - val_loss: 0.1318 - val_weighted_dice_loss: 0.1337

Epoch 00130: val_weighted_dice_loss did not improve from 0.12076
Epoch 131/150
 - 1125s - loss: 0.0825 - weighted_dice_loss: 0.0836 - val_loss: 0.1257 - val_weighted_dice_loss: 0.1275

Epoch 00131: val_weighted_dice_loss did not improve from 0.12076
Epoch 132/150
 - 1126s - loss: 0.0822 - weighted_dice_loss: 0.0834 - val_loss: 0.1201 - val_weighted_dice_loss: 0.1219

Epoch 00132: val_weighted_dice_loss did not improve from 0.12076
Epoch 133/150
 - 1125s - loss: 0.0821 - weighted_dice_loss: 0.0833 - val_loss: 0.1159 - val_weighted_dice_loss: 0.1176

Epoch 00133: val_weighted_dice_loss improved from 0.12076 to 0.11756, saving model to /nobackup/data/mehfo331/Code/Unet-weights/U-net_weights_GAN_2.h5
Epoch 134/150
 - 1125s - loss: 0.0819 - weighted_dice_loss: 0.0831 - val_loss: 0.1296 - val_weighted_dice_loss: 0.1314

Epoch 00134: val_weighted_dice_loss did not improve from 0.11756
Epoch 135/150
 - 1126s - loss: 0.0817 - weighted_dice_loss: 0.0829 - val_loss: 0.1253 - val_weighted_dice_loss: 0.1271

Epoch 00135: val_weighted_dice_loss did not improve from 0.11756
Epoch 136/150
 - 1126s - loss: 0.0816 - weighted_dice_loss: 0.0828 - val_loss: 0.1215 - val_weighted_dice_loss: 0.1232

Epoch 00136: val_weighted_dice_loss did not improve from 0.11756
Epoch 137/150
 - 1127s - loss: 0.0815 - weighted_dice_loss: 0.0827 - val_loss: 0.1200 - val_weighted_dice_loss: 0.1217

Epoch 00137: val_weighted_dice_loss did not improve from 0.11756
Epoch 138/150
 - 1125s - loss: 0.0812 - weighted_dice_loss: 0.0824 - val_loss: 0.1348 - val_weighted_dice_loss: 0.1368

Epoch 00138: val_weighted_dice_loss did not improve from 0.11756
Epoch 139/150
 - 1125s - loss: 0.0812 - weighted_dice_loss: 0.0824 - val_loss: 0.1237 - val_weighted_dice_loss: 0.1254

Epoch 00139: val_weighted_dice_loss did not improve from 0.11756
Epoch 140/150
 - 1124s - loss: 0.0808 - weighted_dice_loss: 0.0820 - val_loss: 0.1198 - val_weighted_dice_loss: 0.1215

Epoch 00140: val_weighted_dice_loss did not improve from 0.11756
Epoch 141/150
 - 1127s - loss: 0.0807 - weighted_dice_loss: 0.0819 - val_loss: 0.1263 - val_weighted_dice_loss: 0.1281

Epoch 00141: val_weighted_dice_loss did not improve from 0.11756
Epoch 142/150
 - 1125s - loss: 0.0807 - weighted_dice_loss: 0.0819 - val_loss: 0.1323 - val_weighted_dice_loss: 0.1342

Epoch 00142: val_weighted_dice_loss did not improve from 0.11756
Epoch 143/150
 - 1126s - loss: 0.0806 - weighted_dice_loss: 0.0818 - val_loss: 0.1208 - val_weighted_dice_loss: 0.1225

Epoch 00143: val_weighted_dice_loss did not improve from 0.11756
Epoch 144/150
 - 1126s - loss: 0.0803 - weighted_dice_loss: 0.0815 - val_loss: 0.1291 - val_weighted_dice_loss: 0.1309

Epoch 00144: val_weighted_dice_loss did not improve from 0.11756
Epoch 145/150
 - 1126s - loss: 0.0803 - weighted_dice_loss: 0.0815 - val_loss: 0.1221 - val_weighted_dice_loss: 0.1238

Epoch 00145: val_weighted_dice_loss did not improve from 0.11756
Epoch 146/150
 - 1125s - loss: 0.0799 - weighted_dice_loss: 0.0811 - val_loss: 0.1201 - val_weighted_dice_loss: 0.1218

Epoch 00146: val_weighted_dice_loss did not improve from 0.11756
Epoch 147/150
 - 1125s - loss: 0.0799 - weighted_dice_loss: 0.0811 - val_loss: 0.1192 - val_weighted_dice_loss: 0.1209

Epoch 00147: val_weighted_dice_loss did not improve from 0.11756
Epoch 148/150
 - 1126s - loss: 0.0798 - weighted_dice_loss: 0.0810 - val_loss: 0.1228 - val_weighted_dice_loss: 0.1245

Epoch 00148: val_weighted_dice_loss did not improve from 0.11756
Epoch 149/150
 - 1126s - loss: 0.0797 - weighted_dice_loss: 0.0809 - val_loss: 0.1260 - val_weighted_dice_loss: 0.1277

Epoch 00149: val_weighted_dice_loss did not improve from 0.11756
Epoch 150/150
 - 1126s - loss: 0.0795 - weighted_dice_loss: 0.0806 - val_loss: 0.1203 - val_weighted_dice_loss: 0.1220

Epoch 00150: val_weighted_dice_loss did not improve from 0.11756
